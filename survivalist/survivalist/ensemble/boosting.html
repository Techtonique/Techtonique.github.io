<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 14.4.0"/>
    <title>survivalist.ensemble.boosting API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! theme.css */:root{--pdoc-background:#212529;}.pdoc{--text:#f7f7f7;--muted:#9d9d9d;--link:#58a6ff;--link-hover:#3989ff;--code:#333;--active:#555;--accent:#343434;--accent2:#555;--nav-hover:rgba(0, 0, 0, 0.1);--name:#77C1FF;--def:#0cdd0c;--annotation:#00c037;}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#49483e}.pdoc-code{background:#272822; color:#f8f8f2}.pdoc-code .c{color:#75715e}.pdoc-code .err{color:#960050; background-color:#1e0010}.pdoc-code .esc{color:#f8f8f2}.pdoc-code .g{color:#f8f8f2}.pdoc-code .k{color:#66d9ef}.pdoc-code .l{color:#ae81ff}.pdoc-code .n{color:#f8f8f2}.pdoc-code .o{color:#f92672}.pdoc-code .x{color:#f8f8f2}.pdoc-code .p{color:#f8f8f2}.pdoc-code .ch{color:#75715e}.pdoc-code .cm{color:#75715e}.pdoc-code .cp{color:#75715e}.pdoc-code .cpf{color:#75715e}.pdoc-code .c1{color:#75715e}.pdoc-code .cs{color:#75715e}.pdoc-code .gd{color:#f92672}.pdoc-code .ge{color:#f8f8f2; font-style:italic}.pdoc-code .gr{color:#f8f8f2}.pdoc-code .gh{color:#f8f8f2}.pdoc-code .gi{color:#a6e22e}.pdoc-code .go{color:#66d9ef}.pdoc-code .gp{color:#f92672; font-weight:bold}.pdoc-code .gs{color:#f8f8f2; font-weight:bold}.pdoc-code .gu{color:#75715e}.pdoc-code .gt{color:#f8f8f2}.pdoc-code .kc{color:#66d9ef}.pdoc-code .kd{color:#66d9ef}.pdoc-code .kn{color:#f92672}.pdoc-code .kp{color:#66d9ef}.pdoc-code .kr{color:#66d9ef}.pdoc-code .kt{color:#66d9ef}.pdoc-code .ld{color:#e6db74}.pdoc-code .m{color:#ae81ff}.pdoc-code .s{color:#e6db74}.pdoc-code .na{color:#a6e22e}.pdoc-code .nb{color:#f8f8f2}.pdoc-code .nc{color:#a6e22e}.pdoc-code .no{color:#66d9ef}.pdoc-code .nd{color:#a6e22e}.pdoc-code .ni{color:#f8f8f2}.pdoc-code .ne{color:#a6e22e}.pdoc-code .nf{color:#a6e22e}.pdoc-code .nl{color:#f8f8f2}.pdoc-code .nn{color:#f8f8f2}.pdoc-code .nx{color:#a6e22e}.pdoc-code .py{color:#f8f8f2}.pdoc-code .nt{color:#f92672}.pdoc-code .nv{color:#f8f8f2}.pdoc-code .ow{color:#f92672}.pdoc-code .w{color:#f8f8f2}.pdoc-code .mb{color:#ae81ff}.pdoc-code .mf{color:#ae81ff}.pdoc-code .mh{color:#ae81ff}.pdoc-code .mi{color:#ae81ff}.pdoc-code .mo{color:#ae81ff}.pdoc-code .sa{color:#e6db74}.pdoc-code .sb{color:#e6db74}.pdoc-code .sc{color:#e6db74}.pdoc-code .dl{color:#e6db74}.pdoc-code .sd{color:#e6db74}.pdoc-code .s2{color:#e6db74}.pdoc-code .se{color:#ae81ff}.pdoc-code .sh{color:#e6db74}.pdoc-code .si{color:#e6db74}.pdoc-code .sx{color:#e6db74}.pdoc-code .sr{color:#e6db74}.pdoc-code .s1{color:#e6db74}.pdoc-code .ss{color:#e6db74}.pdoc-code .bp{color:#f8f8f2}.pdoc-code .fm{color:#a6e22e}.pdoc-code .vc{color:#f8f8f2}.pdoc-code .vg{color:#f8f8f2}.pdoc-code .vi{color:#f8f8f2}.pdoc-code .vm{color:#f8f8f2}</style>
    <style>/*! theme.css */:root{--pdoc-background:#212529;}.pdoc{--text:#f7f7f7;--muted:#9d9d9d;--link:#58a6ff;--link-hover:#3989ff;--code:#333;--active:#555;--accent:#343434;--accent2:#555;--nav-hover:rgba(0, 0, 0, 0.1);--name:#77C1FF;--def:#0cdd0c;--annotation:#00c037;}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#49483e}.pdoc-code{background:#272822; color:#f8f8f2}.pdoc-code .c{color:#75715e}.pdoc-code .err{color:#960050; background-color:#1e0010}.pdoc-code .esc{color:#f8f8f2}.pdoc-code .g{color:#f8f8f2}.pdoc-code .k{color:#66d9ef}.pdoc-code .l{color:#ae81ff}.pdoc-code .n{color:#f8f8f2}.pdoc-code .o{color:#f92672}.pdoc-code .x{color:#f8f8f2}.pdoc-code .p{color:#f8f8f2}.pdoc-code .ch{color:#75715e}.pdoc-code .cm{color:#75715e}.pdoc-code .cp{color:#75715e}.pdoc-code .cpf{color:#75715e}.pdoc-code .c1{color:#75715e}.pdoc-code .cs{color:#75715e}.pdoc-code .gd{color:#f92672}.pdoc-code .ge{color:#f8f8f2; font-style:italic}.pdoc-code .gr{color:#f8f8f2}.pdoc-code .gh{color:#f8f8f2}.pdoc-code .gi{color:#a6e22e}.pdoc-code .go{color:#66d9ef}.pdoc-code .gp{color:#f92672; font-weight:bold}.pdoc-code .gs{color:#f8f8f2; font-weight:bold}.pdoc-code .gu{color:#75715e}.pdoc-code .gt{color:#f8f8f2}.pdoc-code .kc{color:#66d9ef}.pdoc-code .kd{color:#66d9ef}.pdoc-code .kn{color:#f92672}.pdoc-code .kp{color:#66d9ef}.pdoc-code .kr{color:#66d9ef}.pdoc-code .kt{color:#66d9ef}.pdoc-code .ld{color:#e6db74}.pdoc-code .m{color:#ae81ff}.pdoc-code .s{color:#e6db74}.pdoc-code .na{color:#a6e22e}.pdoc-code .nb{color:#f8f8f2}.pdoc-code .nc{color:#a6e22e}.pdoc-code .no{color:#66d9ef}.pdoc-code .nd{color:#a6e22e}.pdoc-code .ni{color:#f8f8f2}.pdoc-code .ne{color:#a6e22e}.pdoc-code .nf{color:#a6e22e}.pdoc-code .nl{color:#f8f8f2}.pdoc-code .nn{color:#f8f8f2}.pdoc-code .nx{color:#a6e22e}.pdoc-code .py{color:#f8f8f2}.pdoc-code .nt{color:#f92672}.pdoc-code .nv{color:#f8f8f2}.pdoc-code .ow{color:#f92672}.pdoc-code .w{color:#f8f8f2}.pdoc-code .mb{color:#ae81ff}.pdoc-code .mf{color:#ae81ff}.pdoc-code .mh{color:#ae81ff}.pdoc-code .mi{color:#ae81ff}.pdoc-code .mo{color:#ae81ff}.pdoc-code .sa{color:#e6db74}.pdoc-code .sb{color:#e6db74}.pdoc-code .sc{color:#e6db74}.pdoc-code .dl{color:#e6db74}.pdoc-code .sd{color:#e6db74}.pdoc-code .s2{color:#e6db74}.pdoc-code .se{color:#ae81ff}.pdoc-code .sh{color:#e6db74}.pdoc-code .si{color:#e6db74}.pdoc-code .sx{color:#e6db74}.pdoc-code .sr{color:#e6db74}.pdoc-code .s1{color:#e6db74}.pdoc-code .ss{color:#e6db74}.pdoc-code .bp{color:#f8f8f2}.pdoc-code .fm{color:#a6e22e}.pdoc-code .vc{color:#f8f8f2}.pdoc-code .vg{color:#f8f8f2}.pdoc-code .vi{color:#f8f8f2}.pdoc-code .vm{color:#f8f8f2}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../ensemble.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;survivalist.ensemble</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>            
                <ul class="memberlist">
            <li>
                    <a class="class" href="#ComponentwiseGradientBoostingSurvivalAnalysis">ComponentwiseGradientBoostingSurvivalAnalysis</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#GradientBoostingSurvivalAnalysis">GradientBoostingSurvivalAnalysis</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../../survivalist.html">survivalist</a><wbr>.<a href="./../ensemble.html">ensemble</a><wbr>.boosting    </h1>

                
                        <input id="mod-boosting-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-boosting-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">   1</span></a><span class="c1"># This program is free software: you can redistribute it and/or modify</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">   2</span></a><span class="c1"># it under the terms of the GNU General Public License as published by</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">   3</span></a><span class="c1"># the Free Software Foundation, either version 3 of the License, or</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">   4</span></a><span class="c1"># (at your option) any later version.</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">   5</span></a><span class="c1">#</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">   6</span></a><span class="c1"># This program is distributed in the hope that it will be useful,</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">   7</span></a><span class="c1"># but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">   8</span></a><span class="c1"># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">   9</span></a><span class="c1"># GNU General Public License for more details.</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">  10</span></a><span class="c1">#</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">  11</span></a><span class="c1"># You should have received a copy of the GNU General Public License</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">  12</span></a><span class="c1"># along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">  13</span></a><span class="kn">import</span> <span class="nn">numbers</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">  14</span></a>
</span><span id="L-15"><a href="#L-15"><span class="linenos">  15</span></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos">  16</span></a><span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csc_matrix</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">,</span> <span class="n">issparse</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos">  17</span></a><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos">  18</span></a><span class="kn">from</span> <span class="nn">sklearn.ensemble._base</span> <span class="kn">import</span> <span class="n">BaseEnsemble</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos">  19</span></a><span class="kn">from</span> <span class="nn">sklearn.ensemble._gb</span> <span class="kn">import</span> <span class="n">BaseGradientBoosting</span><span class="p">,</span> <span class="n">VerboseReporter</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos">  20</span></a><span class="kn">from</span> <span class="nn">sklearn.ensemble._gradient_boosting</span> <span class="kn">import</span> <span class="n">_random_sample_mask</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos">  21</span></a><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos">  22</span></a><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos">  23</span></a><span class="kn">from</span> <span class="nn">sklearn.tree._tree</span> <span class="kn">import</span> <span class="n">DTYPE</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos">  24</span></a><span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos">  25</span></a><span class="kn">from</span> <span class="nn">sklearn.utils._param_validation</span> <span class="kn">import</span> <span class="n">Interval</span><span class="p">,</span> <span class="n">StrOptions</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos">  26</span></a><span class="kn">from</span> <span class="nn">sklearn.utils.extmath</span> <span class="kn">import</span> <span class="n">squared_norm</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos">  27</span></a><span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="p">(</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos">  28</span></a>    <span class="n">_check_sample_weight</span><span class="p">,</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos">  29</span></a>    <span class="n">check_array</span><span class="p">,</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos">  30</span></a>    <span class="n">check_is_fitted</span><span class="p">,</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos">  31</span></a><span class="p">)</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos">  32</span></a>
</span><span id="L-33"><a href="#L-33"><span class="linenos">  33</span></a><span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">SurvivalAnalysisMixin</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos">  34</span></a><span class="kn">from</span> <span class="nn">..linear_model.coxph</span> <span class="kn">import</span> <span class="n">BreslowEstimator</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos">  35</span></a><span class="kn">from</span> <span class="nn">..util</span> <span class="kn">import</span> <span class="n">check_array_survival</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos">  36</span></a><span class="kn">from</span> <span class="nn">.survival_loss</span> <span class="kn">import</span> <span class="p">(</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos">  37</span></a>    <span class="n">LOSS_FUNCTIONS</span><span class="p">,</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos">  38</span></a>    <span class="n">CensoredSquaredLoss</span><span class="p">,</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos">  39</span></a>    <span class="n">CoxPH</span><span class="p">,</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos">  40</span></a>    <span class="n">IPCWLeastSquaresError</span><span class="p">,</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos">  41</span></a><span class="p">)</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos">  42</span></a>
</span><span id="L-43"><a href="#L-43"><span class="linenos">  43</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos">  44</span></a>    <span class="s2">&quot;ComponentwiseGradientBoostingSurvivalAnalysis&quot;</span><span class="p">,</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos">  45</span></a>    <span class="s2">&quot;GradientBoostingSurvivalAnalysis&quot;</span><span class="p">,</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos">  46</span></a><span class="p">]</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos">  47</span></a>
</span><span id="L-48"><a href="#L-48"><span class="linenos">  48</span></a>
</span><span id="L-49"><a href="#L-49"><span class="linenos">  49</span></a><span class="k">def</span> <span class="nf">_sample_binomial_plus_one</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos">  50</span></a>    <span class="n">drop_model</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos">  51</span></a>    <span class="n">n_dropped</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">drop_model</span><span class="p">)</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos">  52</span></a>    <span class="k">if</span> <span class="n">n_dropped</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos">  53</span></a>        <span class="n">idx</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos">  54</span></a>        <span class="n">drop_model</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos">  55</span></a>        <span class="n">n_dropped</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos">  56</span></a>    <span class="k">return</span> <span class="n">drop_model</span><span class="p">,</span> <span class="n">n_dropped</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos">  57</span></a>
</span><span id="L-58"><a href="#L-58"><span class="linenos">  58</span></a>
</span><span id="L-59"><a href="#L-59"><span class="linenos">  59</span></a><span class="k">class</span> <span class="nc">_ComponentwiseLeastSquares</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos">  60</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">component</span><span class="p">):</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos">  61</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">component</span> <span class="o">=</span> <span class="n">component</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos">  62</span></a>
</span><span id="L-63"><a href="#L-63"><span class="linenos">  63</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos">  64</span></a>        <span class="n">xw</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">component</span><span class="p">]</span> <span class="o">*</span> <span class="n">sample_weight</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos">  65</span></a>        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xw</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos">  66</span></a>        <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos">  67</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos">  68</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos">  69</span></a>            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xw</span><span class="p">,</span> <span class="n">xw</span><span class="p">)</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos">  70</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">b</span> <span class="o">/</span> <span class="n">a</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos">  71</span></a>
</span><span id="L-72"><a href="#L-72"><span class="linenos">  72</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos">  73</span></a>
</span><span id="L-74"><a href="#L-74"><span class="linenos">  74</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos">  75</span></a>        <span class="k">return</span> <span class="n">X</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">component</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos">  76</span></a>
</span><span id="L-77"><a href="#L-77"><span class="linenos">  77</span></a>
</span><span id="L-78"><a href="#L-78"><span class="linenos">  78</span></a><span class="k">def</span> <span class="nf">_fit_stage_componentwise</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">):</span>  <span class="c1"># pylint: disable=unused-argument</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos">  79</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Fit component-wise weighted least squares model&quot;&quot;&quot;</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos">  80</span></a>    <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos">  81</span></a>
</span><span id="L-82"><a href="#L-82"><span class="linenos">  82</span></a>    <span class="n">base_learners</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos">  83</span></a>    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos">  84</span></a>    <span class="k">for</span> <span class="n">component</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos">  85</span></a>        <span class="n">learner</span> <span class="o">=</span> <span class="n">_ComponentwiseLeastSquares</span><span class="p">(</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos">  86</span></a>            <span class="n">component</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos">  87</span></a>        <span class="n">l_pred</span> <span class="o">=</span> <span class="n">learner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos">  88</span></a>        <span class="n">error</span><span class="p">[</span><span class="n">component</span><span class="p">]</span> <span class="o">=</span> <span class="n">squared_norm</span><span class="p">(</span><span class="n">residuals</span> <span class="o">-</span> <span class="n">l_pred</span><span class="p">)</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos">  89</span></a>        <span class="n">base_learners</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos">  90</span></a>
</span><span id="L-91"><a href="#L-91"><span class="linenos">  91</span></a>    <span class="c1"># TODO: could use bottleneck.nanargmin for speed</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos">  92</span></a>    <span class="n">best_component</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanargmin</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos">  93</span></a>    <span class="n">best_learner</span> <span class="o">=</span> <span class="n">base_learners</span><span class="p">[</span><span class="n">best_component</span><span class="p">]</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos">  94</span></a>    <span class="k">return</span> <span class="n">best_learner</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos">  95</span></a>
</span><span id="L-96"><a href="#L-96"><span class="linenos">  96</span></a>
</span><span id="L-97"><a href="#L-97"><span class="linenos">  97</span></a><span class="k">class</span> <span class="nc">ComponentwiseGradientBoostingSurvivalAnalysis</span><span class="p">(</span><span class="n">BaseEnsemble</span><span class="p">,</span> <span class="n">SurvivalAnalysisMixin</span><span class="p">):</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos">  98</span></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gradient boosting with component-wise least squares as base learner.</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos">  99</span></a>
</span><span id="L-100"><a href="#L-100"><span class="linenos"> 100</span></a><span class="sd">    See the :ref:`User Guide &lt;/user_guide/boosting.ipynb&gt;` and [1]_ for further description.</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos"> 101</span></a>
</span><span id="L-102"><a href="#L-102"><span class="linenos"> 102</span></a><span class="sd">    Parameters</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos"> 103</span></a><span class="sd">    ----------</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos"> 104</span></a><span class="sd">    loss : {&#39;coxph&#39;, &#39;squared&#39;, &#39;ipcwls&#39;}, optional, default: &#39;coxph&#39;</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos"> 105</span></a><span class="sd">        loss function to be optimized. &#39;coxph&#39; refers to partial likelihood loss</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos"> 106</span></a><span class="sd">        of Cox&#39;s proportional hazards model. The loss &#39;squared&#39; minimizes a</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos"> 107</span></a><span class="sd">        squared regression loss that ignores predictions beyond the time of censoring,</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos"> 108</span></a><span class="sd">        and &#39;ipcwls&#39; refers to inverse-probability of censoring weighted least squares error.</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos"> 109</span></a>
</span><span id="L-110"><a href="#L-110"><span class="linenos"> 110</span></a><span class="sd">    learning_rate : float, optional, default: 0.1</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos"> 111</span></a><span class="sd">        learning rate shrinks the contribution of each base learner by `learning_rate`.</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos"> 112</span></a><span class="sd">        There is a trade-off between `learning_rate` and `n_estimators`.</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos"> 113</span></a><span class="sd">        Values must be in the range `[0.0, inf)`.</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos"> 114</span></a>
</span><span id="L-115"><a href="#L-115"><span class="linenos"> 115</span></a><span class="sd">    n_estimators : int, default: 100</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos"> 116</span></a><span class="sd">        The number of boosting stages to perform. Gradient boosting</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos"> 117</span></a><span class="sd">        is fairly robust to over-fitting so a large number usually</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos"> 118</span></a><span class="sd">        results in better performance.</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos"> 119</span></a><span class="sd">        Values must be in the range `[1, inf)`.</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos"> 120</span></a>
</span><span id="L-121"><a href="#L-121"><span class="linenos"> 121</span></a><span class="sd">    subsample : float, optional, default: 1.0</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos"> 122</span></a><span class="sd">        The fraction of samples to be used for fitting the individual base</span>
</span><span id="L-123"><a href="#L-123"><span class="linenos"> 123</span></a><span class="sd">        learners. If smaller than 1.0 this results in Stochastic Gradient</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos"> 124</span></a><span class="sd">        Boosting. `subsample` interacts with the parameter `n_estimators`.</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos"> 125</span></a><span class="sd">        Choosing `subsample &lt; 1.0` leads to a reduction of variance</span>
</span><span id="L-126"><a href="#L-126"><span class="linenos"> 126</span></a><span class="sd">        and an increase in bias.</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos"> 127</span></a><span class="sd">        Values must be in the range `(0.0, 1.0]`.</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos"> 128</span></a>
</span><span id="L-129"><a href="#L-129"><span class="linenos"> 129</span></a><span class="sd">    warm_start : bool, default: False</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos"> 130</span></a><span class="sd">        When set to ``True``, reuse the solution of the previous call to fit</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos"> 131</span></a><span class="sd">        and add more estimators to the ensemble, otherwise, just erase the</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos"> 132</span></a><span class="sd">        previous solution.</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos"> 133</span></a>
</span><span id="L-134"><a href="#L-134"><span class="linenos"> 134</span></a><span class="sd">    dropout_rate : float, optional, default: 0.0</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos"> 135</span></a><span class="sd">        If larger than zero, the residuals at each iteration are only computed</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos"> 136</span></a><span class="sd">        from a random subset of base learners. The value corresponds to the</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos"> 137</span></a><span class="sd">        percentage of base learners that are dropped. In each iteration,</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos"> 138</span></a><span class="sd">        at least one base learner is dropped. This is an alternative regularization</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos"> 139</span></a><span class="sd">        to shrinkage, i.e., setting `learning_rate &lt; 1.0`.</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos"> 140</span></a><span class="sd">        Values must be in the range `[0.0, 1.0)`.</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos"> 141</span></a>
</span><span id="L-142"><a href="#L-142"><span class="linenos"> 142</span></a><span class="sd">    random_state : int seed, RandomState instance, or None, default: None</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos"> 143</span></a><span class="sd">        The seed of the pseudo random number generator to use when</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos"> 144</span></a><span class="sd">        shuffling the data.</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos"> 145</span></a>
</span><span id="L-146"><a href="#L-146"><span class="linenos"> 146</span></a><span class="sd">    verbose : int, default: 0</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos"> 147</span></a><span class="sd">        Enable verbose output. If 1 then it prints progress and performance</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos"> 148</span></a><span class="sd">        once in a while.</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos"> 149</span></a><span class="sd">        Values must be in the range `[0, inf)`.</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos"> 150</span></a>
</span><span id="L-151"><a href="#L-151"><span class="linenos"> 151</span></a><span class="sd">    Attributes</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos"> 152</span></a><span class="sd">    ----------</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos"> 153</span></a><span class="sd">    coef_ : array, shape = (n_features + 1,)</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos"> 154</span></a><span class="sd">        The aggregated coefficients. The first element `coef\_[0]` corresponds</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos"> 155</span></a><span class="sd">        to the intercept. If loss is `coxph`, the intercept will always be zero.</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos"> 156</span></a>
</span><span id="L-157"><a href="#L-157"><span class="linenos"> 157</span></a><span class="sd">    estimators_ : list of base learners</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos"> 158</span></a><span class="sd">        The collection of fitted sub-estimators.</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos"> 159</span></a>
</span><span id="L-160"><a href="#L-160"><span class="linenos"> 160</span></a><span class="sd">    train_score_ : ndarray, shape = (n_estimators,)</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos"> 161</span></a><span class="sd">        The i-th score ``train_score_[i]`` is the loss of the</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos"> 162</span></a><span class="sd">        model at iteration ``i`` on the in-bag sample.</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos"> 163</span></a><span class="sd">        If ``subsample == 1`` this is the loss on the training data.</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos"> 164</span></a>
</span><span id="L-165"><a href="#L-165"><span class="linenos"> 165</span></a><span class="sd">    oob_improvement_ : ndarray, shape = (n_estimators,)</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos"> 166</span></a><span class="sd">        The improvement in loss on the out-of-bag samples</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos"> 167</span></a><span class="sd">        relative to the previous iteration.</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos"> 168</span></a><span class="sd">        ``oob_improvement_[0]`` is the improvement in</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos"> 169</span></a><span class="sd">        loss of the first stage over the ``init`` estimator.</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos"> 170</span></a><span class="sd">        Only available if ``subsample &lt; 1.0``.</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos"> 171</span></a>
</span><span id="L-172"><a href="#L-172"><span class="linenos"> 172</span></a><span class="sd">    oob_scores_ : ndarray of shape (n_estimators,)</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos"> 173</span></a><span class="sd">        The full history of the loss values on the out-of-bag</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos"> 174</span></a><span class="sd">        samples. Only available if ``subsample &lt; 1.0``.</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos"> 175</span></a>
</span><span id="L-176"><a href="#L-176"><span class="linenos"> 176</span></a><span class="sd">    oob_score_ : float</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos"> 177</span></a><span class="sd">        The last value of the loss on the out-of-bag samples. It is</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos"> 178</span></a><span class="sd">        the same as ``oob_scores_[-1]``. Only available if ``subsample &lt; 1.0``.</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos"> 179</span></a>
</span><span id="L-180"><a href="#L-180"><span class="linenos"> 180</span></a><span class="sd">    n_features_in_ : int</span>
</span><span id="L-181"><a href="#L-181"><span class="linenos"> 181</span></a><span class="sd">        Number of features seen during ``fit``.</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos"> 182</span></a>
</span><span id="L-183"><a href="#L-183"><span class="linenos"> 183</span></a><span class="sd">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos"> 184</span></a><span class="sd">        Names of features seen during ``fit``. Defined only when `X`</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos"> 185</span></a><span class="sd">        has feature names that are all strings.</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos"> 186</span></a>
</span><span id="L-187"><a href="#L-187"><span class="linenos"> 187</span></a><span class="sd">    unique_times_ : array of shape = (n_unique_times,)</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos"> 188</span></a><span class="sd">        Unique time points.</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos"> 189</span></a>
</span><span id="L-190"><a href="#L-190"><span class="linenos"> 190</span></a><span class="sd">    References</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos"> 191</span></a><span class="sd">    ----------</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos"> 192</span></a><span class="sd">    .. [1] Hothorn, T., Bhlmann, P., Dudoit, S., Molinaro, A., van der Laan, M. J.,</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos"> 193</span></a><span class="sd">           &quot;Survival ensembles&quot;, Biostatistics, 7(3), 355-73, 2006</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos"> 194</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos"> 195</span></a>
</span><span id="L-196"><a href="#L-196"><span class="linenos"> 196</span></a>    <span class="n">_parameter_constraints</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos"> 197</span></a>        <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">LOSS_FUNCTIONS</span><span class="o">.</span><span class="n">keys</span><span class="p">()))],</span>
</span><span id="L-198"><a href="#L-198"><span class="linenos"> 198</span></a>        <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos"> 199</span></a>        <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos"> 200</span></a>        <span class="s2">&quot;subsample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)],</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos"> 201</span></a>        <span class="s2">&quot;warm_start&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos"> 202</span></a>        <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos"> 203</span></a>        <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">],</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos"> 204</span></a>        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">],</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos"> 205</span></a>    <span class="p">}</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos"> 206</span></a>
</span><span id="L-207"><a href="#L-207"><span class="linenos"> 207</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos"> 208</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos"> 209</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos"> 210</span></a>        <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;coxph&quot;</span><span class="p">,</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos"> 211</span></a>        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos"> 212</span></a>        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos"> 213</span></a>        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos"> 214</span></a>        <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos"> 215</span></a>        <span class="n">dropout_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos"> 216</span></a>        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos"> 217</span></a>        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos"> 218</span></a>    <span class="p">):</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos"> 219</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos"> 220</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos"> 221</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos"> 222</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">=</span> <span class="n">subsample</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos"> 223</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span> <span class="o">=</span> <span class="n">warm_start</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos"> 224</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos"> 225</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos"> 226</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos"> 227</span></a>
</span><span id="L-228"><a href="#L-228"><span class="linenos"> 228</span></a>    <span class="nd">@property</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos"> 229</span></a>    <span class="k">def</span> <span class="nf">_predict_risk_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos"> 230</span></a>        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="n">CoxPH</span><span class="p">)</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos"> 231</span></a>
</span><span id="L-232"><a href="#L-232"><span class="linenos"> 232</span></a>    <span class="k">def</span> <span class="nf">_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos"> 233</span></a>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">,</span> <span class="p">[]))</span> <span class="o">&gt;</span> <span class="mi">0</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos"> 234</span></a>
</span><span id="L-235"><a href="#L-235"><span class="linenos"> 235</span></a>    <span class="k">def</span> <span class="nf">_init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos"> 236</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos"> 237</span></a>
</span><span id="L-238"><a href="#L-238"><span class="linenos"> 238</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos"> 239</span></a>        <span class="c1"># do oob?</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos"> 240</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos"> 241</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos"> 242</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos"> 243</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos"> 244</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos"> 245</span></a>
</span><span id="L-246"><a href="#L-246"><span class="linenos"> 246</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos"> 247</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos"> 248</span></a>
</span><span id="L-249"><a href="#L-249"><span class="linenos"> 249</span></a>    <span class="k">def</span> <span class="nf">_resize_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos"> 250</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Add additional ``n_estimators`` entries to all attributes.&quot;&quot;&quot;</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos"> 251</span></a>        <span class="c1"># self.n_estimators is the number of additional est to fit</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos"> 252</span></a>        <span class="n">total_n_estimators</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos"> 253</span></a>
</span><span id="L-254"><a href="#L-254"><span class="linenos"> 254</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="L-255"><a href="#L-255"><span class="linenos"> 255</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos"> 256</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_improvement_&quot;</span><span class="p">):</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos"> 257</span></a>            <span class="c1"># if do oob resize arrays or create new if not available</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos"> 258</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_improvement_&quot;</span><span class="p">):</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos"> 259</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos"> 260</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="L-261"><a href="#L-261"><span class="linenos"> 261</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos"> 262</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos"> 263</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos"> 264</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos"> 265</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos"> 266</span></a>                    <span class="n">total_n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos"> 267</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos"> 268</span></a>                    <span class="p">(</span><span class="n">total_n_estimators</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="L-269"><a href="#L-269"><span class="linenos"> 269</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos"> 270</span></a>
</span><span id="L-271"><a href="#L-271"><span class="linenos"> 271</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos"> 272</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos"> 273</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos"> 274</span></a>                    <span class="s2">&quot;fitting with warm_start=True and dropout_rate &gt; 0 is only &quot;</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos"> 275</span></a>                    <span class="s2">&quot;supported if the previous fit used dropout_rate &gt; 0 too&quot;</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos"> 276</span></a>                <span class="p">)</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos"> 277</span></a>
</span><span id="L-278"><a href="#L-278"><span class="linenos"> 278</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos"> 279</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos"> 280</span></a>
</span><span id="L-281"><a href="#L-281"><span class="linenos"> 281</span></a>    <span class="k">def</span> <span class="nf">_clear_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos"> 282</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear the state of the gradient boosting model.&quot;&quot;&quot;</span>
</span><span id="L-283"><a href="#L-283"><span class="linenos"> 283</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">):</span>
</span><span id="L-284"><a href="#L-284"><span class="linenos"> 284</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos"> 285</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;train_score_&quot;</span><span class="p">):</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos"> 286</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span>
</span><span id="L-287"><a href="#L-287"><span class="linenos"> 287</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_improvement_&quot;</span><span class="p">):</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos"> 288</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos"> 289</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_scores_&quot;</span><span class="p">):</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos"> 290</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos"> 291</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_score_&quot;</span><span class="p">):</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos"> 292</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos"> 293</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_rng&quot;</span><span class="p">):</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos"> 294</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span>
</span><span id="L-295"><a href="#L-295"><span class="linenos"> 295</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos"> 296</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos"> 297</span></a>
</span><span id="L-298"><a href="#L-298"><span class="linenos"> 298</span></a>    <span class="k">def</span> <span class="nf">_update_with_dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos"> 299</span></a>        <span class="c1"># select base learners to be dropped for next iteration</span>
</span><span id="L-300"><a href="#L-300"><span class="linenos"> 300</span></a>        <span class="n">drop_model</span><span class="p">,</span> <span class="n">n_dropped</span> <span class="o">=</span> <span class="n">_sample_binomial_plus_one</span><span class="p">(</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos"> 301</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos"> 302</span></a>
</span><span id="L-303"><a href="#L-303"><span class="linenos"> 303</span></a>        <span class="c1"># adjust scaling factor of tree that is going to be trained in next iteration</span>
</span><span id="L-304"><a href="#L-304"><span class="linenos"> 304</span></a>        <span class="n">scale</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_dropped</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos"> 305</span></a>
</span><span id="L-306"><a href="#L-306"><span class="linenos"> 306</span></a>        <span class="n">raw_predictions</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos"> 307</span></a>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="L-308"><a href="#L-308"><span class="linenos"> 308</span></a>            <span class="k">if</span> <span class="n">drop_model</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-309"><a href="#L-309"><span class="linenos"> 309</span></a>                <span class="c1"># adjust scaling factor of dropped trees</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos"> 310</span></a>                <span class="n">scale</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">*=</span> <span class="n">n_dropped</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_dropped</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos"> 311</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos"> 312</span></a>                <span class="c1"># pseudoresponse of next iteration (without contribution of dropped trees)</span>
</span><span id="L-313"><a href="#L-313"><span class="linenos"> 313</span></a>                <span class="n">raw_predictions</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> \
</span><span id="L-314"><a href="#L-314"><span class="linenos"> 314</span></a>                    <span class="n">scale</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">m</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos"> 315</span></a>
</span><span id="L-316"><a href="#L-316"><span class="linenos"> 316</span></a>    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span>
</span><span id="L-317"><a href="#L-317"><span class="linenos"> 317</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos"> 318</span></a>        <span class="n">X</span><span class="p">,</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos"> 319</span></a>        <span class="n">event</span><span class="p">,</span>
</span><span id="L-320"><a href="#L-320"><span class="linenos"> 320</span></a>        <span class="n">time</span><span class="p">,</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos"> 321</span></a>        <span class="n">y_pred</span><span class="p">,</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos"> 322</span></a>        <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos"> 323</span></a>        <span class="n">random_state</span><span class="p">,</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos"> 324</span></a>        <span class="n">begin_at_stage</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos"> 325</span></a>    <span class="p">):</span>  <span class="c1"># noqa: C901</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos"> 326</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos"> 327</span></a>        <span class="c1"># account for intercept</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos"> 328</span></a>        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[</span>
</span><span id="L-329"><a href="#L-329"><span class="linenos"> 329</span></a>                        <span class="p">(</span><span class="s2">&quot;event&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)])</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos"> 330</span></a>
</span><span id="L-331"><a href="#L-331"><span class="linenos"> 331</span></a>        <span class="n">do_oob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mf">1.0</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos"> 332</span></a>        <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="L-333"><a href="#L-333"><span class="linenos"> 333</span></a>            <span class="n">n_inbag</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">))</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos"> 334</span></a>
</span><span id="L-335"><a href="#L-335"><span class="linenos"> 335</span></a>        <span class="n">do_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span>
</span><span id="L-336"><a href="#L-336"><span class="linenos"> 336</span></a>        <span class="k">if</span> <span class="n">do_dropout</span><span class="p">:</span>
</span><span id="L-337"><a href="#L-337"><span class="linenos"> 337</span></a>            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos"> 338</span></a>
</span><span id="L-339"><a href="#L-339"><span class="linenos"> 339</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
</span><span id="L-340"><a href="#L-340"><span class="linenos"> 340</span></a>            <span class="n">verbose_reporter</span> <span class="o">=</span> <span class="n">VerboseReporter</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos"> 341</span></a>            <span class="n">verbose_reporter</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="L-342"><a href="#L-342"><span class="linenos"> 342</span></a>
</span><span id="L-343"><a href="#L-343"><span class="linenos"> 343</span></a>        <span class="c1"># perform boosting iterations</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos"> 344</span></a>        <span class="n">i</span> <span class="o">=</span> <span class="n">begin_at_stage</span>
</span><span id="L-345"><a href="#L-345"><span class="linenos"> 345</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">begin_at_stage</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">)):</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos"> 346</span></a>            <span class="c1"># subsampling</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos"> 347</span></a>            <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="L-348"><a href="#L-348"><span class="linenos"> 348</span></a>                <span class="n">sample_mask</span> <span class="o">=</span> <span class="n">_random_sample_mask</span><span class="p">(</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos"> 349</span></a>                    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_inbag</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos"> 350</span></a>                <span class="n">subsample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="o">*</span> \
</span><span id="L-351"><a href="#L-351"><span class="linenos"> 351</span></a>                    <span class="n">sample_mask</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="L-352"><a href="#L-352"><span class="linenos"> 352</span></a>
</span><span id="L-353"><a href="#L-353"><span class="linenos"> 353</span></a>                <span class="c1"># OOB score before adding this stage</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos"> 354</span></a>                <span class="n">y_oob_masked</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">]</span>
</span><span id="L-355"><a href="#L-355"><span class="linenos"> 355</span></a>                <span class="n">sample_weight_oob_masked</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">]</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos"> 356</span></a>                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># store the initial loss to compute the OOB score</span>
</span><span id="L-357"><a href="#L-357"><span class="linenos"> 357</span></a>                    <span class="n">initial_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos"> 358</span></a>                        <span class="n">y_true</span><span class="o">=</span><span class="n">y_oob_masked</span><span class="p">,</span>
</span><span id="L-359"><a href="#L-359"><span class="linenos"> 359</span></a>                        <span class="n">raw_prediction</span><span class="o">=</span><span class="n">y_pred</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-360"><a href="#L-360"><span class="linenos"> 360</span></a>                        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight_oob_masked</span><span class="p">,</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos"> 361</span></a>                    <span class="p">)</span>
</span><span id="L-362"><a href="#L-362"><span class="linenos"> 362</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-363"><a href="#L-363"><span class="linenos"> 363</span></a>                <span class="n">subsample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span>
</span><span id="L-364"><a href="#L-364"><span class="linenos"> 364</span></a>
</span><span id="L-365"><a href="#L-365"><span class="linenos"> 365</span></a>            <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos"> 366</span></a>                <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos"> 367</span></a>
</span><span id="L-368"><a href="#L-368"><span class="linenos"> 368</span></a>            <span class="n">best_learner</span> <span class="o">=</span> <span class="n">_fit_stage_componentwise</span><span class="p">(</span>
</span><span id="L-369"><a href="#L-369"><span class="linenos"> 369</span></a>                <span class="n">X</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">subsample_weight</span><span class="p">)</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos"> 370</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_learner</span>
</span><span id="L-371"><a href="#L-371"><span class="linenos"> 371</span></a>
</span><span id="L-372"><a href="#L-372"><span class="linenos"> 372</span></a>            <span class="k">if</span> <span class="n">do_dropout</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos"> 373</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos"> 374</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos"> 375</span></a>                <span class="n">y_pred</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">best_learner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-376"><a href="#L-376"><span class="linenos"> 376</span></a>
</span><span id="L-377"><a href="#L-377"><span class="linenos"> 377</span></a>            <span class="c1"># track loss</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos"> 378</span></a>            <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="L-379"><a href="#L-379"><span class="linenos"> 379</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="L-380"><a href="#L-380"><span class="linenos"> 380</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos"> 381</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">y_pred</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos"> 382</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-383"><a href="#L-383"><span class="linenos"> 383</span></a>                <span class="p">)</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos"> 384</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos"> 385</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y_oob_masked</span><span class="p">,</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos"> 386</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">y_pred</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-387"><a href="#L-387"><span class="linenos"> 387</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight_oob_masked</span><span class="p">,</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos"> 388</span></a>                <span class="p">)</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos"> 389</span></a>                <span class="n">previous_loss</span> <span class="o">=</span> <span class="n">initial_loss</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos"> 390</span></a>                    <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="L-391"><a href="#L-391"><span class="linenos"> 391</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">previous_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="L-392"><a href="#L-392"><span class="linenos"> 392</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-393"><a href="#L-393"><span class="linenos"> 393</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-394"><a href="#L-394"><span class="linenos"> 394</span></a>                <span class="c1"># no need to fancy index w/ no subsampling</span>
</span><span id="L-395"><a href="#L-395"><span class="linenos"> 395</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos"> 396</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">raw_prediction</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos"> 397</span></a>
</span><span id="L-398"><a href="#L-398"><span class="linenos"> 398</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos"> 399</span></a>                <span class="n">verbose_reporter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
</span><span id="L-400"><a href="#L-400"><span class="linenos"> 400</span></a>
</span><span id="L-401"><a href="#L-401"><span class="linenos"> 401</span></a>        <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="L-402"><a href="#L-402"><span class="linenos"> 402</span></a>
</span><span id="L-403"><a href="#L-403"><span class="linenos"> 403</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos"> 404</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit estimator.</span>
</span><span id="L-405"><a href="#L-405"><span class="linenos"> 405</span></a>
</span><span id="L-406"><a href="#L-406"><span class="linenos"> 406</span></a><span class="sd">        Parameters</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos"> 407</span></a><span class="sd">        ----------</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos"> 408</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="L-409"><a href="#L-409"><span class="linenos"> 409</span></a><span class="sd">            Data matrix</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos"> 410</span></a>
</span><span id="L-411"><a href="#L-411"><span class="linenos"> 411</span></a><span class="sd">        y : structured array, shape = (n_samples,)</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos"> 412</span></a><span class="sd">            A structured array containing the binary event indicator</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos"> 413</span></a><span class="sd">            as first field, and time of event or time of censoring as</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos"> 414</span></a><span class="sd">            second field.</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos"> 415</span></a>
</span><span id="L-416"><a href="#L-416"><span class="linenos"> 416</span></a><span class="sd">        sample_weight : array-like, shape = (n_samples,), optional</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos"> 417</span></a><span class="sd">            Weights given to each sample. If omitted, all samples have weight 1.</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos"> 418</span></a>
</span><span id="L-419"><a href="#L-419"><span class="linenos"> 419</span></a><span class="sd">        Returns</span>
</span><span id="L-420"><a href="#L-420"><span class="linenos"> 420</span></a><span class="sd">        -------</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos"> 421</span></a><span class="sd">        self</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos"> 422</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-423"><a href="#L-423"><span class="linenos"> 423</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>
</span><span id="L-424"><a href="#L-424"><span class="linenos"> 424</span></a>
</span><span id="L-425"><a href="#L-425"><span class="linenos"> 425</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span><span class="p">:</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos"> 426</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_state</span><span class="p">()</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos"> 427</span></a>
</span><span id="L-428"><a href="#L-428"><span class="linenos"> 428</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">ensure_min_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos"> 429</span></a>        <span class="n">event</span><span class="p">,</span> <span class="n">time</span> <span class="o">=</span> <span class="n">check_array_survival</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="L-430"><a href="#L-430"><span class="linenos"> 430</span></a>
</span><span id="L-431"><a href="#L-431"><span class="linenos"> 431</span></a>        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</span><span id="L-432"><a href="#L-432"><span class="linenos"> 432</span></a>
</span><span id="L-433"><a href="#L-433"><span class="linenos"> 433</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-434"><a href="#L-434"><span class="linenos"> 434</span></a>        <span class="n">Xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
</span><span id="L-435"><a href="#L-435"><span class="linenos"> 435</span></a>
</span><span id="L-436"><a href="#L-436"><span class="linenos"> 436</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="n">LOSS_FUNCTIONS</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">]()</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos"> 437</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="p">(</span><span class="n">CensoredSquaredLoss</span><span class="p">,</span> <span class="n">IPCWLeastSquaresError</span><span class="p">)):</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos"> 438</span></a>            <span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
</span><span id="L-439"><a href="#L-439"><span class="linenos"> 439</span></a>
</span><span id="L-440"><a href="#L-440"><span class="linenos"> 440</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_fitted</span><span class="p">():</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos"> 441</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_init_state</span><span class="p">()</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos"> 442</span></a>
</span><span id="L-443"><a href="#L-443"><span class="linenos"> 443</span></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos"> 444</span></a>
</span><span id="L-445"><a href="#L-445"><span class="linenos"> 445</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos"> 446</span></a>
</span><span id="L-447"><a href="#L-447"><span class="linenos"> 447</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos"> 448</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos"> 449</span></a>            <span class="c1"># add more estimators to fitted model</span>
</span><span id="L-450"><a href="#L-450"><span class="linenos"> 450</span></a>            <span class="c1"># invariant: warm_start = True</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos"> 451</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos"> 452</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-453"><a href="#L-453"><span class="linenos"> 453</span></a>                    <span class="s2">&quot;n_estimators=</span><span class="si">%d</span><span class="s2"> must be larger or equal to &quot;</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos"> 454</span></a>                    <span class="s2">&quot;estimators_.shape[0]=</span><span class="si">%d</span><span class="s2"> when &quot;</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos"> 455</span></a>                    <span class="s2">&quot;warm_start==True&quot;</span> <span class="o">%</span> <span class="p">(</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos"> 456</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="L-457"><a href="#L-457"><span class="linenos"> 457</span></a>                <span class="p">)</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos"> 458</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos"> 459</span></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">Xi</span><span class="p">)</span>
</span><span id="L-460"><a href="#L-460"><span class="linenos"> 460</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_resize_state</span><span class="p">()</span>
</span><span id="L-461"><a href="#L-461"><span class="linenos"> 461</span></a>
</span><span id="L-462"><a href="#L-462"><span class="linenos"> 462</span></a>            <span class="c1"># apply dropout to last stage of previous fit</span>
</span><span id="L-463"><a href="#L-463"><span class="linenos"> 463</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos"> 464</span></a>                <span class="c1"># pylint: disable-next=access-member-before-definition</span>
</span><span id="L-465"><a href="#L-465"><span class="linenos"> 465</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos"> 466</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Xi</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">)</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos"> 467</span></a>
</span><span id="L-468"><a href="#L-468"><span class="linenos"> 468</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span>
</span><span id="L-469"><a href="#L-469"><span class="linenos"> 469</span></a>            <span class="n">Xi</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">,</span> <span class="n">begin_at_stage</span><span class="p">)</span>
</span><span id="L-470"><a href="#L-470"><span class="linenos"> 470</span></a>
</span><span id="L-471"><a href="#L-471"><span class="linenos"> 471</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_baseline_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos"> 472</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="L-473"><a href="#L-473"><span class="linenos"> 473</span></a>
</span><span id="L-474"><a href="#L-474"><span class="linenos"> 474</span></a>    <span class="k">def</span> <span class="nf">_set_baseline_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">):</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos"> 475</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="n">CoxPH</span><span class="p">):</span>
</span><span id="L-476"><a href="#L-476"><span class="linenos"> 476</span></a>            <span class="n">risk_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-477"><a href="#L-477"><span class="linenos"> 477</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="o">=</span> <span class="n">BreslowEstimator</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">risk_scores</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</span><span id="L-478"><a href="#L-478"><span class="linenos"> 478</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos"> 479</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-480"><a href="#L-480"><span class="linenos"> 480</span></a>
</span><span id="L-481"><a href="#L-481"><span class="linenos"> 481</span></a>    <span class="k">def</span> <span class="nf">_raw_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos"> 482</span></a>        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="L-483"><a href="#L-483"><span class="linenos"> 483</span></a>        <span class="k">for</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">:</span>
</span><span id="L-484"><a href="#L-484"><span class="linenos"> 484</span></a>            <span class="n">pred</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-485"><a href="#L-485"><span class="linenos"> 485</span></a>        <span class="k">return</span> <span class="n">pred</span>
</span><span id="L-486"><a href="#L-486"><span class="linenos"> 486</span></a>
</span><span id="L-487"><a href="#L-487"><span class="linenos"> 487</span></a>    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-488"><a href="#L-488"><span class="linenos"> 488</span></a>        <span class="c1"># account for intercept</span>
</span><span id="L-489"><a href="#L-489"><span class="linenos"> 489</span></a>        <span class="n">Xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">X</span><span class="p">))</span>
</span><span id="L-490"><a href="#L-490"><span class="linenos"> 490</span></a>        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">Xi</span><span class="p">)</span>
</span><span id="L-491"><a href="#L-491"><span class="linenos"> 491</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">_scale_raw_prediction</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
</span><span id="L-492"><a href="#L-492"><span class="linenos"> 492</span></a>
</span><span id="L-493"><a href="#L-493"><span class="linenos"> 493</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-494"><a href="#L-494"><span class="linenos"> 494</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict risk scores.</span>
</span><span id="L-495"><a href="#L-495"><span class="linenos"> 495</span></a>
</span><span id="L-496"><a href="#L-496"><span class="linenos"> 496</span></a><span class="sd">        If `loss=&#39;coxph&#39;`, predictions can be interpreted as log hazard ratio</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos"> 497</span></a><span class="sd">        corresponding to the linear predictor of a Cox proportional hazards</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos"> 498</span></a><span class="sd">        model. If `loss=&#39;squared&#39;` or `loss=&#39;ipcwls&#39;`, predictions are the</span>
</span><span id="L-499"><a href="#L-499"><span class="linenos"> 499</span></a><span class="sd">        time to event.</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos"> 500</span></a>
</span><span id="L-501"><a href="#L-501"><span class="linenos"> 501</span></a><span class="sd">        Parameters</span>
</span><span id="L-502"><a href="#L-502"><span class="linenos"> 502</span></a><span class="sd">        ----------</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos"> 503</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos"> 504</span></a><span class="sd">            Data matrix.</span>
</span><span id="L-505"><a href="#L-505"><span class="linenos"> 505</span></a>
</span><span id="L-506"><a href="#L-506"><span class="linenos"> 506</span></a><span class="sd">        Returns</span>
</span><span id="L-507"><a href="#L-507"><span class="linenos"> 507</span></a><span class="sd">        -------</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos"> 508</span></a><span class="sd">        risk_score : array, shape = (n_samples,)</span>
</span><span id="L-509"><a href="#L-509"><span class="linenos"> 509</span></a><span class="sd">            Predicted risk scores.</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos"> 510</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos"> 511</span></a>        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">)</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos"> 512</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos"> 513</span></a>
</span><span id="L-514"><a href="#L-514"><span class="linenos"> 514</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos"> 515</span></a>
</span><span id="L-516"><a href="#L-516"><span class="linenos"> 516</span></a>    <span class="k">def</span> <span class="nf">_get_baseline_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-517"><a href="#L-517"><span class="linenos"> 517</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos"> 518</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos"> 519</span></a>                <span class="s2">&quot;`fit` must be called with the loss option set to &#39;coxph&#39;.&quot;</span><span class="p">)</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos"> 520</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos"> 521</span></a>
</span><span id="L-522"><a href="#L-522"><span class="linenos"> 522</span></a>    <span class="k">def</span> <span class="nf">predict_cumulative_hazard_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos"> 523</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict cumulative hazard function.</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos"> 524</span></a>
</span><span id="L-525"><a href="#L-525"><span class="linenos"> 525</span></a><span class="sd">        Only available if :meth:`fit` has been called with `loss = &quot;coxph&quot;`.</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos"> 526</span></a>
</span><span id="L-527"><a href="#L-527"><span class="linenos"> 527</span></a><span class="sd">        The cumulative hazard function for an individual</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos"> 528</span></a><span class="sd">        with feature vector :math:`x` is defined as</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos"> 529</span></a>
</span><span id="L-530"><a href="#L-530"><span class="linenos"> 530</span></a><span class="sd">        .. math::</span>
</span><span id="L-531"><a href="#L-531"><span class="linenos"> 531</span></a>
</span><span id="L-532"><a href="#L-532"><span class="linenos"> 532</span></a><span class="sd">            H(t \\mid x) = \\exp(f(x)) H_0(t) ,</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos"> 533</span></a>
</span><span id="L-534"><a href="#L-534"><span class="linenos"> 534</span></a><span class="sd">        where :math:`f(\\cdot)` is the additive ensemble of base learners,</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos"> 535</span></a><span class="sd">        and :math:`H_0(t)` is the baseline hazard function,</span>
</span><span id="L-536"><a href="#L-536"><span class="linenos"> 536</span></a><span class="sd">        estimated by Breslow&#39;s estimator.</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos"> 537</span></a>
</span><span id="L-538"><a href="#L-538"><span class="linenos"> 538</span></a><span class="sd">        Parameters</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos"> 539</span></a><span class="sd">        ----------</span>
</span><span id="L-540"><a href="#L-540"><span class="linenos"> 540</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos"> 541</span></a><span class="sd">            Data matrix.</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos"> 542</span></a>
</span><span id="L-543"><a href="#L-543"><span class="linenos"> 543</span></a><span class="sd">        return_array : boolean, default: False</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos"> 544</span></a><span class="sd">            If set, return an array with the cumulative hazard rate</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos"> 545</span></a><span class="sd">            for each `self.unique_times_`, otherwise an array of</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos"> 546</span></a><span class="sd">            :class:`survivalist.functions.StepFunction`.</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos"> 547</span></a>
</span><span id="L-548"><a href="#L-548"><span class="linenos"> 548</span></a><span class="sd">        Returns</span>
</span><span id="L-549"><a href="#L-549"><span class="linenos"> 549</span></a><span class="sd">        -------</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos"> 550</span></a><span class="sd">        cum_hazard : ndarray</span>
</span><span id="L-551"><a href="#L-551"><span class="linenos"> 551</span></a><span class="sd">            If `return_array` is set, an array with the cumulative hazard rate</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos"> 552</span></a><span class="sd">            for each `self.unique_times_`, otherwise an array of length `n_samples`</span>
</span><span id="L-553"><a href="#L-553"><span class="linenos"> 553</span></a><span class="sd">            of :class:`survivalist.functions.StepFunction` instances will be returned.</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos"> 554</span></a>
</span><span id="L-555"><a href="#L-555"><span class="linenos"> 555</span></a><span class="sd">        Examples</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos"> 556</span></a><span class="sd">        --------</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos"> 557</span></a><span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos"> 558</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.datasets import load_whas500</span>
</span><span id="L-559"><a href="#L-559"><span class="linenos"> 559</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos"> 560</span></a>
</span><span id="L-561"><a href="#L-561"><span class="linenos"> 561</span></a><span class="sd">        Load the data.</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos"> 562</span></a>
</span><span id="L-563"><a href="#L-563"><span class="linenos"> 563</span></a><span class="sd">        &gt;&gt;&gt; X, y = load_whas500()</span>
</span><span id="L-564"><a href="#L-564"><span class="linenos"> 564</span></a><span class="sd">        &gt;&gt;&gt; X = X.astype(float)</span>
</span><span id="L-565"><a href="#L-565"><span class="linenos"> 565</span></a>
</span><span id="L-566"><a href="#L-566"><span class="linenos"> 566</span></a><span class="sd">        Fit the model.</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos"> 567</span></a>
</span><span id="L-568"><a href="#L-568"><span class="linenos"> 568</span></a><span class="sd">        &gt;&gt;&gt; estimator = ComponentwiseGradientBoostingSurvivalAnalysis(loss=&quot;coxph&quot;).fit(X, y)</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos"> 569</span></a>
</span><span id="L-570"><a href="#L-570"><span class="linenos"> 570</span></a><span class="sd">        Estimate the cumulative hazard function for the first 10 samples.</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos"> 571</span></a>
</span><span id="L-572"><a href="#L-572"><span class="linenos"> 572</span></a><span class="sd">        &gt;&gt;&gt; chf_funcs = estimator.predict_cumulative_hazard_function(X.iloc[:10])</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos"> 573</span></a>
</span><span id="L-574"><a href="#L-574"><span class="linenos"> 574</span></a><span class="sd">        Plot the estimated cumulative hazard functions.</span>
</span><span id="L-575"><a href="#L-575"><span class="linenos"> 575</span></a>
</span><span id="L-576"><a href="#L-576"><span class="linenos"> 576</span></a><span class="sd">        &gt;&gt;&gt; for fn in chf_funcs:</span>
</span><span id="L-577"><a href="#L-577"><span class="linenos"> 577</span></a><span class="sd">        ...     plt.step(fn.x, fn(fn.x), where=&quot;post&quot;)</span>
</span><span id="L-578"><a href="#L-578"><span class="linenos"> 578</span></a><span class="sd">        ...</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos"> 579</span></a><span class="sd">        &gt;&gt;&gt; plt.ylim(0, 1)</span>
</span><span id="L-580"><a href="#L-580"><span class="linenos"> 580</span></a><span class="sd">        &gt;&gt;&gt; plt.show()</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos"> 581</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-582"><a href="#L-582"><span class="linenos"> 582</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_cumulative_hazard_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">return_array</span><span class="p">)</span>
</span><span id="L-583"><a href="#L-583"><span class="linenos"> 583</span></a>
</span><span id="L-584"><a href="#L-584"><span class="linenos"> 584</span></a>    <span class="k">def</span> <span class="nf">predict_survival_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos"> 585</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict survival function.</span>
</span><span id="L-586"><a href="#L-586"><span class="linenos"> 586</span></a>
</span><span id="L-587"><a href="#L-587"><span class="linenos"> 587</span></a><span class="sd">        Only available if :meth:`fit` has been called with `loss = &quot;coxph&quot;`.</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos"> 588</span></a>
</span><span id="L-589"><a href="#L-589"><span class="linenos"> 589</span></a><span class="sd">        The survival function for an individual</span>
</span><span id="L-590"><a href="#L-590"><span class="linenos"> 590</span></a><span class="sd">        with feature vector :math:`x` is defined as</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos"> 591</span></a>
</span><span id="L-592"><a href="#L-592"><span class="linenos"> 592</span></a><span class="sd">        .. math::</span>
</span><span id="L-593"><a href="#L-593"><span class="linenos"> 593</span></a>
</span><span id="L-594"><a href="#L-594"><span class="linenos"> 594</span></a><span class="sd">            S(t \\mid x) = S_0(t)^{\\exp(f(x)} ,</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos"> 595</span></a>
</span><span id="L-596"><a href="#L-596"><span class="linenos"> 596</span></a><span class="sd">        where :math:`f(\\cdot)` is the additive ensemble of base learners,</span>
</span><span id="L-597"><a href="#L-597"><span class="linenos"> 597</span></a><span class="sd">        and :math:`S_0(t)` is the baseline survival function,</span>
</span><span id="L-598"><a href="#L-598"><span class="linenos"> 598</span></a><span class="sd">        estimated by Breslow&#39;s estimator.</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos"> 599</span></a>
</span><span id="L-600"><a href="#L-600"><span class="linenos"> 600</span></a><span class="sd">        Parameters</span>
</span><span id="L-601"><a href="#L-601"><span class="linenos"> 601</span></a><span class="sd">        ----------</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos"> 602</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="L-603"><a href="#L-603"><span class="linenos"> 603</span></a><span class="sd">            Data matrix.</span>
</span><span id="L-604"><a href="#L-604"><span class="linenos"> 604</span></a>
</span><span id="L-605"><a href="#L-605"><span class="linenos"> 605</span></a><span class="sd">        return_array : boolean, default: False</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos"> 606</span></a><span class="sd">            If set, return an array with the probability</span>
</span><span id="L-607"><a href="#L-607"><span class="linenos"> 607</span></a><span class="sd">            of survival for each `self.unique_times_`,</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos"> 608</span></a><span class="sd">            otherwise an array of :class:`survivalist.functions.StepFunction`.</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos"> 609</span></a>
</span><span id="L-610"><a href="#L-610"><span class="linenos"> 610</span></a><span class="sd">        Returns</span>
</span><span id="L-611"><a href="#L-611"><span class="linenos"> 611</span></a><span class="sd">        -------</span>
</span><span id="L-612"><a href="#L-612"><span class="linenos"> 612</span></a><span class="sd">        survival : ndarray</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos"> 613</span></a><span class="sd">            If `return_array` is set, an array with the probability of</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos"> 614</span></a><span class="sd">            survival for each `self.unique_times_`, otherwise an array of</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos"> 615</span></a><span class="sd">            length `n_samples` of :class:`survivalist.functions.StepFunction`</span>
</span><span id="L-616"><a href="#L-616"><span class="linenos"> 616</span></a><span class="sd">            instances will be returned.</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos"> 617</span></a>
</span><span id="L-618"><a href="#L-618"><span class="linenos"> 618</span></a><span class="sd">        Examples</span>
</span><span id="L-619"><a href="#L-619"><span class="linenos"> 619</span></a><span class="sd">        --------</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos"> 620</span></a><span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos"> 621</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.datasets import load_whas500</span>
</span><span id="L-622"><a href="#L-622"><span class="linenos"> 622</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis</span>
</span><span id="L-623"><a href="#L-623"><span class="linenos"> 623</span></a>
</span><span id="L-624"><a href="#L-624"><span class="linenos"> 624</span></a><span class="sd">        Load the data.</span>
</span><span id="L-625"><a href="#L-625"><span class="linenos"> 625</span></a>
</span><span id="L-626"><a href="#L-626"><span class="linenos"> 626</span></a><span class="sd">        &gt;&gt;&gt; X, y = load_whas500()</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos"> 627</span></a><span class="sd">        &gt;&gt;&gt; X = X.astype(float)</span>
</span><span id="L-628"><a href="#L-628"><span class="linenos"> 628</span></a>
</span><span id="L-629"><a href="#L-629"><span class="linenos"> 629</span></a><span class="sd">        Fit the model.</span>
</span><span id="L-630"><a href="#L-630"><span class="linenos"> 630</span></a>
</span><span id="L-631"><a href="#L-631"><span class="linenos"> 631</span></a><span class="sd">        &gt;&gt;&gt; estimator = ComponentwiseGradientBoostingSurvivalAnalysis(loss=&quot;coxph&quot;).fit(X, y)</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos"> 632</span></a>
</span><span id="L-633"><a href="#L-633"><span class="linenos"> 633</span></a><span class="sd">        Estimate the survival function for the first 10 samples.</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos"> 634</span></a>
</span><span id="L-635"><a href="#L-635"><span class="linenos"> 635</span></a><span class="sd">        &gt;&gt;&gt; surv_funcs = estimator.predict_survival_function(X.iloc[:10])</span>
</span><span id="L-636"><a href="#L-636"><span class="linenos"> 636</span></a>
</span><span id="L-637"><a href="#L-637"><span class="linenos"> 637</span></a><span class="sd">        Plot the estimated survival functions.</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos"> 638</span></a>
</span><span id="L-639"><a href="#L-639"><span class="linenos"> 639</span></a><span class="sd">        &gt;&gt;&gt; for fn in surv_funcs:</span>
</span><span id="L-640"><a href="#L-640"><span class="linenos"> 640</span></a><span class="sd">        ...     plt.step(fn.x, fn(fn.x), where=&quot;post&quot;)</span>
</span><span id="L-641"><a href="#L-641"><span class="linenos"> 641</span></a><span class="sd">        ...</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos"> 642</span></a><span class="sd">        &gt;&gt;&gt; plt.ylim(0, 1)</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos"> 643</span></a><span class="sd">        &gt;&gt;&gt; plt.show()</span>
</span><span id="L-644"><a href="#L-644"><span class="linenos"> 644</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos"> 645</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_survival_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">return_array</span><span class="p">)</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos"> 646</span></a>
</span><span id="L-647"><a href="#L-647"><span class="linenos"> 647</span></a>    <span class="nd">@property</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos"> 648</span></a>    <span class="k">def</span> <span class="nf">coef_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-649"><a href="#L-649"><span class="linenos"> 649</span></a>        <span class="n">coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="L-650"><a href="#L-650"><span class="linenos"> 650</span></a>
</span><span id="L-651"><a href="#L-651"><span class="linenos"> 651</span></a>        <span class="k">for</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">:</span>
</span><span id="L-652"><a href="#L-652"><span class="linenos"> 652</span></a>            <span class="n">coef</span><span class="p">[</span><span class="n">estimator</span><span class="o">.</span><span class="n">component</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span>
</span><span id="L-653"><a href="#L-653"><span class="linenos"> 653</span></a>
</span><span id="L-654"><a href="#L-654"><span class="linenos"> 654</span></a>        <span class="k">return</span> <span class="n">coef</span>
</span><span id="L-655"><a href="#L-655"><span class="linenos"> 655</span></a>
</span><span id="L-656"><a href="#L-656"><span class="linenos"> 656</span></a>    <span class="nd">@property</span>
</span><span id="L-657"><a href="#L-657"><span class="linenos"> 657</span></a>    <span class="k">def</span> <span class="nf">unique_times_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-658"><a href="#L-658"><span class="linenos"> 658</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">()</span><span class="o">.</span><span class="n">unique_times_</span>
</span><span id="L-659"><a href="#L-659"><span class="linenos"> 659</span></a>
</span><span id="L-660"><a href="#L-660"><span class="linenos"> 660</span></a>    <span class="nd">@property</span>
</span><span id="L-661"><a href="#L-661"><span class="linenos"> 661</span></a>    <span class="k">def</span> <span class="nf">feature_importances_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-662"><a href="#L-662"><span class="linenos"> 662</span></a>        <span class="n">imp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</span><span id="L-663"><a href="#L-663"><span class="linenos"> 663</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">imp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
</span><span id="L-664"><a href="#L-664"><span class="linenos"> 664</span></a>            <span class="n">imp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-665"><a href="#L-665"><span class="linenos"> 665</span></a>
</span><span id="L-666"><a href="#L-666"><span class="linenos"> 666</span></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">):</span>
</span><span id="L-667"><a href="#L-667"><span class="linenos"> 667</span></a>            <span class="n">imp</span><span class="p">[</span><span class="n">estimator</span><span class="o">.</span><span class="n">component</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-668"><a href="#L-668"><span class="linenos"> 668</span></a>
</span><span id="L-669"><a href="#L-669"><span class="linenos"> 669</span></a>        <span class="k">def</span> <span class="nf">_importance</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span id="L-670"><a href="#L-670"><span class="linenos"> 670</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-671"><a href="#L-671"><span class="linenos"> 671</span></a>                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-672"><a href="#L-672"><span class="linenos"> 672</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</span><span id="L-673"><a href="#L-673"><span class="linenos"> 673</span></a>
</span><span id="L-674"><a href="#L-674"><span class="linenos"> 674</span></a>        <span class="n">ret</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">_importance</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">imp</span><span class="p">])</span>
</span><span id="L-675"><a href="#L-675"><span class="linenos"> 675</span></a>        <span class="k">return</span> <span class="n">ret</span>
</span><span id="L-676"><a href="#L-676"><span class="linenos"> 676</span></a>
</span><span id="L-677"><a href="#L-677"><span class="linenos"> 677</span></a>    <span class="k">def</span> <span class="nf">_make_estimator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-678"><a href="#L-678"><span class="linenos"> 678</span></a>        <span class="c1"># we don&#39;t need _make_estimator</span>
</span><span id="L-679"><a href="#L-679"><span class="linenos"> 679</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</span><span id="L-680"><a href="#L-680"><span class="linenos"> 680</span></a>
</span><span id="L-681"><a href="#L-681"><span class="linenos"> 681</span></a>
</span><span id="L-682"><a href="#L-682"><span class="linenos"> 682</span></a><span class="k">class</span> <span class="nc">GradientBoostingSurvivalAnalysis</span><span class="p">(</span><span class="n">BaseGradientBoosting</span><span class="p">,</span> <span class="n">SurvivalAnalysisMixin</span><span class="p">):</span>
</span><span id="L-683"><a href="#L-683"><span class="linenos"> 683</span></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gradient-boosted Cox proportional hazard loss with</span>
</span><span id="L-684"><a href="#L-684"><span class="linenos"> 684</span></a><span class="sd">    regression trees as base learner.</span>
</span><span id="L-685"><a href="#L-685"><span class="linenos"> 685</span></a>
</span><span id="L-686"><a href="#L-686"><span class="linenos"> 686</span></a><span class="sd">    In each stage, a regression tree is fit on the negative gradient</span>
</span><span id="L-687"><a href="#L-687"><span class="linenos"> 687</span></a><span class="sd">    of the loss function.</span>
</span><span id="L-688"><a href="#L-688"><span class="linenos"> 688</span></a>
</span><span id="L-689"><a href="#L-689"><span class="linenos"> 689</span></a><span class="sd">    For more details on gradient boosting see [1]_ and [2]_. If `loss=&#39;coxph&#39;`,</span>
</span><span id="L-690"><a href="#L-690"><span class="linenos"> 690</span></a><span class="sd">    the partial likelihood of the proportional hazards model is optimized as</span>
</span><span id="L-691"><a href="#L-691"><span class="linenos"> 691</span></a><span class="sd">    described in [3]_. If `loss=&#39;ipcwls&#39;`, the accelerated failure time model with</span>
</span><span id="L-692"><a href="#L-692"><span class="linenos"> 692</span></a><span class="sd">    inverse-probability of censoring weighted least squares error is optimized as</span>
</span><span id="L-693"><a href="#L-693"><span class="linenos"> 693</span></a><span class="sd">    described in [4]_. When using a non-zero `dropout_rate`, regularization is</span>
</span><span id="L-694"><a href="#L-694"><span class="linenos"> 694</span></a><span class="sd">    applied during training following [5]_.</span>
</span><span id="L-695"><a href="#L-695"><span class="linenos"> 695</span></a>
</span><span id="L-696"><a href="#L-696"><span class="linenos"> 696</span></a><span class="sd">    See the :ref:`User Guide &lt;/user_guide/boosting.ipynb&gt;` for examples.</span>
</span><span id="L-697"><a href="#L-697"><span class="linenos"> 697</span></a>
</span><span id="L-698"><a href="#L-698"><span class="linenos"> 698</span></a><span class="sd">    Parameters</span>
</span><span id="L-699"><a href="#L-699"><span class="linenos"> 699</span></a><span class="sd">    ----------</span>
</span><span id="L-700"><a href="#L-700"><span class="linenos"> 700</span></a><span class="sd">    loss : {&#39;coxph&#39;, &#39;squared&#39;, &#39;ipcwls&#39;}, optional, default: &#39;coxph&#39;</span>
</span><span id="L-701"><a href="#L-701"><span class="linenos"> 701</span></a><span class="sd">        loss function to be optimized. &#39;coxph&#39; refers to partial likelihood loss</span>
</span><span id="L-702"><a href="#L-702"><span class="linenos"> 702</span></a><span class="sd">        of Cox&#39;s proportional hazards model. The loss &#39;squared&#39; minimizes a</span>
</span><span id="L-703"><a href="#L-703"><span class="linenos"> 703</span></a><span class="sd">        squared regression loss that ignores predictions beyond the time of censoring,</span>
</span><span id="L-704"><a href="#L-704"><span class="linenos"> 704</span></a><span class="sd">        and &#39;ipcwls&#39; refers to inverse-probability of censoring weighted least squares error.</span>
</span><span id="L-705"><a href="#L-705"><span class="linenos"> 705</span></a>
</span><span id="L-706"><a href="#L-706"><span class="linenos"> 706</span></a><span class="sd">    learning_rate : float, optional, default: 0.1</span>
</span><span id="L-707"><a href="#L-707"><span class="linenos"> 707</span></a><span class="sd">        learning rate shrinks the contribution of each tree by `learning_rate`.</span>
</span><span id="L-708"><a href="#L-708"><span class="linenos"> 708</span></a><span class="sd">        There is a trade-off between `learning_rate` and `n_estimators`.</span>
</span><span id="L-709"><a href="#L-709"><span class="linenos"> 709</span></a><span class="sd">        Values must be in the range `[0.0, inf)`.</span>
</span><span id="L-710"><a href="#L-710"><span class="linenos"> 710</span></a>
</span><span id="L-711"><a href="#L-711"><span class="linenos"> 711</span></a><span class="sd">    n_estimators : int, default: 100</span>
</span><span id="L-712"><a href="#L-712"><span class="linenos"> 712</span></a><span class="sd">        The number of regression trees to create. Gradient boosting</span>
</span><span id="L-713"><a href="#L-713"><span class="linenos"> 713</span></a><span class="sd">        is fairly robust to over-fitting so a large number usually</span>
</span><span id="L-714"><a href="#L-714"><span class="linenos"> 714</span></a><span class="sd">        results in better performance.</span>
</span><span id="L-715"><a href="#L-715"><span class="linenos"> 715</span></a><span class="sd">        Values must be in the range `[1, inf)`.</span>
</span><span id="L-716"><a href="#L-716"><span class="linenos"> 716</span></a>
</span><span id="L-717"><a href="#L-717"><span class="linenos"> 717</span></a><span class="sd">    subsample : float, optional, default: 1.0</span>
</span><span id="L-718"><a href="#L-718"><span class="linenos"> 718</span></a><span class="sd">        The fraction of samples to be used for fitting the individual base</span>
</span><span id="L-719"><a href="#L-719"><span class="linenos"> 719</span></a><span class="sd">        learners. If smaller than 1.0 this results in Stochastic Gradient</span>
</span><span id="L-720"><a href="#L-720"><span class="linenos"> 720</span></a><span class="sd">        Boosting. `subsample` interacts with the parameter `n_estimators`.</span>
</span><span id="L-721"><a href="#L-721"><span class="linenos"> 721</span></a><span class="sd">        Choosing `subsample &lt; 1.0` leads to a reduction of variance</span>
</span><span id="L-722"><a href="#L-722"><span class="linenos"> 722</span></a><span class="sd">        and an increase in bias.</span>
</span><span id="L-723"><a href="#L-723"><span class="linenos"> 723</span></a><span class="sd">        Values must be in the range `(0.0, 1.0]`.</span>
</span><span id="L-724"><a href="#L-724"><span class="linenos"> 724</span></a>
</span><span id="L-725"><a href="#L-725"><span class="linenos"> 725</span></a><span class="sd">    criterion : {&#39;friedman_mse&#39;, &#39;squared_error&#39;}, default: &#39;friedman_mse&#39;</span>
</span><span id="L-726"><a href="#L-726"><span class="linenos"> 726</span></a><span class="sd">        The function to measure the quality of a split. Supported criteria are</span>
</span><span id="L-727"><a href="#L-727"><span class="linenos"> 727</span></a><span class="sd">        &#39;friedman_mse&#39; for the mean squared error with improvement score by</span>
</span><span id="L-728"><a href="#L-728"><span class="linenos"> 728</span></a><span class="sd">        Friedman, &#39;squared_error&#39; for mean squared error. The default value of</span>
</span><span id="L-729"><a href="#L-729"><span class="linenos"> 729</span></a><span class="sd">        &#39;friedman_mse&#39; is generally the best as it can provide a better</span>
</span><span id="L-730"><a href="#L-730"><span class="linenos"> 730</span></a><span class="sd">        approximation in some cases.</span>
</span><span id="L-731"><a href="#L-731"><span class="linenos"> 731</span></a>
</span><span id="L-732"><a href="#L-732"><span class="linenos"> 732</span></a><span class="sd">    min_samples_split : int or float, optional, default: 2</span>
</span><span id="L-733"><a href="#L-733"><span class="linenos"> 733</span></a><span class="sd">        The minimum number of samples required to split an internal node:</span>
</span><span id="L-734"><a href="#L-734"><span class="linenos"> 734</span></a>
</span><span id="L-735"><a href="#L-735"><span class="linenos"> 735</span></a><span class="sd">        - If int, values must be in the range `[2, inf)`.</span>
</span><span id="L-736"><a href="#L-736"><span class="linenos"> 736</span></a><span class="sd">        - If float, values must be in the range `(0.0, 1.0]` and `min_samples_split`</span>
</span><span id="L-737"><a href="#L-737"><span class="linenos"> 737</span></a><span class="sd">          will be `ceil(min_samples_split * n_samples)`.</span>
</span><span id="L-738"><a href="#L-738"><span class="linenos"> 738</span></a>
</span><span id="L-739"><a href="#L-739"><span class="linenos"> 739</span></a><span class="sd">    min_samples_leaf : int or float, default: 1</span>
</span><span id="L-740"><a href="#L-740"><span class="linenos"> 740</span></a><span class="sd">        The minimum number of samples required to be at a leaf node.</span>
</span><span id="L-741"><a href="#L-741"><span class="linenos"> 741</span></a><span class="sd">        A split point at any depth will only be considered if it leaves at</span>
</span><span id="L-742"><a href="#L-742"><span class="linenos"> 742</span></a><span class="sd">        least ``min_samples_leaf`` training samples in each of the left and</span>
</span><span id="L-743"><a href="#L-743"><span class="linenos"> 743</span></a><span class="sd">        right branches.  This may have the effect of smoothing the model,</span>
</span><span id="L-744"><a href="#L-744"><span class="linenos"> 744</span></a><span class="sd">        especially in regression.</span>
</span><span id="L-745"><a href="#L-745"><span class="linenos"> 745</span></a>
</span><span id="L-746"><a href="#L-746"><span class="linenos"> 746</span></a><span class="sd">        - If int, values must be in the range `[1, inf)`.</span>
</span><span id="L-747"><a href="#L-747"><span class="linenos"> 747</span></a><span class="sd">        - If float, values must be in the range `(0.0, 1.0)` and `min_samples_leaf`</span>
</span><span id="L-748"><a href="#L-748"><span class="linenos"> 748</span></a><span class="sd">          will be `ceil(min_samples_leaf * n_samples)`.</span>
</span><span id="L-749"><a href="#L-749"><span class="linenos"> 749</span></a>
</span><span id="L-750"><a href="#L-750"><span class="linenos"> 750</span></a><span class="sd">    min_weight_fraction_leaf : float, optional, default: 0.</span>
</span><span id="L-751"><a href="#L-751"><span class="linenos"> 751</span></a><span class="sd">        The minimum weighted fraction of the sum total of weights (of all</span>
</span><span id="L-752"><a href="#L-752"><span class="linenos"> 752</span></a><span class="sd">        the input samples) required to be at a leaf node. Samples have</span>
</span><span id="L-753"><a href="#L-753"><span class="linenos"> 753</span></a><span class="sd">        equal weight when `sample_weight` is not provided.</span>
</span><span id="L-754"><a href="#L-754"><span class="linenos"> 754</span></a><span class="sd">        Values must be in the range `[0.0, 0.5]`.</span>
</span><span id="L-755"><a href="#L-755"><span class="linenos"> 755</span></a>
</span><span id="L-756"><a href="#L-756"><span class="linenos"> 756</span></a><span class="sd">    max_depth : int or None, optional, default: 3</span>
</span><span id="L-757"><a href="#L-757"><span class="linenos"> 757</span></a><span class="sd">        Maximum depth of the individual regression estimators. The maximum</span>
</span><span id="L-758"><a href="#L-758"><span class="linenos"> 758</span></a><span class="sd">        depth limits the number of nodes in the tree. Tune this parameter</span>
</span><span id="L-759"><a href="#L-759"><span class="linenos"> 759</span></a><span class="sd">        for best performance; the best value depends on the interaction</span>
</span><span id="L-760"><a href="#L-760"><span class="linenos"> 760</span></a><span class="sd">        of the input variables. If None, then nodes are expanded until</span>
</span><span id="L-761"><a href="#L-761"><span class="linenos"> 761</span></a><span class="sd">        all leaves are pure or until all leaves contain less than</span>
</span><span id="L-762"><a href="#L-762"><span class="linenos"> 762</span></a><span class="sd">        `min_samples_split` samples.</span>
</span><span id="L-763"><a href="#L-763"><span class="linenos"> 763</span></a><span class="sd">        If int, values must be in the range `[1, inf)`.</span>
</span><span id="L-764"><a href="#L-764"><span class="linenos"> 764</span></a>
</span><span id="L-765"><a href="#L-765"><span class="linenos"> 765</span></a><span class="sd">    min_impurity_decrease : float, optional, default: 0.</span>
</span><span id="L-766"><a href="#L-766"><span class="linenos"> 766</span></a><span class="sd">        A node will be split if this split induces a decrease of the impurity</span>
</span><span id="L-767"><a href="#L-767"><span class="linenos"> 767</span></a><span class="sd">        greater than or equal to this value.</span>
</span><span id="L-768"><a href="#L-768"><span class="linenos"> 768</span></a>
</span><span id="L-769"><a href="#L-769"><span class="linenos"> 769</span></a><span class="sd">        The weighted impurity decrease equation is the following::</span>
</span><span id="L-770"><a href="#L-770"><span class="linenos"> 770</span></a>
</span><span id="L-771"><a href="#L-771"><span class="linenos"> 771</span></a><span class="sd">            N_t / N * (impurity - N_t_R / N_t * right_impurity</span>
</span><span id="L-772"><a href="#L-772"><span class="linenos"> 772</span></a><span class="sd">                                - N_t_L / N_t * left_impurity)</span>
</span><span id="L-773"><a href="#L-773"><span class="linenos"> 773</span></a>
</span><span id="L-774"><a href="#L-774"><span class="linenos"> 774</span></a><span class="sd">        where ``N`` is the total number of samples, ``N_t`` is the number of</span>
</span><span id="L-775"><a href="#L-775"><span class="linenos"> 775</span></a><span class="sd">        samples at the current node, ``N_t_L`` is the number of samples in the</span>
</span><span id="L-776"><a href="#L-776"><span class="linenos"> 776</span></a><span class="sd">        left child, and ``N_t_R`` is the number of samples in the right child.</span>
</span><span id="L-777"><a href="#L-777"><span class="linenos"> 777</span></a>
</span><span id="L-778"><a href="#L-778"><span class="linenos"> 778</span></a><span class="sd">        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,</span>
</span><span id="L-779"><a href="#L-779"><span class="linenos"> 779</span></a><span class="sd">        if ``sample_weight`` is passed.</span>
</span><span id="L-780"><a href="#L-780"><span class="linenos"> 780</span></a>
</span><span id="L-781"><a href="#L-781"><span class="linenos"> 781</span></a><span class="sd">    random_state : int seed, RandomState instance, or None, default: None</span>
</span><span id="L-782"><a href="#L-782"><span class="linenos"> 782</span></a><span class="sd">        Controls the random seed given to each Tree estimator at each</span>
</span><span id="L-783"><a href="#L-783"><span class="linenos"> 783</span></a><span class="sd">        boosting iteration.</span>
</span><span id="L-784"><a href="#L-784"><span class="linenos"> 784</span></a><span class="sd">        In addition, it controls the random permutation of the features at</span>
</span><span id="L-785"><a href="#L-785"><span class="linenos"> 785</span></a><span class="sd">        each split.</span>
</span><span id="L-786"><a href="#L-786"><span class="linenos"> 786</span></a><span class="sd">        It also controls the random splitting of the training data to obtain a</span>
</span><span id="L-787"><a href="#L-787"><span class="linenos"> 787</span></a><span class="sd">        validation set if `n_iter_no_change` is not None.</span>
</span><span id="L-788"><a href="#L-788"><span class="linenos"> 788</span></a><span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
</span><span id="L-789"><a href="#L-789"><span class="linenos"> 789</span></a>
</span><span id="L-790"><a href="#L-790"><span class="linenos"> 790</span></a><span class="sd">    max_features : int, float, string or None, optional, default: None</span>
</span><span id="L-791"><a href="#L-791"><span class="linenos"> 791</span></a><span class="sd">        The number of features to consider when looking for the best split:</span>
</span><span id="L-792"><a href="#L-792"><span class="linenos"> 792</span></a>
</span><span id="L-793"><a href="#L-793"><span class="linenos"> 793</span></a><span class="sd">        - If int, values must be in the range `[1, inf)`.</span>
</span><span id="L-794"><a href="#L-794"><span class="linenos"> 794</span></a><span class="sd">        - If float, values must be in the range `(0.0, 1.0]` and the features</span>
</span><span id="L-795"><a href="#L-795"><span class="linenos"> 795</span></a><span class="sd">          considered at each split will be `max(1, int(max_features * n_features_in_))`.</span>
</span><span id="L-796"><a href="#L-796"><span class="linenos"> 796</span></a><span class="sd">        - If &#39;sqrt&#39;, then `max_features=sqrt(n_features)`.</span>
</span><span id="L-797"><a href="#L-797"><span class="linenos"> 797</span></a><span class="sd">        - If &#39;log2&#39;, then `max_features=log2(n_features)`.</span>
</span><span id="L-798"><a href="#L-798"><span class="linenos"> 798</span></a><span class="sd">        - If None, then `max_features=n_features`.</span>
</span><span id="L-799"><a href="#L-799"><span class="linenos"> 799</span></a>
</span><span id="L-800"><a href="#L-800"><span class="linenos"> 800</span></a><span class="sd">        Choosing `max_features &lt; n_features` leads to a reduction of variance</span>
</span><span id="L-801"><a href="#L-801"><span class="linenos"> 801</span></a><span class="sd">        and an increase in bias.</span>
</span><span id="L-802"><a href="#L-802"><span class="linenos"> 802</span></a>
</span><span id="L-803"><a href="#L-803"><span class="linenos"> 803</span></a><span class="sd">        Note: the search for a split does not stop until at least one</span>
</span><span id="L-804"><a href="#L-804"><span class="linenos"> 804</span></a><span class="sd">        valid partition of the node samples is found, even if it requires to</span>
</span><span id="L-805"><a href="#L-805"><span class="linenos"> 805</span></a><span class="sd">        effectively inspect more than ``max_features`` features.</span>
</span><span id="L-806"><a href="#L-806"><span class="linenos"> 806</span></a>
</span><span id="L-807"><a href="#L-807"><span class="linenos"> 807</span></a><span class="sd">    max_leaf_nodes : int or None, optional, default: None</span>
</span><span id="L-808"><a href="#L-808"><span class="linenos"> 808</span></a><span class="sd">        Grow trees with ``max_leaf_nodes`` in best-first fashion.</span>
</span><span id="L-809"><a href="#L-809"><span class="linenos"> 809</span></a><span class="sd">        Best nodes are defined as relative reduction in impurity.</span>
</span><span id="L-810"><a href="#L-810"><span class="linenos"> 810</span></a><span class="sd">        Values must be in the range `[2, inf)`.</span>
</span><span id="L-811"><a href="#L-811"><span class="linenos"> 811</span></a><span class="sd">        If `None`, then unlimited number of leaf nodes.</span>
</span><span id="L-812"><a href="#L-812"><span class="linenos"> 812</span></a>
</span><span id="L-813"><a href="#L-813"><span class="linenos"> 813</span></a><span class="sd">    warm_start : bool, default: False</span>
</span><span id="L-814"><a href="#L-814"><span class="linenos"> 814</span></a><span class="sd">        When set to ``True``, reuse the solution of the previous call to fit</span>
</span><span id="L-815"><a href="#L-815"><span class="linenos"> 815</span></a><span class="sd">        and add more estimators to the ensemble, otherwise, just erase the</span>
</span><span id="L-816"><a href="#L-816"><span class="linenos"> 816</span></a><span class="sd">        previous solution.</span>
</span><span id="L-817"><a href="#L-817"><span class="linenos"> 817</span></a>
</span><span id="L-818"><a href="#L-818"><span class="linenos"> 818</span></a><span class="sd">    validation_fraction : float, default: 0.1</span>
</span><span id="L-819"><a href="#L-819"><span class="linenos"> 819</span></a><span class="sd">        The proportion of training data to set aside as validation set for</span>
</span><span id="L-820"><a href="#L-820"><span class="linenos"> 820</span></a><span class="sd">        early stopping. Values must be in the range `(0.0, 1.0)`.</span>
</span><span id="L-821"><a href="#L-821"><span class="linenos"> 821</span></a><span class="sd">        Only used if ``n_iter_no_change`` is set to an integer.</span>
</span><span id="L-822"><a href="#L-822"><span class="linenos"> 822</span></a>
</span><span id="L-823"><a href="#L-823"><span class="linenos"> 823</span></a><span class="sd">    n_iter_no_change : int, default: None</span>
</span><span id="L-824"><a href="#L-824"><span class="linenos"> 824</span></a><span class="sd">        ``n_iter_no_change`` is used to decide if early stopping will be used</span>
</span><span id="L-825"><a href="#L-825"><span class="linenos"> 825</span></a><span class="sd">        to terminate training when validation score is not improving. By</span>
</span><span id="L-826"><a href="#L-826"><span class="linenos"> 826</span></a><span class="sd">        default it is set to None to disable early stopping. If set to a</span>
</span><span id="L-827"><a href="#L-827"><span class="linenos"> 827</span></a><span class="sd">        number, it will set aside ``validation_fraction`` size of the training</span>
</span><span id="L-828"><a href="#L-828"><span class="linenos"> 828</span></a><span class="sd">        data as validation and terminate training when validation score is not</span>
</span><span id="L-829"><a href="#L-829"><span class="linenos"> 829</span></a><span class="sd">        improving in all of the previous ``n_iter_no_change`` numbers of</span>
</span><span id="L-830"><a href="#L-830"><span class="linenos"> 830</span></a><span class="sd">        iterations. The split is stratified.</span>
</span><span id="L-831"><a href="#L-831"><span class="linenos"> 831</span></a><span class="sd">        Values must be in the range `[1, inf)`.</span>
</span><span id="L-832"><a href="#L-832"><span class="linenos"> 832</span></a>
</span><span id="L-833"><a href="#L-833"><span class="linenos"> 833</span></a><span class="sd">    tol : float, default: 1e-4</span>
</span><span id="L-834"><a href="#L-834"><span class="linenos"> 834</span></a><span class="sd">        Tolerance for the early stopping. When the loss is not improving</span>
</span><span id="L-835"><a href="#L-835"><span class="linenos"> 835</span></a><span class="sd">        by at least tol for ``n_iter_no_change`` iterations (if set to a</span>
</span><span id="L-836"><a href="#L-836"><span class="linenos"> 836</span></a><span class="sd">        number), the training stops.</span>
</span><span id="L-837"><a href="#L-837"><span class="linenos"> 837</span></a><span class="sd">        Values must be in the range `[0.0, inf)`.</span>
</span><span id="L-838"><a href="#L-838"><span class="linenos"> 838</span></a>
</span><span id="L-839"><a href="#L-839"><span class="linenos"> 839</span></a><span class="sd">    dropout_rate : float, optional, default: 0.0</span>
</span><span id="L-840"><a href="#L-840"><span class="linenos"> 840</span></a><span class="sd">        If larger than zero, the residuals at each iteration are only computed</span>
</span><span id="L-841"><a href="#L-841"><span class="linenos"> 841</span></a><span class="sd">        from a random subset of base learners. The value corresponds to the</span>
</span><span id="L-842"><a href="#L-842"><span class="linenos"> 842</span></a><span class="sd">        percentage of base learners that are dropped. In each iteration,</span>
</span><span id="L-843"><a href="#L-843"><span class="linenos"> 843</span></a><span class="sd">        at least one base learner is dropped. This is an alternative regularization</span>
</span><span id="L-844"><a href="#L-844"><span class="linenos"> 844</span></a><span class="sd">        to shrinkage, i.e., setting `learning_rate &lt; 1.0`.</span>
</span><span id="L-845"><a href="#L-845"><span class="linenos"> 845</span></a><span class="sd">        Values must be in the range `[0.0, 1.0)`.</span>
</span><span id="L-846"><a href="#L-846"><span class="linenos"> 846</span></a>
</span><span id="L-847"><a href="#L-847"><span class="linenos"> 847</span></a><span class="sd">    verbose : int, default: 0</span>
</span><span id="L-848"><a href="#L-848"><span class="linenos"> 848</span></a><span class="sd">        Enable verbose output. If 1 then it prints progress and performance</span>
</span><span id="L-849"><a href="#L-849"><span class="linenos"> 849</span></a><span class="sd">        once in a while (the more trees the lower the frequency). If greater</span>
</span><span id="L-850"><a href="#L-850"><span class="linenos"> 850</span></a><span class="sd">        than 1 then it prints progress and performance for every tree.</span>
</span><span id="L-851"><a href="#L-851"><span class="linenos"> 851</span></a><span class="sd">        Values must be in the range `[0, inf)`.</span>
</span><span id="L-852"><a href="#L-852"><span class="linenos"> 852</span></a>
</span><span id="L-853"><a href="#L-853"><span class="linenos"> 853</span></a><span class="sd">    ccp_alpha : non-negative float, optional, default: 0.0.</span>
</span><span id="L-854"><a href="#L-854"><span class="linenos"> 854</span></a><span class="sd">        Complexity parameter used for Minimal Cost-Complexity Pruning. The</span>
</span><span id="L-855"><a href="#L-855"><span class="linenos"> 855</span></a><span class="sd">        subtree with the largest cost complexity that is smaller than</span>
</span><span id="L-856"><a href="#L-856"><span class="linenos"> 856</span></a><span class="sd">        ``ccp_alpha`` will be chosen. By default, no pruning is performed.</span>
</span><span id="L-857"><a href="#L-857"><span class="linenos"> 857</span></a><span class="sd">        Values must be in the range `[0.0, inf)`.</span>
</span><span id="L-858"><a href="#L-858"><span class="linenos"> 858</span></a>
</span><span id="L-859"><a href="#L-859"><span class="linenos"> 859</span></a><span class="sd">    Attributes</span>
</span><span id="L-860"><a href="#L-860"><span class="linenos"> 860</span></a><span class="sd">    ----------</span>
</span><span id="L-861"><a href="#L-861"><span class="linenos"> 861</span></a><span class="sd">    n_estimators_ : int</span>
</span><span id="L-862"><a href="#L-862"><span class="linenos"> 862</span></a><span class="sd">        The number of estimators as selected by early stopping (if</span>
</span><span id="L-863"><a href="#L-863"><span class="linenos"> 863</span></a><span class="sd">        ``n_iter_no_change`` is specified). Otherwise it is set to</span>
</span><span id="L-864"><a href="#L-864"><span class="linenos"> 864</span></a><span class="sd">        ``n_estimators``.</span>
</span><span id="L-865"><a href="#L-865"><span class="linenos"> 865</span></a>
</span><span id="L-866"><a href="#L-866"><span class="linenos"> 866</span></a><span class="sd">    feature_importances_ : ndarray, shape = (n_features,)</span>
</span><span id="L-867"><a href="#L-867"><span class="linenos"> 867</span></a><span class="sd">        The feature importances (the higher, the more important the feature).</span>
</span><span id="L-868"><a href="#L-868"><span class="linenos"> 868</span></a>
</span><span id="L-869"><a href="#L-869"><span class="linenos"> 869</span></a><span class="sd">    estimators_ : ndarray of DecisionTreeRegressor, shape = (n_estimators, 1)</span>
</span><span id="L-870"><a href="#L-870"><span class="linenos"> 870</span></a><span class="sd">        The collection of fitted sub-estimators.</span>
</span><span id="L-871"><a href="#L-871"><span class="linenos"> 871</span></a>
</span><span id="L-872"><a href="#L-872"><span class="linenos"> 872</span></a><span class="sd">    train_score_ : ndarray, shape = (n_estimators,)</span>
</span><span id="L-873"><a href="#L-873"><span class="linenos"> 873</span></a><span class="sd">        The i-th score ``train_score_[i]`` is the loss of the</span>
</span><span id="L-874"><a href="#L-874"><span class="linenos"> 874</span></a><span class="sd">        model at iteration ``i`` on the in-bag sample.</span>
</span><span id="L-875"><a href="#L-875"><span class="linenos"> 875</span></a><span class="sd">        If ``subsample == 1`` this is the loss on the training data.</span>
</span><span id="L-876"><a href="#L-876"><span class="linenos"> 876</span></a>
</span><span id="L-877"><a href="#L-877"><span class="linenos"> 877</span></a><span class="sd">    oob_improvement_ : ndarray, shape = (n_estimators,)</span>
</span><span id="L-878"><a href="#L-878"><span class="linenos"> 878</span></a><span class="sd">        The improvement in loss on the out-of-bag samples</span>
</span><span id="L-879"><a href="#L-879"><span class="linenos"> 879</span></a><span class="sd">        relative to the previous iteration.</span>
</span><span id="L-880"><a href="#L-880"><span class="linenos"> 880</span></a><span class="sd">        ``oob_improvement_[0]`` is the improvement in</span>
</span><span id="L-881"><a href="#L-881"><span class="linenos"> 881</span></a><span class="sd">        loss of the first stage over the ``init`` estimator.</span>
</span><span id="L-882"><a href="#L-882"><span class="linenos"> 882</span></a><span class="sd">        Only available if ``subsample &lt; 1.0``.</span>
</span><span id="L-883"><a href="#L-883"><span class="linenos"> 883</span></a>
</span><span id="L-884"><a href="#L-884"><span class="linenos"> 884</span></a><span class="sd">    oob_scores_ : ndarray of shape (n_estimators,)</span>
</span><span id="L-885"><a href="#L-885"><span class="linenos"> 885</span></a><span class="sd">        The full history of the loss values on the out-of-bag</span>
</span><span id="L-886"><a href="#L-886"><span class="linenos"> 886</span></a><span class="sd">        samples. Only available if ``subsample &lt; 1.0``.</span>
</span><span id="L-887"><a href="#L-887"><span class="linenos"> 887</span></a>
</span><span id="L-888"><a href="#L-888"><span class="linenos"> 888</span></a><span class="sd">    oob_score_ : float</span>
</span><span id="L-889"><a href="#L-889"><span class="linenos"> 889</span></a><span class="sd">        The last value of the loss on the out-of-bag samples. It is</span>
</span><span id="L-890"><a href="#L-890"><span class="linenos"> 890</span></a><span class="sd">        the same as ``oob_scores_[-1]``. Only available if ``subsample &lt; 1.0``.</span>
</span><span id="L-891"><a href="#L-891"><span class="linenos"> 891</span></a>
</span><span id="L-892"><a href="#L-892"><span class="linenos"> 892</span></a><span class="sd">    n_features_in_ : int</span>
</span><span id="L-893"><a href="#L-893"><span class="linenos"> 893</span></a><span class="sd">        Number of features seen during ``fit``.</span>
</span><span id="L-894"><a href="#L-894"><span class="linenos"> 894</span></a>
</span><span id="L-895"><a href="#L-895"><span class="linenos"> 895</span></a><span class="sd">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span>
</span><span id="L-896"><a href="#L-896"><span class="linenos"> 896</span></a><span class="sd">        Names of features seen during ``fit``. Defined only when `X`</span>
</span><span id="L-897"><a href="#L-897"><span class="linenos"> 897</span></a><span class="sd">        has feature names that are all strings.</span>
</span><span id="L-898"><a href="#L-898"><span class="linenos"> 898</span></a>
</span><span id="L-899"><a href="#L-899"><span class="linenos"> 899</span></a><span class="sd">    max_features_ : int</span>
</span><span id="L-900"><a href="#L-900"><span class="linenos"> 900</span></a><span class="sd">        The inferred value of max_features.</span>
</span><span id="L-901"><a href="#L-901"><span class="linenos"> 901</span></a>
</span><span id="L-902"><a href="#L-902"><span class="linenos"> 902</span></a><span class="sd">    unique_times_ : array of shape = (n_unique_times,)</span>
</span><span id="L-903"><a href="#L-903"><span class="linenos"> 903</span></a><span class="sd">        Unique time points.</span>
</span><span id="L-904"><a href="#L-904"><span class="linenos"> 904</span></a>
</span><span id="L-905"><a href="#L-905"><span class="linenos"> 905</span></a><span class="sd">    See also</span>
</span><span id="L-906"><a href="#L-906"><span class="linenos"> 906</span></a><span class="sd">    --------</span>
</span><span id="L-907"><a href="#L-907"><span class="linenos"> 907</span></a><span class="sd">    survivalist.ensemble.ComponentwiseGradientBoostingSurvivalAnalysis</span>
</span><span id="L-908"><a href="#L-908"><span class="linenos"> 908</span></a><span class="sd">        Gradient boosting with component-wise least squares as base learner.</span>
</span><span id="L-909"><a href="#L-909"><span class="linenos"> 909</span></a>
</span><span id="L-910"><a href="#L-910"><span class="linenos"> 910</span></a><span class="sd">    References</span>
</span><span id="L-911"><a href="#L-911"><span class="linenos"> 911</span></a><span class="sd">    ----------</span>
</span><span id="L-912"><a href="#L-912"><span class="linenos"> 912</span></a><span class="sd">    .. [1] J. H. Friedman, &quot;Greedy function approximation: A gradient boosting machine,&quot;</span>
</span><span id="L-913"><a href="#L-913"><span class="linenos"> 913</span></a><span class="sd">           The Annals of Statistics, 29(5), 11891232, 2001.</span>
</span><span id="L-914"><a href="#L-914"><span class="linenos"> 914</span></a><span class="sd">    .. [2] J. H. Friedman, &quot;Stochastic gradient boosting,&quot;</span>
</span><span id="L-915"><a href="#L-915"><span class="linenos"> 915</span></a><span class="sd">           Computational Statistics &amp; Data Analysis, 38(4), 367378, 2002.</span>
</span><span id="L-916"><a href="#L-916"><span class="linenos"> 916</span></a><span class="sd">    .. [3] G. Ridgeway, &quot;The state of boosting,&quot;</span>
</span><span id="L-917"><a href="#L-917"><span class="linenos"> 917</span></a><span class="sd">           Computing Science and Statistics, 172181, 1999.</span>
</span><span id="L-918"><a href="#L-918"><span class="linenos"> 918</span></a><span class="sd">    .. [4] Hothorn, T., Bhlmann, P., Dudoit, S., Molinaro, A., van der Laan, M. J.,</span>
</span><span id="L-919"><a href="#L-919"><span class="linenos"> 919</span></a><span class="sd">           &quot;Survival ensembles&quot;, Biostatistics, 7(3), 355-73, 2006.</span>
</span><span id="L-920"><a href="#L-920"><span class="linenos"> 920</span></a><span class="sd">    .. [5] K. V. Rashmi and R. Gilad-Bachrach,</span>
</span><span id="L-921"><a href="#L-921"><span class="linenos"> 921</span></a><span class="sd">           &quot;DART: Dropouts meet multiple additive regression trees,&quot;</span>
</span><span id="L-922"><a href="#L-922"><span class="linenos"> 922</span></a><span class="sd">           in 18th International Conference on Artificial Intelligence and Statistics,</span>
</span><span id="L-923"><a href="#L-923"><span class="linenos"> 923</span></a><span class="sd">           2015, 489497.</span>
</span><span id="L-924"><a href="#L-924"><span class="linenos"> 924</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-925"><a href="#L-925"><span class="linenos"> 925</span></a>
</span><span id="L-926"><a href="#L-926"><span class="linenos"> 926</span></a>    <span class="n">_parameter_constraints</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-927"><a href="#L-927"><span class="linenos"> 927</span></a>        <span class="o">**</span><span class="n">BaseGradientBoosting</span><span class="o">.</span><span class="n">_parameter_constraints</span><span class="p">,</span>
</span><span id="L-928"><a href="#L-928"><span class="linenos"> 928</span></a>        <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">LOSS_FUNCTIONS</span><span class="o">.</span><span class="n">keys</span><span class="p">()))],</span>
</span><span id="L-929"><a href="#L-929"><span class="linenos"> 929</span></a>        <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
</span><span id="L-930"><a href="#L-930"><span class="linenos"> 930</span></a>    <span class="p">}</span>
</span><span id="L-931"><a href="#L-931"><span class="linenos"> 931</span></a>
</span><span id="L-932"><a href="#L-932"><span class="linenos"> 932</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-933"><a href="#L-933"><span class="linenos"> 933</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-934"><a href="#L-934"><span class="linenos"> 934</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="L-935"><a href="#L-935"><span class="linenos"> 935</span></a>        <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;coxph&quot;</span><span class="p">,</span>
</span><span id="L-936"><a href="#L-936"><span class="linenos"> 936</span></a>        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="L-937"><a href="#L-937"><span class="linenos"> 937</span></a>        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="L-938"><a href="#L-938"><span class="linenos"> 938</span></a>        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="L-939"><a href="#L-939"><span class="linenos"> 939</span></a>        <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;friedman_mse&quot;</span><span class="p">,</span>
</span><span id="L-940"><a href="#L-940"><span class="linenos"> 940</span></a>        <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="L-941"><a href="#L-941"><span class="linenos"> 941</span></a>        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="L-942"><a href="#L-942"><span class="linenos"> 942</span></a>        <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="L-943"><a href="#L-943"><span class="linenos"> 943</span></a>        <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span><span id="L-944"><a href="#L-944"><span class="linenos"> 944</span></a>        <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="L-945"><a href="#L-945"><span class="linenos"> 945</span></a>        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-946"><a href="#L-946"><span class="linenos"> 946</span></a>        <span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-947"><a href="#L-947"><span class="linenos"> 947</span></a>        <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-948"><a href="#L-948"><span class="linenos"> 948</span></a>        <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-949"><a href="#L-949"><span class="linenos"> 949</span></a>        <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="L-950"><a href="#L-950"><span class="linenos"> 950</span></a>        <span class="n">n_iter_no_change</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-951"><a href="#L-951"><span class="linenos"> 951</span></a>        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
</span><span id="L-952"><a href="#L-952"><span class="linenos"> 952</span></a>        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="L-953"><a href="#L-953"><span class="linenos"> 953</span></a>        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-954"><a href="#L-954"><span class="linenos"> 954</span></a>        <span class="n">ccp_alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="L-955"><a href="#L-955"><span class="linenos"> 955</span></a>    <span class="p">):</span>
</span><span id="L-956"><a href="#L-956"><span class="linenos"> 956</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-957"><a href="#L-957"><span class="linenos"> 957</span></a>            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span id="L-958"><a href="#L-958"><span class="linenos"> 958</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="L-959"><a href="#L-959"><span class="linenos"> 959</span></a>            <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="L-960"><a href="#L-960"><span class="linenos"> 960</span></a>            <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
</span><span id="L-961"><a href="#L-961"><span class="linenos"> 961</span></a>            <span class="n">min_samples_split</span><span class="o">=</span><span class="n">min_samples_split</span><span class="p">,</span>
</span><span id="L-962"><a href="#L-962"><span class="linenos"> 962</span></a>            <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_samples_leaf</span><span class="p">,</span>
</span><span id="L-963"><a href="#L-963"><span class="linenos"> 963</span></a>            <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="n">min_weight_fraction_leaf</span><span class="p">,</span>
</span><span id="L-964"><a href="#L-964"><span class="linenos"> 964</span></a>            <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span>
</span><span id="L-965"><a href="#L-965"><span class="linenos"> 965</span></a>            <span class="n">init</span><span class="o">=</span><span class="s2">&quot;zero&quot;</span><span class="p">,</span>
</span><span id="L-966"><a href="#L-966"><span class="linenos"> 966</span></a>            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
</span><span id="L-967"><a href="#L-967"><span class="linenos"> 967</span></a>            <span class="n">max_features</span><span class="o">=</span><span class="n">max_features</span><span class="p">,</span>
</span><span id="L-968"><a href="#L-968"><span class="linenos"> 968</span></a>            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
</span><span id="L-969"><a href="#L-969"><span class="linenos"> 969</span></a>            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="L-970"><a href="#L-970"><span class="linenos"> 970</span></a>            <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span>
</span><span id="L-971"><a href="#L-971"><span class="linenos"> 971</span></a>            <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span>
</span><span id="L-972"><a href="#L-972"><span class="linenos"> 972</span></a>            <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="n">min_impurity_decrease</span><span class="p">,</span>
</span><span id="L-973"><a href="#L-973"><span class="linenos"> 973</span></a>            <span class="n">validation_fraction</span><span class="o">=</span><span class="n">validation_fraction</span><span class="p">,</span>
</span><span id="L-974"><a href="#L-974"><span class="linenos"> 974</span></a>            <span class="n">n_iter_no_change</span><span class="o">=</span><span class="n">n_iter_no_change</span><span class="p">,</span>
</span><span id="L-975"><a href="#L-975"><span class="linenos"> 975</span></a>            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
</span><span id="L-976"><a href="#L-976"><span class="linenos"> 976</span></a>            <span class="n">ccp_alpha</span><span class="o">=</span><span class="n">ccp_alpha</span><span class="p">,</span>
</span><span id="L-977"><a href="#L-977"><span class="linenos"> 977</span></a>        <span class="p">)</span>
</span><span id="L-978"><a href="#L-978"><span class="linenos"> 978</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>
</span><span id="L-979"><a href="#L-979"><span class="linenos"> 979</span></a>
</span><span id="L-980"><a href="#L-980"><span class="linenos"> 980</span></a>    <span class="k">def</span> <span class="nf">_encode_y</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
</span><span id="L-981"><a href="#L-981"><span class="linenos"> 981</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-982"><a href="#L-982"><span class="linenos"> 982</span></a>        <span class="k">return</span> <span class="n">y</span>
</span><span id="L-983"><a href="#L-983"><span class="linenos"> 983</span></a>
</span><span id="L-984"><a href="#L-984"><span class="linenos"> 984</span></a>    <span class="k">def</span> <span class="nf">_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
</span><span id="L-985"><a href="#L-985"><span class="linenos"> 985</span></a>        <span class="k">return</span> <span class="n">LOSS_FUNCTIONS</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">]()</span>
</span><span id="L-986"><a href="#L-986"><span class="linenos"> 986</span></a>
</span><span id="L-987"><a href="#L-987"><span class="linenos"> 987</span></a>    <span class="nd">@property</span>
</span><span id="L-988"><a href="#L-988"><span class="linenos"> 988</span></a>    <span class="k">def</span> <span class="nf">_predict_risk_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-989"><a href="#L-989"><span class="linenos"> 989</span></a>        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="n">CoxPH</span><span class="p">)</span>
</span><span id="L-990"><a href="#L-990"><span class="linenos"> 990</span></a>
</span><span id="L-991"><a href="#L-991"><span class="linenos"> 991</span></a>    <span class="k">def</span> <span class="nf">_set_max_features</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-992"><a href="#L-992"><span class="linenos"> 992</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Set self.max_features_.&quot;&quot;&quot;</span>
</span><span id="L-993"><a href="#L-993"><span class="linenos"> 993</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="L-994"><a href="#L-994"><span class="linenos"> 994</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_features</span> <span class="o">==</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">:</span>
</span><span id="L-995"><a href="#L-995"><span class="linenos"> 995</span></a>                <span class="n">max_features</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">)))</span>
</span><span id="L-996"><a href="#L-996"><span class="linenos"> 996</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_features</span> <span class="o">==</span> <span class="s2">&quot;log2&quot;</span><span class="p">:</span>
</span><span id="L-997"><a href="#L-997"><span class="linenos"> 997</span></a>                <span class="n">max_features</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">)))</span>
</span><span id="L-998"><a href="#L-998"><span class="linenos"> 998</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-999"><a href="#L-999"><span class="linenos"> 999</span></a>            <span class="n">max_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span>
</span><span id="L-1000"><a href="#L-1000"><span class="linenos">1000</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span><span class="p">,</span> <span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
</span><span id="L-1001"><a href="#L-1001"><span class="linenos">1001</span></a>            <span class="n">max_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_features</span>
</span><span id="L-1002"><a href="#L-1002"><span class="linenos">1002</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># float</span>
</span><span id="L-1003"><a href="#L-1003"><span class="linenos">1003</span></a>            <span class="n">max_features</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">))</span>
</span><span id="L-1004"><a href="#L-1004"><span class="linenos">1004</span></a>
</span><span id="L-1005"><a href="#L-1005"><span class="linenos">1005</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_features_</span> <span class="o">=</span> <span class="n">max_features</span>
</span><span id="L-1006"><a href="#L-1006"><span class="linenos">1006</span></a>
</span><span id="L-1007"><a href="#L-1007"><span class="linenos">1007</span></a>    <span class="k">def</span> <span class="nf">_update_with_dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
</span><span id="L-1008"><a href="#L-1008"><span class="linenos">1008</span></a>        <span class="c1"># select base learners to be dropped for next iteration</span>
</span><span id="L-1009"><a href="#L-1009"><span class="linenos">1009</span></a>        <span class="n">drop_model</span><span class="p">,</span> <span class="n">n_dropped</span> <span class="o">=</span> <span class="n">_sample_binomial_plus_one</span><span class="p">(</span>
</span><span id="L-1010"><a href="#L-1010"><span class="linenos">1010</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="L-1011"><a href="#L-1011"><span class="linenos">1011</span></a>
</span><span id="L-1012"><a href="#L-1012"><span class="linenos">1012</span></a>        <span class="c1"># adjust scaling factor of tree that is going to be trained in next iteration</span>
</span><span id="L-1013"><a href="#L-1013"><span class="linenos">1013</span></a>        <span class="n">scale</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_dropped</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-1014"><a href="#L-1014"><span class="linenos">1014</span></a>
</span><span id="L-1015"><a href="#L-1015"><span class="linenos">1015</span></a>        <span class="n">raw_predictions</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-1016"><a href="#L-1016"><span class="linenos">1016</span></a>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="L-1017"><a href="#L-1017"><span class="linenos">1017</span></a>            <span class="k">if</span> <span class="n">drop_model</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-1018"><a href="#L-1018"><span class="linenos">1018</span></a>                <span class="c1"># adjust scaling factor of dropped trees</span>
</span><span id="L-1019"><a href="#L-1019"><span class="linenos">1019</span></a>                <span class="n">scale</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">*=</span> <span class="n">n_dropped</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_dropped</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-1020"><a href="#L-1020"><span class="linenos">1020</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1021"><a href="#L-1021"><span class="linenos">1021</span></a>                <span class="c1"># pseudoresponse of next iteration (without contribution of dropped trees)</span>
</span><span id="L-1022"><a href="#L-1022"><span class="linenos">1022</span></a>                <span class="n">raw_predictions</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> \
</span><span id="L-1023"><a href="#L-1023"><span class="linenos">1023</span></a>                    <span class="n">scale</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span><span id="L-1024"><a href="#L-1024"><span class="linenos">1024</span></a>
</span><span id="L-1025"><a href="#L-1025"><span class="linenos">1025</span></a>    <span class="k">def</span> <span class="nf">_fit_stage</span><span class="p">(</span>
</span><span id="L-1026"><a href="#L-1026"><span class="linenos">1026</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-1027"><a href="#L-1027"><span class="linenos">1027</span></a>        <span class="n">i</span><span class="p">,</span>
</span><span id="L-1028"><a href="#L-1028"><span class="linenos">1028</span></a>        <span class="n">X</span><span class="p">,</span>
</span><span id="L-1029"><a href="#L-1029"><span class="linenos">1029</span></a>        <span class="n">y</span><span class="p">,</span>
</span><span id="L-1030"><a href="#L-1030"><span class="linenos">1030</span></a>        <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="L-1031"><a href="#L-1031"><span class="linenos">1031</span></a>        <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="L-1032"><a href="#L-1032"><span class="linenos">1032</span></a>        <span class="n">sample_mask</span><span class="p">,</span>
</span><span id="L-1033"><a href="#L-1033"><span class="linenos">1033</span></a>        <span class="n">random_state</span><span class="p">,</span>
</span><span id="L-1034"><a href="#L-1034"><span class="linenos">1034</span></a>        <span class="n">scale</span><span class="p">,</span>
</span><span id="L-1035"><a href="#L-1035"><span class="linenos">1035</span></a>        <span class="n">X_csc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-1036"><a href="#L-1036"><span class="linenos">1036</span></a>        <span class="n">X_csr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-1037"><a href="#L-1037"><span class="linenos">1037</span></a>    <span class="p">):</span>
</span><span id="L-1038"><a href="#L-1038"><span class="linenos">1038</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit another stage of ``n_classes_`` trees to the boosting model.&quot;&quot;&quot;</span>
</span><span id="L-1039"><a href="#L-1039"><span class="linenos">1039</span></a>
</span><span id="L-1040"><a href="#L-1040"><span class="linenos">1040</span></a>        <span class="k">assert</span> <span class="n">sample_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">bool</span>
</span><span id="L-1041"><a href="#L-1041"><span class="linenos">1041</span></a>
</span><span id="L-1042"><a href="#L-1042"><span class="linenos">1042</span></a>        <span class="c1"># whether to use dropout in next iteration</span>
</span><span id="L-1043"><a href="#L-1043"><span class="linenos">1043</span></a>        <span class="n">do_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="L-1044"><a href="#L-1044"><span class="linenos">1044</span></a>
</span><span id="L-1045"><a href="#L-1045"><span class="linenos">1045</span></a>        <span class="c1"># Need to pass a copy of raw_predictions to negative_gradient()</span>
</span><span id="L-1046"><a href="#L-1046"><span class="linenos">1046</span></a>        <span class="c1"># because raw_predictions is partially updated at the end of the loop</span>
</span><span id="L-1047"><a href="#L-1047"><span class="linenos">1047</span></a>        <span class="c1"># in update_terminal_regions(), and gradients need to be evaluated at</span>
</span><span id="L-1048"><a href="#L-1048"><span class="linenos">1048</span></a>        <span class="c1"># iteration i - 1.</span>
</span><span id="L-1049"><a href="#L-1049"><span class="linenos">1049</span></a>        <span class="n">raw_predictions_copy</span> <span class="o">=</span> <span class="n">raw_predictions</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="L-1050"><a href="#L-1050"><span class="linenos">1050</span></a>
</span><span id="L-1051"><a href="#L-1051"><span class="linenos">1051</span></a>        <span class="n">neg_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
</span><span id="L-1052"><a href="#L-1052"><span class="linenos">1052</span></a>            <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
</span><span id="L-1053"><a href="#L-1053"><span class="linenos">1053</span></a>            <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions_copy</span><span class="p">,</span>
</span><span id="L-1054"><a href="#L-1054"><span class="linenos">1054</span></a>            <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># We pass sample_weights to the tree directly.</span>
</span><span id="L-1055"><a href="#L-1055"><span class="linenos">1055</span></a>        <span class="p">)</span>
</span><span id="L-1056"><a href="#L-1056"><span class="linenos">1056</span></a>
</span><span id="L-1057"><a href="#L-1057"><span class="linenos">1057</span></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span><span class="p">):</span>
</span><span id="L-1058"><a href="#L-1058"><span class="linenos">1058</span></a>            <span class="c1"># induce regression tree on the negative gradient</span>
</span><span id="L-1059"><a href="#L-1059"><span class="linenos">1059</span></a>            <span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span>
</span><span id="L-1060"><a href="#L-1060"><span class="linenos">1060</span></a>                <span class="n">criterion</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">,</span>
</span><span id="L-1061"><a href="#L-1061"><span class="linenos">1061</span></a>                <span class="n">splitter</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span>
</span><span id="L-1062"><a href="#L-1062"><span class="linenos">1062</span></a>                <span class="n">max_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">,</span>
</span><span id="L-1063"><a href="#L-1063"><span class="linenos">1063</span></a>                <span class="n">min_samples_split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_samples_split</span><span class="p">,</span>
</span><span id="L-1064"><a href="#L-1064"><span class="linenos">1064</span></a>                <span class="n">min_samples_leaf</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_samples_leaf</span><span class="p">,</span>
</span><span id="L-1065"><a href="#L-1065"><span class="linenos">1065</span></a>                <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_weight_fraction_leaf</span><span class="p">,</span>
</span><span id="L-1066"><a href="#L-1066"><span class="linenos">1066</span></a>                <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_impurity_decrease</span><span class="p">,</span>
</span><span id="L-1067"><a href="#L-1067"><span class="linenos">1067</span></a>                <span class="n">max_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span><span class="p">,</span>
</span><span id="L-1068"><a href="#L-1068"><span class="linenos">1068</span></a>                <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_leaf_nodes</span><span class="p">,</span>
</span><span id="L-1069"><a href="#L-1069"><span class="linenos">1069</span></a>                <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
</span><span id="L-1070"><a href="#L-1070"><span class="linenos">1070</span></a>                <span class="n">ccp_alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ccp_alpha</span><span class="p">,</span>
</span><span id="L-1071"><a href="#L-1071"><span class="linenos">1071</span></a>            <span class="p">)</span>
</span><span id="L-1072"><a href="#L-1072"><span class="linenos">1072</span></a>
</span><span id="L-1073"><a href="#L-1073"><span class="linenos">1073</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span id="L-1074"><a href="#L-1074"><span class="linenos">1074</span></a>                <span class="c1"># no inplace multiplication!</span>
</span><span id="L-1075"><a href="#L-1075"><span class="linenos">1075</span></a>                <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="o">*</span> <span class="n">sample_mask</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="L-1076"><a href="#L-1076"><span class="linenos">1076</span></a>
</span><span id="L-1077"><a href="#L-1077"><span class="linenos">1077</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X_csc</span> <span class="k">if</span> <span class="n">X_csc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>
</span><span id="L-1078"><a href="#L-1078"><span class="linenos">1078</span></a>            <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">neg_gradient</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
</span><span id="L-1079"><a href="#L-1079"><span class="linenos">1079</span></a>                     <span class="n">check_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-1080"><a href="#L-1080"><span class="linenos">1080</span></a>
</span><span id="L-1081"><a href="#L-1081"><span class="linenos">1081</span></a>            <span class="c1"># add tree to ensemble</span>
</span><span id="L-1082"><a href="#L-1082"><span class="linenos">1082</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tree</span>
</span><span id="L-1083"><a href="#L-1083"><span class="linenos">1083</span></a>
</span><span id="L-1084"><a href="#L-1084"><span class="linenos">1084</span></a>            <span class="c1"># update tree leaves</span>
</span><span id="L-1085"><a href="#L-1085"><span class="linenos">1085</span></a>            <span class="k">if</span> <span class="n">do_dropout</span><span class="p">:</span>
</span><span id="L-1086"><a href="#L-1086"><span class="linenos">1086</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span>
</span><span id="L-1087"><a href="#L-1087"><span class="linenos">1087</span></a>                    <span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="L-1088"><a href="#L-1088"><span class="linenos">1088</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1089"><a href="#L-1089"><span class="linenos">1089</span></a>                <span class="c1"># update tree leaves</span>
</span><span id="L-1090"><a href="#L-1090"><span class="linenos">1090</span></a>                <span class="n">X_for_tree_update</span> <span class="o">=</span> <span class="n">X_csr</span> <span class="k">if</span> <span class="n">X_csr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>
</span><span id="L-1091"><a href="#L-1091"><span class="linenos">1091</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">update_terminal_regions</span><span class="p">(</span>
</span><span id="L-1092"><a href="#L-1092"><span class="linenos">1092</span></a>                    <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="p">,</span>
</span><span id="L-1093"><a href="#L-1093"><span class="linenos">1093</span></a>                    <span class="n">X_for_tree_update</span><span class="p">,</span>
</span><span id="L-1094"><a href="#L-1094"><span class="linenos">1094</span></a>                    <span class="n">y</span><span class="p">,</span>
</span><span id="L-1095"><a href="#L-1095"><span class="linenos">1095</span></a>                    <span class="n">neg_gradient</span><span class="p">,</span>
</span><span id="L-1096"><a href="#L-1096"><span class="linenos">1096</span></a>                    <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="L-1097"><a href="#L-1097"><span class="linenos">1097</span></a>                    <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="L-1098"><a href="#L-1098"><span class="linenos">1098</span></a>                    <span class="n">sample_mask</span><span class="p">,</span>
</span><span id="L-1099"><a href="#L-1099"><span class="linenos">1099</span></a>                    <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="L-1100"><a href="#L-1100"><span class="linenos">1100</span></a>                    <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
</span><span id="L-1101"><a href="#L-1101"><span class="linenos">1101</span></a>                <span class="p">)</span>
</span><span id="L-1102"><a href="#L-1102"><span class="linenos">1102</span></a>
</span><span id="L-1103"><a href="#L-1103"><span class="linenos">1103</span></a>        <span class="k">return</span> <span class="n">raw_predictions</span>
</span><span id="L-1104"><a href="#L-1104"><span class="linenos">1104</span></a>
</span><span id="L-1105"><a href="#L-1105"><span class="linenos">1105</span></a>    <span class="k">def</span> <span class="nf">_fit_stages</span><span class="p">(</span>  <span class="c1"># noqa: C901</span>
</span><span id="L-1106"><a href="#L-1106"><span class="linenos">1106</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-1107"><a href="#L-1107"><span class="linenos">1107</span></a>        <span class="n">X</span><span class="p">,</span>
</span><span id="L-1108"><a href="#L-1108"><span class="linenos">1108</span></a>        <span class="n">y</span><span class="p">,</span>
</span><span id="L-1109"><a href="#L-1109"><span class="linenos">1109</span></a>        <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="L-1110"><a href="#L-1110"><span class="linenos">1110</span></a>        <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="L-1111"><a href="#L-1111"><span class="linenos">1111</span></a>        <span class="n">random_state</span><span class="p">,</span>
</span><span id="L-1112"><a href="#L-1112"><span class="linenos">1112</span></a>        <span class="n">X_val</span><span class="p">,</span>
</span><span id="L-1113"><a href="#L-1113"><span class="linenos">1113</span></a>        <span class="n">y_val</span><span class="p">,</span>
</span><span id="L-1114"><a href="#L-1114"><span class="linenos">1114</span></a>        <span class="n">sample_weight_val</span><span class="p">,</span>
</span><span id="L-1115"><a href="#L-1115"><span class="linenos">1115</span></a>        <span class="n">scale</span><span class="p">,</span>
</span><span id="L-1116"><a href="#L-1116"><span class="linenos">1116</span></a>        <span class="n">begin_at_stage</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-1117"><a href="#L-1117"><span class="linenos">1117</span></a>        <span class="n">monitor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-1118"><a href="#L-1118"><span class="linenos">1118</span></a>    <span class="p">):</span>
</span><span id="L-1119"><a href="#L-1119"><span class="linenos">1119</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Iteratively fits the stages.</span>
</span><span id="L-1120"><a href="#L-1120"><span class="linenos">1120</span></a>
</span><span id="L-1121"><a href="#L-1121"><span class="linenos">1121</span></a><span class="sd">        For each stage it computes the progress (OOB, train score)</span>
</span><span id="L-1122"><a href="#L-1122"><span class="linenos">1122</span></a><span class="sd">        and delegates to ``_fit_stage``.</span>
</span><span id="L-1123"><a href="#L-1123"><span class="linenos">1123</span></a><span class="sd">        Returns the number of stages fit; might differ from ``n_estimators``</span>
</span><span id="L-1124"><a href="#L-1124"><span class="linenos">1124</span></a><span class="sd">        due to early stopping.</span>
</span><span id="L-1125"><a href="#L-1125"><span class="linenos">1125</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1126"><a href="#L-1126"><span class="linenos">1126</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-1127"><a href="#L-1127"><span class="linenos">1127</span></a>        <span class="n">do_oob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mf">1.0</span>
</span><span id="L-1128"><a href="#L-1128"><span class="linenos">1128</span></a>        <span class="n">sample_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
</span><span id="L-1129"><a href="#L-1129"><span class="linenos">1129</span></a>        <span class="n">n_inbag</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">))</span>
</span><span id="L-1130"><a href="#L-1130"><span class="linenos">1130</span></a>
</span><span id="L-1131"><a href="#L-1131"><span class="linenos">1131</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
</span><span id="L-1132"><a href="#L-1132"><span class="linenos">1132</span></a>            <span class="n">verbose_reporter</span> <span class="o">=</span> <span class="n">VerboseReporter</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
</span><span id="L-1133"><a href="#L-1133"><span class="linenos">1133</span></a>            <span class="n">verbose_reporter</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">begin_at_stage</span><span class="p">)</span>
</span><span id="L-1134"><a href="#L-1134"><span class="linenos">1134</span></a>
</span><span id="L-1135"><a href="#L-1135"><span class="linenos">1135</span></a>        <span class="n">X_csc</span> <span class="o">=</span> <span class="n">csc_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="L-1136"><a href="#L-1136"><span class="linenos">1136</span></a>        <span class="n">X_csr</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="L-1137"><a href="#L-1137"><span class="linenos">1137</span></a>
</span><span id="L-1138"><a href="#L-1138"><span class="linenos">1138</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1139"><a href="#L-1139"><span class="linenos">1139</span></a>            <span class="n">loss_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
</span><span id="L-1140"><a href="#L-1140"><span class="linenos">1140</span></a>            <span class="c1"># We create a generator to get the predictions for X_val after</span>
</span><span id="L-1141"><a href="#L-1141"><span class="linenos">1141</span></a>            <span class="c1"># the addition of each successive stage</span>
</span><span id="L-1142"><a href="#L-1142"><span class="linenos">1142</span></a>            <span class="n">y_val_pred_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_staged_raw_predict</span><span class="p">(</span>
</span><span id="L-1143"><a href="#L-1143"><span class="linenos">1143</span></a>                <span class="n">X_val</span><span class="p">,</span> <span class="n">check_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-1144"><a href="#L-1144"><span class="linenos">1144</span></a>
</span><span id="L-1145"><a href="#L-1145"><span class="linenos">1145</span></a>        <span class="c1"># perform boosting iterations</span>
</span><span id="L-1146"><a href="#L-1146"><span class="linenos">1146</span></a>        <span class="n">i</span> <span class="o">=</span> <span class="n">begin_at_stage</span>
</span><span id="L-1147"><a href="#L-1147"><span class="linenos">1147</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">begin_at_stage</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="L-1148"><a href="#L-1148"><span class="linenos">1148</span></a>            <span class="c1"># subsampling</span>
</span><span id="L-1149"><a href="#L-1149"><span class="linenos">1149</span></a>            <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="L-1150"><a href="#L-1150"><span class="linenos">1150</span></a>                <span class="n">sample_mask</span> <span class="o">=</span> <span class="n">_random_sample_mask</span><span class="p">(</span>
</span><span id="L-1151"><a href="#L-1151"><span class="linenos">1151</span></a>                    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_inbag</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="L-1152"><a href="#L-1152"><span class="linenos">1152</span></a>                <span class="c1"># OOB score before adding this stage</span>
</span><span id="L-1153"><a href="#L-1153"><span class="linenos">1153</span></a>                <span class="n">y_oob_masked</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">]</span>
</span><span id="L-1154"><a href="#L-1154"><span class="linenos">1154</span></a>                <span class="n">sample_weight_oob_masked</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">]</span>
</span><span id="L-1155"><a href="#L-1155"><span class="linenos">1155</span></a>                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># store the initial loss to compute the OOB score</span>
</span><span id="L-1156"><a href="#L-1156"><span class="linenos">1156</span></a>                    <span class="n">initial_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="L-1157"><a href="#L-1157"><span class="linenos">1157</span></a>                        <span class="n">y_true</span><span class="o">=</span><span class="n">y_oob_masked</span><span class="p">,</span>
</span><span id="L-1158"><a href="#L-1158"><span class="linenos">1158</span></a>                        <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-1159"><a href="#L-1159"><span class="linenos">1159</span></a>                        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight_oob_masked</span><span class="p">,</span>
</span><span id="L-1160"><a href="#L-1160"><span class="linenos">1160</span></a>                    <span class="p">)</span>
</span><span id="L-1161"><a href="#L-1161"><span class="linenos">1161</span></a>
</span><span id="L-1162"><a href="#L-1162"><span class="linenos">1162</span></a>            <span class="c1"># fit next stage of trees</span>
</span><span id="L-1163"><a href="#L-1163"><span class="linenos">1163</span></a>            <span class="n">raw_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_stage</span><span class="p">(</span>
</span><span id="L-1164"><a href="#L-1164"><span class="linenos">1164</span></a>                <span class="n">i</span><span class="p">,</span>
</span><span id="L-1165"><a href="#L-1165"><span class="linenos">1165</span></a>                <span class="n">X</span><span class="p">,</span>
</span><span id="L-1166"><a href="#L-1166"><span class="linenos">1166</span></a>                <span class="n">y</span><span class="p">,</span>
</span><span id="L-1167"><a href="#L-1167"><span class="linenos">1167</span></a>                <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="L-1168"><a href="#L-1168"><span class="linenos">1168</span></a>                <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="L-1169"><a href="#L-1169"><span class="linenos">1169</span></a>                <span class="n">sample_mask</span><span class="p">,</span>
</span><span id="L-1170"><a href="#L-1170"><span class="linenos">1170</span></a>                <span class="n">random_state</span><span class="p">,</span>
</span><span id="L-1171"><a href="#L-1171"><span class="linenos">1171</span></a>                <span class="n">scale</span><span class="p">,</span>
</span><span id="L-1172"><a href="#L-1172"><span class="linenos">1172</span></a>                <span class="n">X_csc</span><span class="o">=</span><span class="n">X_csc</span><span class="p">,</span>
</span><span id="L-1173"><a href="#L-1173"><span class="linenos">1173</span></a>                <span class="n">X_csr</span><span class="o">=</span><span class="n">X_csr</span><span class="p">,</span>
</span><span id="L-1174"><a href="#L-1174"><span class="linenos">1174</span></a>            <span class="p">)</span>
</span><span id="L-1175"><a href="#L-1175"><span class="linenos">1175</span></a>
</span><span id="L-1176"><a href="#L-1176"><span class="linenos">1176</span></a>            <span class="c1"># track loss</span>
</span><span id="L-1177"><a href="#L-1177"><span class="linenos">1177</span></a>            <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="L-1178"><a href="#L-1178"><span class="linenos">1178</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="L-1179"><a href="#L-1179"><span class="linenos">1179</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-1180"><a href="#L-1180"><span class="linenos">1180</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-1181"><a href="#L-1181"><span class="linenos">1181</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-1182"><a href="#L-1182"><span class="linenos">1182</span></a>                <span class="p">)</span>
</span><span id="L-1183"><a href="#L-1183"><span class="linenos">1183</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="L-1184"><a href="#L-1184"><span class="linenos">1184</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y_oob_masked</span><span class="p">,</span>
</span><span id="L-1185"><a href="#L-1185"><span class="linenos">1185</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="L-1186"><a href="#L-1186"><span class="linenos">1186</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight_oob_masked</span><span class="p">,</span>
</span><span id="L-1187"><a href="#L-1187"><span class="linenos">1187</span></a>                <span class="p">)</span>
</span><span id="L-1188"><a href="#L-1188"><span class="linenos">1188</span></a>                <span class="n">previous_loss</span> <span class="o">=</span> <span class="n">initial_loss</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span>
</span><span id="L-1189"><a href="#L-1189"><span class="linenos">1189</span></a>                    <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="L-1190"><a href="#L-1190"><span class="linenos">1190</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">previous_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="L-1191"><a href="#L-1191"><span class="linenos">1191</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-1192"><a href="#L-1192"><span class="linenos">1192</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1193"><a href="#L-1193"><span class="linenos">1193</span></a>                <span class="c1"># no need to fancy index w/ no subsampling</span>
</span><span id="L-1194"><a href="#L-1194"><span class="linenos">1194</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="L-1195"><a href="#L-1195"><span class="linenos">1195</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
</span><span id="L-1196"><a href="#L-1196"><span class="linenos">1196</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="L-1197"><a href="#L-1197"><span class="linenos">1197</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
</span><span id="L-1198"><a href="#L-1198"><span class="linenos">1198</span></a>                <span class="p">)</span>
</span><span id="L-1199"><a href="#L-1199"><span class="linenos">1199</span></a>
</span><span id="L-1200"><a href="#L-1200"><span class="linenos">1200</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-1201"><a href="#L-1201"><span class="linenos">1201</span></a>                <span class="n">verbose_reporter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
</span><span id="L-1202"><a href="#L-1202"><span class="linenos">1202</span></a>
</span><span id="L-1203"><a href="#L-1203"><span class="linenos">1203</span></a>            <span class="k">if</span> <span class="n">monitor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1204"><a href="#L-1204"><span class="linenos">1204</span></a>                <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">monitor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span>
</span><span id="L-1205"><a href="#L-1205"><span class="linenos">1205</span></a>                <span class="k">if</span> <span class="n">early_stopping</span><span class="p">:</span>
</span><span id="L-1206"><a href="#L-1206"><span class="linenos">1206</span></a>                    <span class="k">break</span>
</span><span id="L-1207"><a href="#L-1207"><span class="linenos">1207</span></a>
</span><span id="L-1208"><a href="#L-1208"><span class="linenos">1208</span></a>            <span class="c1"># We also provide an early stopping based on the score from</span>
</span><span id="L-1209"><a href="#L-1209"><span class="linenos">1209</span></a>            <span class="c1"># validation set (X_val, y_val), if n_iter_no_change is set</span>
</span><span id="L-1210"><a href="#L-1210"><span class="linenos">1210</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1211"><a href="#L-1211"><span class="linenos">1211</span></a>                <span class="c1"># By calling next(y_val_pred_iter), we get the predictions</span>
</span><span id="L-1212"><a href="#L-1212"><span class="linenos">1212</span></a>                <span class="c1"># for X_val after the addition of the current stage</span>
</span><span id="L-1213"><a href="#L-1213"><span class="linenos">1213</span></a>                <span class="n">validation_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span>
</span><span id="L-1214"><a href="#L-1214"><span class="linenos">1214</span></a>                    <span class="n">y_val_pred_iter</span><span class="p">),</span> <span class="n">sample_weight_val</span><span class="p">)</span>
</span><span id="L-1215"><a href="#L-1215"><span class="linenos">1215</span></a>
</span><span id="L-1216"><a href="#L-1216"><span class="linenos">1216</span></a>                <span class="c1"># Require validation_score to be better (less) than at least</span>
</span><span id="L-1217"><a href="#L-1217"><span class="linenos">1217</span></a>                <span class="c1"># one of the last n_iter_no_change evaluations</span>
</span><span id="L-1218"><a href="#L-1218"><span class="linenos">1218</span></a>                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">validation_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">&lt;</span> <span class="n">loss_history</span><span class="p">):</span>
</span><span id="L-1219"><a href="#L-1219"><span class="linenos">1219</span></a>                    <span class="n">loss_history</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_history</span><span class="p">)]</span> <span class="o">=</span> <span class="n">validation_loss</span>
</span><span id="L-1220"><a href="#L-1220"><span class="linenos">1220</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-1221"><a href="#L-1221"><span class="linenos">1221</span></a>                    <span class="k">break</span>
</span><span id="L-1222"><a href="#L-1222"><span class="linenos">1222</span></a>
</span><span id="L-1223"><a href="#L-1223"><span class="linenos">1223</span></a>        <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="L-1224"><a href="#L-1224"><span class="linenos">1224</span></a>
</span><span id="L-1225"><a href="#L-1225"><span class="linenos">1225</span></a>    <span class="k">def</span> <span class="nf">_init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-1226"><a href="#L-1226"><span class="linenos">1226</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_init_state</span><span class="p">()</span>
</span><span id="L-1227"><a href="#L-1227"><span class="linenos">1227</span></a>
</span><span id="L-1228"><a href="#L-1228"><span class="linenos">1228</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
</span><span id="L-1229"><a href="#L-1229"><span class="linenos">1229</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="L-1230"><a href="#L-1230"><span class="linenos">1230</span></a>
</span><span id="L-1231"><a href="#L-1231"><span class="linenos">1231</span></a>    <span class="k">def</span> <span class="nf">_resize_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-1232"><a href="#L-1232"><span class="linenos">1232</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_resize_state</span><span class="p">()</span>
</span><span id="L-1233"><a href="#L-1233"><span class="linenos">1233</span></a>
</span><span id="L-1234"><a href="#L-1234"><span class="linenos">1234</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-1235"><a href="#L-1235"><span class="linenos">1235</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="L-1236"><a href="#L-1236"><span class="linenos">1236</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-1237"><a href="#L-1237"><span class="linenos">1237</span></a>                    <span class="s2">&quot;fitting with warm_start=True and dropout_rate &gt; 0 is only &quot;</span>
</span><span id="L-1238"><a href="#L-1238"><span class="linenos">1238</span></a>                    <span class="s2">&quot;supported if the previous fit used dropout_rate &gt; 0 too&quot;</span>
</span><span id="L-1239"><a href="#L-1239"><span class="linenos">1239</span></a>                <span class="p">)</span>
</span><span id="L-1240"><a href="#L-1240"><span class="linenos">1240</span></a>
</span><span id="L-1241"><a href="#L-1241"><span class="linenos">1241</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">)</span>
</span><span id="L-1242"><a href="#L-1242"><span class="linenos">1242</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-1243"><a href="#L-1243"><span class="linenos">1243</span></a>
</span><span id="L-1244"><a href="#L-1244"><span class="linenos">1244</span></a>    <span class="k">def</span> <span class="nf">_shrink_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_stages</span><span class="p">):</span>
</span><span id="L-1245"><a href="#L-1245"><span class="linenos">1245</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="L-1246"><a href="#L-1246"><span class="linenos">1246</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="L-1247"><a href="#L-1247"><span class="linenos">1247</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_improvement_&quot;</span><span class="p">):</span>
</span><span id="L-1248"><a href="#L-1248"><span class="linenos">1248</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="L-1249"><a href="#L-1249"><span class="linenos">1249</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="L-1250"><a href="#L-1250"><span class="linenos">1250</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-1251"><a href="#L-1251"><span class="linenos">1251</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="L-1252"><a href="#L-1252"><span class="linenos">1252</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="L-1253"><a href="#L-1253"><span class="linenos">1253</span></a>
</span><span id="L-1254"><a href="#L-1254"><span class="linenos">1254</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-1255"><a href="#L-1255"><span class="linenos">1255</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit the gradient boosting model.</span>
</span><span id="L-1256"><a href="#L-1256"><span class="linenos">1256</span></a>
</span><span id="L-1257"><a href="#L-1257"><span class="linenos">1257</span></a><span class="sd">        Parameters</span>
</span><span id="L-1258"><a href="#L-1258"><span class="linenos">1258</span></a><span class="sd">        ----------</span>
</span><span id="L-1259"><a href="#L-1259"><span class="linenos">1259</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="L-1260"><a href="#L-1260"><span class="linenos">1260</span></a><span class="sd">            Data matrix</span>
</span><span id="L-1261"><a href="#L-1261"><span class="linenos">1261</span></a>
</span><span id="L-1262"><a href="#L-1262"><span class="linenos">1262</span></a><span class="sd">        y : structured array, shape = (n_samples,)</span>
</span><span id="L-1263"><a href="#L-1263"><span class="linenos">1263</span></a><span class="sd">            A structured array containing the binary event indicator</span>
</span><span id="L-1264"><a href="#L-1264"><span class="linenos">1264</span></a><span class="sd">            as first field, and time of event or time of censoring as</span>
</span><span id="L-1265"><a href="#L-1265"><span class="linenos">1265</span></a><span class="sd">            second field.</span>
</span><span id="L-1266"><a href="#L-1266"><span class="linenos">1266</span></a>
</span><span id="L-1267"><a href="#L-1267"><span class="linenos">1267</span></a><span class="sd">        sample_weight : array-like, shape = (n_samples,), optional</span>
</span><span id="L-1268"><a href="#L-1268"><span class="linenos">1268</span></a><span class="sd">            Weights given to each sample. If omitted, all samples have weight 1.</span>
</span><span id="L-1269"><a href="#L-1269"><span class="linenos">1269</span></a>
</span><span id="L-1270"><a href="#L-1270"><span class="linenos">1270</span></a><span class="sd">        monitor : callable, optional</span>
</span><span id="L-1271"><a href="#L-1271"><span class="linenos">1271</span></a><span class="sd">            The monitor is called after each iteration with the current</span>
</span><span id="L-1272"><a href="#L-1272"><span class="linenos">1272</span></a><span class="sd">            iteration, a reference to the estimator and the local variables of</span>
</span><span id="L-1273"><a href="#L-1273"><span class="linenos">1273</span></a><span class="sd">            ``_fit_stages`` as keyword arguments ``callable(i, self,</span>
</span><span id="L-1274"><a href="#L-1274"><span class="linenos">1274</span></a><span class="sd">            locals())``. If the callable returns ``True`` the fitting procedure</span>
</span><span id="L-1275"><a href="#L-1275"><span class="linenos">1275</span></a><span class="sd">            is stopped. The monitor can be used for various things such as</span>
</span><span id="L-1276"><a href="#L-1276"><span class="linenos">1276</span></a><span class="sd">            computing held-out estimates, early stopping, model introspect, and</span>
</span><span id="L-1277"><a href="#L-1277"><span class="linenos">1277</span></a><span class="sd">            snapshoting.</span>
</span><span id="L-1278"><a href="#L-1278"><span class="linenos">1278</span></a>
</span><span id="L-1279"><a href="#L-1279"><span class="linenos">1279</span></a><span class="sd">        Returns</span>
</span><span id="L-1280"><a href="#L-1280"><span class="linenos">1280</span></a><span class="sd">        -------</span>
</span><span id="L-1281"><a href="#L-1281"><span class="linenos">1281</span></a><span class="sd">        self : object</span>
</span><span id="L-1282"><a href="#L-1282"><span class="linenos">1282</span></a><span class="sd">            Returns self.</span>
</span><span id="L-1283"><a href="#L-1283"><span class="linenos">1283</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1284"><a href="#L-1284"><span class="linenos">1284</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>
</span><span id="L-1285"><a href="#L-1285"><span class="linenos">1285</span></a>
</span><span id="L-1286"><a href="#L-1286"><span class="linenos">1286</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span><span class="p">:</span>
</span><span id="L-1287"><a href="#L-1287"><span class="linenos">1287</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_state</span><span class="p">()</span>
</span><span id="L-1288"><a href="#L-1288"><span class="linenos">1288</span></a>
</span><span id="L-1289"><a href="#L-1289"><span class="linenos">1289</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
</span><span id="L-1290"><a href="#L-1290"><span class="linenos">1290</span></a>            <span class="n">X</span><span class="p">,</span>
</span><span id="L-1291"><a href="#L-1291"><span class="linenos">1291</span></a>            <span class="n">ensure_min_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="L-1292"><a href="#L-1292"><span class="linenos">1292</span></a>            <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
</span><span id="L-1293"><a href="#L-1293"><span class="linenos">1293</span></a>            <span class="n">accept_sparse</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">,</span> <span class="s2">&quot;coo&quot;</span><span class="p">],</span>
</span><span id="L-1294"><a href="#L-1294"><span class="linenos">1294</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">,</span>
</span><span id="L-1295"><a href="#L-1295"><span class="linenos">1295</span></a>        <span class="p">)</span>
</span><span id="L-1296"><a href="#L-1296"><span class="linenos">1296</span></a>        <span class="n">event</span><span class="p">,</span> <span class="n">time</span> <span class="o">=</span> <span class="n">check_array_survival</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="L-1297"><a href="#L-1297"><span class="linenos">1297</span></a>
</span><span id="L-1298"><a href="#L-1298"><span class="linenos">1298</span></a>        <span class="n">sample_weight_is_none</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="L-1299"><a href="#L-1299"><span class="linenos">1299</span></a>        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</span><span id="L-1300"><a href="#L-1300"><span class="linenos">1300</span></a>
</span><span id="L-1301"><a href="#L-1301"><span class="linenos">1301</span></a>        <span class="k">if</span> <span class="n">sample_weight_is_none</span><span class="p">:</span>
</span><span id="L-1302"><a href="#L-1302"><span class="linenos">1302</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span><span id="L-1303"><a href="#L-1303"><span class="linenos">1303</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1304"><a href="#L-1304"><span class="linenos">1304</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="L-1305"><a href="#L-1305"><span class="linenos">1305</span></a>
</span><span id="L-1306"><a href="#L-1306"><span class="linenos">1306</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_features</span><span class="p">()</span>
</span><span id="L-1307"><a href="#L-1307"><span class="linenos">1307</span></a>
</span><span id="L-1308"><a href="#L-1308"><span class="linenos">1308</span></a>        <span class="c1"># self.loss is guaranteed to be a string</span>
</span><span id="L-1309"><a href="#L-1309"><span class="linenos">1309</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss</span><span class="p">(</span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="L-1310"><a href="#L-1310"><span class="linenos">1310</span></a>
</span><span id="L-1311"><a href="#L-1311"><span class="linenos">1311</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="p">(</span><span class="n">CensoredSquaredLoss</span><span class="p">,</span> <span class="n">IPCWLeastSquaresError</span><span class="p">)):</span>
</span><span id="L-1312"><a href="#L-1312"><span class="linenos">1312</span></a>            <span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
</span><span id="L-1313"><a href="#L-1313"><span class="linenos">1313</span></a>
</span><span id="L-1314"><a href="#L-1314"><span class="linenos">1314</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1315"><a href="#L-1315"><span class="linenos">1315</span></a>            <span class="p">(</span>
</span><span id="L-1316"><a href="#L-1316"><span class="linenos">1316</span></a>                <span class="n">X_train</span><span class="p">,</span>
</span><span id="L-1317"><a href="#L-1317"><span class="linenos">1317</span></a>                <span class="n">X_val</span><span class="p">,</span>
</span><span id="L-1318"><a href="#L-1318"><span class="linenos">1318</span></a>                <span class="n">event_train</span><span class="p">,</span>
</span><span id="L-1319"><a href="#L-1319"><span class="linenos">1319</span></a>                <span class="n">event_val</span><span class="p">,</span>
</span><span id="L-1320"><a href="#L-1320"><span class="linenos">1320</span></a>                <span class="n">time_train</span><span class="p">,</span>
</span><span id="L-1321"><a href="#L-1321"><span class="linenos">1321</span></a>                <span class="n">time_val</span><span class="p">,</span>
</span><span id="L-1322"><a href="#L-1322"><span class="linenos">1322</span></a>                <span class="n">sample_weight_train</span><span class="p">,</span>
</span><span id="L-1323"><a href="#L-1323"><span class="linenos">1323</span></a>                <span class="n">sample_weight_val</span><span class="p">,</span>
</span><span id="L-1324"><a href="#L-1324"><span class="linenos">1324</span></a>            <span class="p">)</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
</span><span id="L-1325"><a href="#L-1325"><span class="linenos">1325</span></a>                <span class="n">X</span><span class="p">,</span>
</span><span id="L-1326"><a href="#L-1326"><span class="linenos">1326</span></a>                <span class="n">event</span><span class="p">,</span>
</span><span id="L-1327"><a href="#L-1327"><span class="linenos">1327</span></a>                <span class="n">time</span><span class="p">,</span>
</span><span id="L-1328"><a href="#L-1328"><span class="linenos">1328</span></a>                <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="L-1329"><a href="#L-1329"><span class="linenos">1329</span></a>                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
</span><span id="L-1330"><a href="#L-1330"><span class="linenos">1330</span></a>                <span class="n">test_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_fraction</span><span class="p">,</span>
</span><span id="L-1331"><a href="#L-1331"><span class="linenos">1331</span></a>                <span class="n">stratify</span><span class="o">=</span><span class="n">event</span><span class="p">,</span>
</span><span id="L-1332"><a href="#L-1332"><span class="linenos">1332</span></a>            <span class="p">)</span>
</span><span id="L-1333"><a href="#L-1333"><span class="linenos">1333</span></a>            <span class="n">y_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
</span><span id="L-1334"><a href="#L-1334"><span class="linenos">1334</span></a>                <span class="nb">zip</span><span class="p">(</span><span class="n">event_val</span><span class="p">,</span> <span class="n">time_val</span><span class="p">),</span>
</span><span id="L-1335"><a href="#L-1335"><span class="linenos">1335</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;event&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span>
</span><span id="L-1336"><a href="#L-1336"><span class="linenos">1336</span></a>            <span class="p">)</span>
</span><span id="L-1337"><a href="#L-1337"><span class="linenos">1337</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1338"><a href="#L-1338"><span class="linenos">1338</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">sample_weight_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span>
</span><span id="L-1339"><a href="#L-1339"><span class="linenos">1339</span></a>            <span class="n">event_train</span><span class="p">,</span> <span class="n">time_train</span> <span class="o">=</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span>
</span><span id="L-1340"><a href="#L-1340"><span class="linenos">1340</span></a>            <span class="n">X_val</span> <span class="o">=</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">sample_weight_val</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1341"><a href="#L-1341"><span class="linenos">1341</span></a>
</span><span id="L-1342"><a href="#L-1342"><span class="linenos">1342</span></a>        <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
</span><span id="L-1343"><a href="#L-1343"><span class="linenos">1343</span></a>            <span class="nb">zip</span><span class="p">(</span><span class="n">event_train</span><span class="p">,</span> <span class="n">time_train</span><span class="p">),</span>
</span><span id="L-1344"><a href="#L-1344"><span class="linenos">1344</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;event&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span>
</span><span id="L-1345"><a href="#L-1345"><span class="linenos">1345</span></a>        <span class="p">)</span>
</span><span id="L-1346"><a href="#L-1346"><span class="linenos">1346</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-1347"><a href="#L-1347"><span class="linenos">1347</span></a>
</span><span id="L-1348"><a href="#L-1348"><span class="linenos">1348</span></a>        <span class="c1"># First time calling fit.</span>
</span><span id="L-1349"><a href="#L-1349"><span class="linenos">1349</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_fitted</span><span class="p">():</span>
</span><span id="L-1350"><a href="#L-1350"><span class="linenos">1350</span></a>            <span class="c1"># init state</span>
</span><span id="L-1351"><a href="#L-1351"><span class="linenos">1351</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_init_state</span><span class="p">()</span>
</span><span id="L-1352"><a href="#L-1352"><span class="linenos">1352</span></a>
</span><span id="L-1353"><a href="#L-1353"><span class="linenos">1353</span></a>            <span class="n">raw_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="L-1354"><a href="#L-1354"><span class="linenos">1354</span></a>                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span><span class="p">),</span>
</span><span id="L-1355"><a href="#L-1355"><span class="linenos">1355</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
</span><span id="L-1356"><a href="#L-1356"><span class="linenos">1356</span></a>            <span class="p">)</span>
</span><span id="L-1357"><a href="#L-1357"><span class="linenos">1357</span></a>
</span><span id="L-1358"><a href="#L-1358"><span class="linenos">1358</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-1359"><a href="#L-1359"><span class="linenos">1359</span></a>
</span><span id="L-1360"><a href="#L-1360"><span class="linenos">1360</span></a>            <span class="c1"># The rng state must be preserved if warm_start is True</span>
</span><span id="L-1361"><a href="#L-1361"><span class="linenos">1361</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="L-1362"><a href="#L-1362"><span class="linenos">1362</span></a>
</span><span id="L-1363"><a href="#L-1363"><span class="linenos">1363</span></a>        <span class="c1"># warm start: this is not the first time fit was called</span>
</span><span id="L-1364"><a href="#L-1364"><span class="linenos">1364</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1365"><a href="#L-1365"><span class="linenos">1365</span></a>            <span class="c1"># add more estimators to fitted model</span>
</span><span id="L-1366"><a href="#L-1366"><span class="linenos">1366</span></a>            <span class="c1"># invariant: warm_start = True</span>
</span><span id="L-1367"><a href="#L-1367"><span class="linenos">1367</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="L-1368"><a href="#L-1368"><span class="linenos">1368</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-1369"><a href="#L-1369"><span class="linenos">1369</span></a>                    <span class="s2">&quot;n_estimators=</span><span class="si">%d</span><span class="s2"> must be larger or equal to &quot;</span>
</span><span id="L-1370"><a href="#L-1370"><span class="linenos">1370</span></a>                    <span class="s2">&quot;estimators_.shape[0]=</span><span class="si">%d</span><span class="s2"> when &quot;</span>
</span><span id="L-1371"><a href="#L-1371"><span class="linenos">1371</span></a>                    <span class="s2">&quot;warm_start==True&quot;</span> <span class="o">%</span> <span class="p">(</span>
</span><span id="L-1372"><a href="#L-1372"><span class="linenos">1372</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="L-1373"><a href="#L-1373"><span class="linenos">1373</span></a>                <span class="p">)</span>
</span><span id="L-1374"><a href="#L-1374"><span class="linenos">1374</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-1375"><a href="#L-1375"><span class="linenos">1375</span></a>            <span class="c1"># The requirements of _raw_predict</span>
</span><span id="L-1376"><a href="#L-1376"><span class="linenos">1376</span></a>            <span class="c1"># are more constrained than fit. It accepts only CSR</span>
</span><span id="L-1377"><a href="#L-1377"><span class="linenos">1377</span></a>            <span class="c1"># matrices. Finite values have already been checked in _validate_data.</span>
</span><span id="L-1378"><a href="#L-1378"><span class="linenos">1378</span></a>            <span class="n">X_train</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span>
</span><span id="L-1379"><a href="#L-1379"><span class="linenos">1379</span></a>                <span class="n">X_train</span><span class="p">,</span>
</span><span id="L-1380"><a href="#L-1380"><span class="linenos">1380</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">,</span>
</span><span id="L-1381"><a href="#L-1381"><span class="linenos">1381</span></a>                <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
</span><span id="L-1382"><a href="#L-1382"><span class="linenos">1382</span></a>                <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span>
</span><span id="L-1383"><a href="#L-1383"><span class="linenos">1383</span></a>                <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-1384"><a href="#L-1384"><span class="linenos">1384</span></a>            <span class="p">)</span>
</span><span id="L-1385"><a href="#L-1385"><span class="linenos">1385</span></a>            <span class="n">raw_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span id="L-1386"><a href="#L-1386"><span class="linenos">1386</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_resize_state</span><span class="p">()</span>
</span><span id="L-1387"><a href="#L-1387"><span class="linenos">1387</span></a>
</span><span id="L-1388"><a href="#L-1388"><span class="linenos">1388</span></a>            <span class="c1"># apply dropout to last stage of previous fit</span>
</span><span id="L-1389"><a href="#L-1389"><span class="linenos">1389</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-1390"><a href="#L-1390"><span class="linenos">1390</span></a>                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span><span class="p">):</span>
</span><span id="L-1391"><a href="#L-1391"><span class="linenos">1391</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span>
</span><span id="L-1392"><a href="#L-1392"><span class="linenos">1392</span></a>                        <span class="c1"># pylint: disable-next=access-member-before-definition</span>
</span><span id="L-1393"><a href="#L-1393"><span class="linenos">1393</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="L-1394"><a href="#L-1394"><span class="linenos">1394</span></a>                        <span class="n">X_train</span><span class="p">,</span>
</span><span id="L-1395"><a href="#L-1395"><span class="linenos">1395</span></a>                        <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="L-1396"><a href="#L-1396"><span class="linenos">1396</span></a>                        <span class="n">k</span><span class="p">,</span>
</span><span id="L-1397"><a href="#L-1397"><span class="linenos">1397</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span>
</span><span id="L-1398"><a href="#L-1398"><span class="linenos">1398</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">,</span>
</span><span id="L-1399"><a href="#L-1399"><span class="linenos">1399</span></a>                    <span class="p">)</span>
</span><span id="L-1400"><a href="#L-1400"><span class="linenos">1400</span></a>
</span><span id="L-1401"><a href="#L-1401"><span class="linenos">1401</span></a>        <span class="n">scale</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="L-1402"><a href="#L-1402"><span class="linenos">1402</span></a>
</span><span id="L-1403"><a href="#L-1403"><span class="linenos">1403</span></a>        <span class="c1"># fit the boosting stages</span>
</span><span id="L-1404"><a href="#L-1404"><span class="linenos">1404</span></a>        <span class="n">n_stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_stages</span><span class="p">(</span>
</span><span id="L-1405"><a href="#L-1405"><span class="linenos">1405</span></a>            <span class="n">X_train</span><span class="p">,</span>
</span><span id="L-1406"><a href="#L-1406"><span class="linenos">1406</span></a>            <span class="n">y_train</span><span class="p">,</span>
</span><span id="L-1407"><a href="#L-1407"><span class="linenos">1407</span></a>            <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="L-1408"><a href="#L-1408"><span class="linenos">1408</span></a>            <span class="n">sample_weight_train</span><span class="p">,</span>
</span><span id="L-1409"><a href="#L-1409"><span class="linenos">1409</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">,</span>
</span><span id="L-1410"><a href="#L-1410"><span class="linenos">1410</span></a>            <span class="n">X_val</span><span class="p">,</span>
</span><span id="L-1411"><a href="#L-1411"><span class="linenos">1411</span></a>            <span class="n">y_val</span><span class="p">,</span>
</span><span id="L-1412"><a href="#L-1412"><span class="linenos">1412</span></a>            <span class="n">sample_weight_val</span><span class="p">,</span>
</span><span id="L-1413"><a href="#L-1413"><span class="linenos">1413</span></a>            <span class="n">scale</span><span class="p">,</span>
</span><span id="L-1414"><a href="#L-1414"><span class="linenos">1414</span></a>            <span class="n">begin_at_stage</span><span class="p">,</span>
</span><span id="L-1415"><a href="#L-1415"><span class="linenos">1415</span></a>            <span class="n">monitor</span><span class="p">,</span>
</span><span id="L-1416"><a href="#L-1416"><span class="linenos">1416</span></a>        <span class="p">)</span>
</span><span id="L-1417"><a href="#L-1417"><span class="linenos">1417</span></a>        <span class="c1"># change shape of arrays after fit (early-stopping or additional tests)</span>
</span><span id="L-1418"><a href="#L-1418"><span class="linenos">1418</span></a>        <span class="k">if</span> <span class="n">n_stages</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="L-1419"><a href="#L-1419"><span class="linenos">1419</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_shrink_state</span><span class="p">(</span><span class="n">n_stages</span><span class="p">)</span>
</span><span id="L-1420"><a href="#L-1420"><span class="linenos">1420</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">=</span> <span class="n">n_stages</span>
</span><span id="L-1421"><a href="#L-1421"><span class="linenos">1421</span></a>
</span><span id="L-1422"><a href="#L-1422"><span class="linenos">1422</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_baseline_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">event_train</span><span class="p">,</span> <span class="n">time_train</span><span class="p">)</span>
</span><span id="L-1423"><a href="#L-1423"><span class="linenos">1423</span></a>
</span><span id="L-1424"><a href="#L-1424"><span class="linenos">1424</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="L-1425"><a href="#L-1425"><span class="linenos">1425</span></a>
</span><span id="L-1426"><a href="#L-1426"><span class="linenos">1426</span></a>    <span class="k">def</span> <span class="nf">_set_baseline_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">):</span>
</span><span id="L-1427"><a href="#L-1427"><span class="linenos">1427</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="n">CoxPH</span><span class="p">):</span>
</span><span id="L-1428"><a href="#L-1428"><span class="linenos">1428</span></a>            <span class="n">X_pred</span> <span class="o">=</span> <span class="n">X</span>
</span><span id="L-1429"><a href="#L-1429"><span class="linenos">1429</span></a>            <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
</span><span id="L-1430"><a href="#L-1430"><span class="linenos">1430</span></a>                <span class="n">X_pred</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">asformat</span><span class="p">(</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
</span><span id="L-1431"><a href="#L-1431"><span class="linenos">1431</span></a>            <span class="n">risk_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X_pred</span><span class="p">)</span>
</span><span id="L-1432"><a href="#L-1432"><span class="linenos">1432</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="o">=</span> <span class="n">BreslowEstimator</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">risk_scores</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</span><span id="L-1433"><a href="#L-1433"><span class="linenos">1433</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1434"><a href="#L-1434"><span class="linenos">1434</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1435"><a href="#L-1435"><span class="linenos">1435</span></a>
</span><span id="L-1436"><a href="#L-1436"><span class="linenos">1436</span></a>    <span class="k">def</span> <span class="nf">_dropout_predict_stage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">score</span><span class="p">):</span>
</span><span id="L-1437"><a href="#L-1437"><span class="linenos">1437</span></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
</span><span id="L-1438"><a href="#L-1438"><span class="linenos">1438</span></a>            <span class="n">tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">tree_</span>
</span><span id="L-1439"><a href="#L-1439"><span class="linenos">1439</span></a>            <span class="n">score</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> \
</span><span id="L-1440"><a href="#L-1440"><span class="linenos">1440</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="L-1441"><a href="#L-1441"><span class="linenos">1441</span></a>        <span class="k">return</span> <span class="n">score</span>
</span><span id="L-1442"><a href="#L-1442"><span class="linenos">1442</span></a>
</span><span id="L-1443"><a href="#L-1443"><span class="linenos">1443</span></a>    <span class="k">def</span> <span class="nf">_dropout_raw_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-1444"><a href="#L-1444"><span class="linenos">1444</span></a>        <span class="n">raw_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict_init</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-1445"><a href="#L-1445"><span class="linenos">1445</span></a>
</span><span id="L-1446"><a href="#L-1446"><span class="linenos">1446</span></a>        <span class="n">n_estimators</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span>
</span><span id="L-1447"><a href="#L-1447"><span class="linenos">1447</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="L-1448"><a href="#L-1448"><span class="linenos">1448</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_dropout_predict_stage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">)</span>
</span><span id="L-1449"><a href="#L-1449"><span class="linenos">1449</span></a>
</span><span id="L-1450"><a href="#L-1450"><span class="linenos">1450</span></a>        <span class="k">return</span> <span class="n">raw_predictions</span>
</span><span id="L-1451"><a href="#L-1451"><span class="linenos">1451</span></a>
</span><span id="L-1452"><a href="#L-1452"><span class="linenos">1452</span></a>    <span class="k">def</span> <span class="nf">_dropout_staged_raw_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-1453"><a href="#L-1453"><span class="linenos">1453</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
</span><span id="L-1454"><a href="#L-1454"><span class="linenos">1454</span></a>        <span class="n">raw_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict_init</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-1455"><a href="#L-1455"><span class="linenos">1455</span></a>
</span><span id="L-1456"><a href="#L-1456"><span class="linenos">1456</span></a>        <span class="n">n_estimators</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span>
</span><span id="L-1457"><a href="#L-1457"><span class="linenos">1457</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="L-1458"><a href="#L-1458"><span class="linenos">1458</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_dropout_predict_stage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">)</span>
</span><span id="L-1459"><a href="#L-1459"><span class="linenos">1459</span></a>            <span class="k">yield</span> <span class="n">raw_predictions</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="L-1460"><a href="#L-1460"><span class="linenos">1460</span></a>
</span><span id="L-1461"><a href="#L-1461"><span class="linenos">1461</span></a>    <span class="k">def</span> <span class="nf">_raw_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-1462"><a href="#L-1462"><span class="linenos">1462</span></a>        <span class="c1"># if dropout wasn&#39;t used during training, proceed as usual,</span>
</span><span id="L-1463"><a href="#L-1463"><span class="linenos">1463</span></a>        <span class="c1"># otherwise consider scaling factor of individual trees</span>
</span><span id="L-1464"><a href="#L-1464"><span class="linenos">1464</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="L-1465"><a href="#L-1465"><span class="linenos">1465</span></a>            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-1466"><a href="#L-1466"><span class="linenos">1466</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dropout_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-1467"><a href="#L-1467"><span class="linenos">1467</span></a>
</span><span id="L-1468"><a href="#L-1468"><span class="linenos">1468</span></a>    <span class="k">def</span> <span class="nf">_init_decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
</span><span id="L-1469"><a href="#L-1469"><span class="linenos">1469</span></a>        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_init_decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-1470"><a href="#L-1470"><span class="linenos">1470</span></a>
</span><span id="L-1471"><a href="#L-1471"><span class="linenos">1471</span></a>    <span class="k">def</span> <span class="nf">_decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
</span><span id="L-1472"><a href="#L-1472"><span class="linenos">1472</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-1473"><a href="#L-1473"><span class="linenos">1473</span></a>
</span><span id="L-1474"><a href="#L-1474"><span class="linenos">1474</span></a>    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-1475"><a href="#L-1475"><span class="linenos">1475</span></a>        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-1476"><a href="#L-1476"><span class="linenos">1476</span></a>        <span class="k">if</span> <span class="n">score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-1477"><a href="#L-1477"><span class="linenos">1477</span></a>            <span class="n">score</span> <span class="o">=</span> <span class="n">score</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span><span id="L-1478"><a href="#L-1478"><span class="linenos">1478</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">_scale_raw_prediction</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</span><span id="L-1479"><a href="#L-1479"><span class="linenos">1479</span></a>
</span><span id="L-1480"><a href="#L-1480"><span class="linenos">1480</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-1481"><a href="#L-1481"><span class="linenos">1481</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict risk scores.</span>
</span><span id="L-1482"><a href="#L-1482"><span class="linenos">1482</span></a>
</span><span id="L-1483"><a href="#L-1483"><span class="linenos">1483</span></a><span class="sd">        If `loss=&#39;coxph&#39;`, predictions can be interpreted as log hazard ratio</span>
</span><span id="L-1484"><a href="#L-1484"><span class="linenos">1484</span></a><span class="sd">        similar to the linear predictor of a Cox proportional hazards</span>
</span><span id="L-1485"><a href="#L-1485"><span class="linenos">1485</span></a><span class="sd">        model. If `loss=&#39;squared&#39;` or `loss=&#39;ipcwls&#39;`, predictions are the</span>
</span><span id="L-1486"><a href="#L-1486"><span class="linenos">1486</span></a><span class="sd">        time to event.</span>
</span><span id="L-1487"><a href="#L-1487"><span class="linenos">1487</span></a>
</span><span id="L-1488"><a href="#L-1488"><span class="linenos">1488</span></a><span class="sd">        Parameters</span>
</span><span id="L-1489"><a href="#L-1489"><span class="linenos">1489</span></a><span class="sd">        ----------</span>
</span><span id="L-1490"><a href="#L-1490"><span class="linenos">1490</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="L-1491"><a href="#L-1491"><span class="linenos">1491</span></a><span class="sd">            The input samples.</span>
</span><span id="L-1492"><a href="#L-1492"><span class="linenos">1492</span></a>
</span><span id="L-1493"><a href="#L-1493"><span class="linenos">1493</span></a><span class="sd">        Returns</span>
</span><span id="L-1494"><a href="#L-1494"><span class="linenos">1494</span></a><span class="sd">        -------</span>
</span><span id="L-1495"><a href="#L-1495"><span class="linenos">1495</span></a><span class="sd">        y : ndarray, shape = (n_samples,)</span>
</span><span id="L-1496"><a href="#L-1496"><span class="linenos">1496</span></a><span class="sd">            The risk scores.</span>
</span><span id="L-1497"><a href="#L-1497"><span class="linenos">1497</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1498"><a href="#L-1498"><span class="linenos">1498</span></a>        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">)</span>
</span><span id="L-1499"><a href="#L-1499"><span class="linenos">1499</span></a>
</span><span id="L-1500"><a href="#L-1500"><span class="linenos">1500</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
</span><span id="L-1501"><a href="#L-1501"><span class="linenos">1501</span></a>                                <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">)</span>
</span><span id="L-1502"><a href="#L-1502"><span class="linenos">1502</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-1503"><a href="#L-1503"><span class="linenos">1503</span></a>
</span><span id="L-1504"><a href="#L-1504"><span class="linenos">1504</span></a>    <span class="k">def</span> <span class="nf">staged_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="L-1505"><a href="#L-1505"><span class="linenos">1505</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict risk scores at each stage for X.</span>
</span><span id="L-1506"><a href="#L-1506"><span class="linenos">1506</span></a>
</span><span id="L-1507"><a href="#L-1507"><span class="linenos">1507</span></a><span class="sd">        This method allows monitoring (i.e. determine error on testing set)</span>
</span><span id="L-1508"><a href="#L-1508"><span class="linenos">1508</span></a><span class="sd">        after each stage.</span>
</span><span id="L-1509"><a href="#L-1509"><span class="linenos">1509</span></a>
</span><span id="L-1510"><a href="#L-1510"><span class="linenos">1510</span></a><span class="sd">        If `loss=&#39;coxph&#39;`, predictions can be interpreted as log hazard ratio</span>
</span><span id="L-1511"><a href="#L-1511"><span class="linenos">1511</span></a><span class="sd">        similar to the linear predictor of a Cox proportional hazards</span>
</span><span id="L-1512"><a href="#L-1512"><span class="linenos">1512</span></a><span class="sd">        model. If `loss=&#39;squared&#39;` or `loss=&#39;ipcwls&#39;`, predictions are the</span>
</span><span id="L-1513"><a href="#L-1513"><span class="linenos">1513</span></a><span class="sd">        time to event.</span>
</span><span id="L-1514"><a href="#L-1514"><span class="linenos">1514</span></a>
</span><span id="L-1515"><a href="#L-1515"><span class="linenos">1515</span></a><span class="sd">        Parameters</span>
</span><span id="L-1516"><a href="#L-1516"><span class="linenos">1516</span></a><span class="sd">        ----------</span>
</span><span id="L-1517"><a href="#L-1517"><span class="linenos">1517</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="L-1518"><a href="#L-1518"><span class="linenos">1518</span></a><span class="sd">            The input samples.</span>
</span><span id="L-1519"><a href="#L-1519"><span class="linenos">1519</span></a>
</span><span id="L-1520"><a href="#L-1520"><span class="linenos">1520</span></a><span class="sd">        Returns</span>
</span><span id="L-1521"><a href="#L-1521"><span class="linenos">1521</span></a><span class="sd">        -------</span>
</span><span id="L-1522"><a href="#L-1522"><span class="linenos">1522</span></a><span class="sd">        y : generator of array of shape = (n_samples,)</span>
</span><span id="L-1523"><a href="#L-1523"><span class="linenos">1523</span></a><span class="sd">            The predicted value of the input samples.</span>
</span><span id="L-1524"><a href="#L-1524"><span class="linenos">1524</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1525"><a href="#L-1525"><span class="linenos">1525</span></a>        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">)</span>
</span><span id="L-1526"><a href="#L-1526"><span class="linenos">1526</span></a>
</span><span id="L-1527"><a href="#L-1527"><span class="linenos">1527</span></a>        <span class="c1"># if dropout wasn&#39;t used during training, proceed as usual,</span>
</span><span id="L-1528"><a href="#L-1528"><span class="linenos">1528</span></a>        <span class="c1"># otherwise consider scaling factor of individual trees</span>
</span><span id="L-1529"><a href="#L-1529"><span class="linenos">1529</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="L-1530"><a href="#L-1530"><span class="linenos">1530</span></a>            <span class="n">predictions_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_staged_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-1531"><a href="#L-1531"><span class="linenos">1531</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1532"><a href="#L-1532"><span class="linenos">1532</span></a>            <span class="n">predictions_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dropout_staged_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="L-1533"><a href="#L-1533"><span class="linenos">1533</span></a>
</span><span id="L-1534"><a href="#L-1534"><span class="linenos">1534</span></a>        <span class="k">for</span> <span class="n">raw_predictions</span> <span class="ow">in</span> <span class="n">predictions_iter</span><span class="p">:</span>
</span><span id="L-1535"><a href="#L-1535"><span class="linenos">1535</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">_scale_raw_prediction</span><span class="p">(</span><span class="n">raw_predictions</span><span class="p">)</span>
</span><span id="L-1536"><a href="#L-1536"><span class="linenos">1536</span></a>            <span class="k">yield</span> <span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span><span id="L-1537"><a href="#L-1537"><span class="linenos">1537</span></a>
</span><span id="L-1538"><a href="#L-1538"><span class="linenos">1538</span></a>    <span class="k">def</span> <span class="nf">_get_baseline_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-1539"><a href="#L-1539"><span class="linenos">1539</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1540"><a href="#L-1540"><span class="linenos">1540</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-1541"><a href="#L-1541"><span class="linenos">1541</span></a>                <span class="s2">&quot;`fit` must be called with the loss option set to &#39;coxph&#39;.&quot;</span><span class="p">)</span>
</span><span id="L-1542"><a href="#L-1542"><span class="linenos">1542</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span>
</span><span id="L-1543"><a href="#L-1543"><span class="linenos">1543</span></a>
</span><span id="L-1544"><a href="#L-1544"><span class="linenos">1544</span></a>    <span class="k">def</span> <span class="nf">predict_cumulative_hazard_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="L-1545"><a href="#L-1545"><span class="linenos">1545</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict cumulative hazard function.</span>
</span><span id="L-1546"><a href="#L-1546"><span class="linenos">1546</span></a>
</span><span id="L-1547"><a href="#L-1547"><span class="linenos">1547</span></a><span class="sd">        Only available if :meth:`fit` has been called with `loss = &quot;coxph&quot;`.</span>
</span><span id="L-1548"><a href="#L-1548"><span class="linenos">1548</span></a>
</span><span id="L-1549"><a href="#L-1549"><span class="linenos">1549</span></a><span class="sd">        The cumulative hazard function for an individual</span>
</span><span id="L-1550"><a href="#L-1550"><span class="linenos">1550</span></a><span class="sd">        with feature vector :math:`x` is defined as</span>
</span><span id="L-1551"><a href="#L-1551"><span class="linenos">1551</span></a>
</span><span id="L-1552"><a href="#L-1552"><span class="linenos">1552</span></a><span class="sd">        .. math::</span>
</span><span id="L-1553"><a href="#L-1553"><span class="linenos">1553</span></a>
</span><span id="L-1554"><a href="#L-1554"><span class="linenos">1554</span></a><span class="sd">            H(t \\mid x) = \\exp(f(x)) H_0(t) ,</span>
</span><span id="L-1555"><a href="#L-1555"><span class="linenos">1555</span></a>
</span><span id="L-1556"><a href="#L-1556"><span class="linenos">1556</span></a><span class="sd">        where :math:`f(\\cdot)` is the additive ensemble of base learners,</span>
</span><span id="L-1557"><a href="#L-1557"><span class="linenos">1557</span></a><span class="sd">        and :math:`H_0(t)` is the baseline hazard function,</span>
</span><span id="L-1558"><a href="#L-1558"><span class="linenos">1558</span></a><span class="sd">        estimated by Breslow&#39;s estimator.</span>
</span><span id="L-1559"><a href="#L-1559"><span class="linenos">1559</span></a>
</span><span id="L-1560"><a href="#L-1560"><span class="linenos">1560</span></a><span class="sd">        Parameters</span>
</span><span id="L-1561"><a href="#L-1561"><span class="linenos">1561</span></a><span class="sd">        ----------</span>
</span><span id="L-1562"><a href="#L-1562"><span class="linenos">1562</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="L-1563"><a href="#L-1563"><span class="linenos">1563</span></a><span class="sd">            Data matrix.</span>
</span><span id="L-1564"><a href="#L-1564"><span class="linenos">1564</span></a>
</span><span id="L-1565"><a href="#L-1565"><span class="linenos">1565</span></a><span class="sd">        return_array : boolean, default: False</span>
</span><span id="L-1566"><a href="#L-1566"><span class="linenos">1566</span></a><span class="sd">            If set, return an array with the cumulative hazard rate</span>
</span><span id="L-1567"><a href="#L-1567"><span class="linenos">1567</span></a><span class="sd">            for each `self.unique_times_`, otherwise an array of</span>
</span><span id="L-1568"><a href="#L-1568"><span class="linenos">1568</span></a><span class="sd">            :class:`survivalist.functions.StepFunction`.</span>
</span><span id="L-1569"><a href="#L-1569"><span class="linenos">1569</span></a>
</span><span id="L-1570"><a href="#L-1570"><span class="linenos">1570</span></a><span class="sd">        Returns</span>
</span><span id="L-1571"><a href="#L-1571"><span class="linenos">1571</span></a><span class="sd">        -------</span>
</span><span id="L-1572"><a href="#L-1572"><span class="linenos">1572</span></a><span class="sd">        cum_hazard : ndarray</span>
</span><span id="L-1573"><a href="#L-1573"><span class="linenos">1573</span></a><span class="sd">            If `return_array` is set, an array with the cumulative hazard rate</span>
</span><span id="L-1574"><a href="#L-1574"><span class="linenos">1574</span></a><span class="sd">            for each `self.unique_times_`, otherwise an array of length `n_samples`</span>
</span><span id="L-1575"><a href="#L-1575"><span class="linenos">1575</span></a><span class="sd">            of :class:`survivalist.functions.StepFunction` instances will be returned.</span>
</span><span id="L-1576"><a href="#L-1576"><span class="linenos">1576</span></a>
</span><span id="L-1577"><a href="#L-1577"><span class="linenos">1577</span></a><span class="sd">        Examples</span>
</span><span id="L-1578"><a href="#L-1578"><span class="linenos">1578</span></a><span class="sd">        --------</span>
</span><span id="L-1579"><a href="#L-1579"><span class="linenos">1579</span></a><span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
</span><span id="L-1580"><a href="#L-1580"><span class="linenos">1580</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.datasets import load_whas500</span>
</span><span id="L-1581"><a href="#L-1581"><span class="linenos">1581</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.ensemble import GradientBoostingSurvivalAnalysis</span>
</span><span id="L-1582"><a href="#L-1582"><span class="linenos">1582</span></a>
</span><span id="L-1583"><a href="#L-1583"><span class="linenos">1583</span></a><span class="sd">        Load the data.</span>
</span><span id="L-1584"><a href="#L-1584"><span class="linenos">1584</span></a>
</span><span id="L-1585"><a href="#L-1585"><span class="linenos">1585</span></a><span class="sd">        &gt;&gt;&gt; X, y = load_whas500()</span>
</span><span id="L-1586"><a href="#L-1586"><span class="linenos">1586</span></a><span class="sd">        &gt;&gt;&gt; X = X.astype(float)</span>
</span><span id="L-1587"><a href="#L-1587"><span class="linenos">1587</span></a>
</span><span id="L-1588"><a href="#L-1588"><span class="linenos">1588</span></a><span class="sd">        Fit the model.</span>
</span><span id="L-1589"><a href="#L-1589"><span class="linenos">1589</span></a>
</span><span id="L-1590"><a href="#L-1590"><span class="linenos">1590</span></a><span class="sd">        &gt;&gt;&gt; estimator = GradientBoostingSurvivalAnalysis(loss=&quot;coxph&quot;).fit(X, y)</span>
</span><span id="L-1591"><a href="#L-1591"><span class="linenos">1591</span></a>
</span><span id="L-1592"><a href="#L-1592"><span class="linenos">1592</span></a><span class="sd">        Estimate the cumulative hazard function for the first 10 samples.</span>
</span><span id="L-1593"><a href="#L-1593"><span class="linenos">1593</span></a>
</span><span id="L-1594"><a href="#L-1594"><span class="linenos">1594</span></a><span class="sd">        &gt;&gt;&gt; chf_funcs = estimator.predict_cumulative_hazard_function(X.iloc[:10])</span>
</span><span id="L-1595"><a href="#L-1595"><span class="linenos">1595</span></a>
</span><span id="L-1596"><a href="#L-1596"><span class="linenos">1596</span></a><span class="sd">        Plot the estimated cumulative hazard functions.</span>
</span><span id="L-1597"><a href="#L-1597"><span class="linenos">1597</span></a>
</span><span id="L-1598"><a href="#L-1598"><span class="linenos">1598</span></a><span class="sd">        &gt;&gt;&gt; for fn in chf_funcs:</span>
</span><span id="L-1599"><a href="#L-1599"><span class="linenos">1599</span></a><span class="sd">        ...     plt.step(fn.x, fn(fn.x), where=&quot;post&quot;)</span>
</span><span id="L-1600"><a href="#L-1600"><span class="linenos">1600</span></a><span class="sd">        ...</span>
</span><span id="L-1601"><a href="#L-1601"><span class="linenos">1601</span></a><span class="sd">        &gt;&gt;&gt; plt.ylim(0, 1)</span>
</span><span id="L-1602"><a href="#L-1602"><span class="linenos">1602</span></a><span class="sd">        &gt;&gt;&gt; plt.show()</span>
</span><span id="L-1603"><a href="#L-1603"><span class="linenos">1603</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1604"><a href="#L-1604"><span class="linenos">1604</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_cumulative_hazard_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">return_array</span><span class="p">)</span>
</span><span id="L-1605"><a href="#L-1605"><span class="linenos">1605</span></a>
</span><span id="L-1606"><a href="#L-1606"><span class="linenos">1606</span></a>    <span class="k">def</span> <span class="nf">predict_survival_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="L-1607"><a href="#L-1607"><span class="linenos">1607</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict survival function.</span>
</span><span id="L-1608"><a href="#L-1608"><span class="linenos">1608</span></a>
</span><span id="L-1609"><a href="#L-1609"><span class="linenos">1609</span></a><span class="sd">        Only available if :meth:`fit` has been called with `loss = &quot;coxph&quot;`.</span>
</span><span id="L-1610"><a href="#L-1610"><span class="linenos">1610</span></a>
</span><span id="L-1611"><a href="#L-1611"><span class="linenos">1611</span></a><span class="sd">        The survival function for an individual</span>
</span><span id="L-1612"><a href="#L-1612"><span class="linenos">1612</span></a><span class="sd">        with feature vector :math:`x` is defined as</span>
</span><span id="L-1613"><a href="#L-1613"><span class="linenos">1613</span></a>
</span><span id="L-1614"><a href="#L-1614"><span class="linenos">1614</span></a><span class="sd">        .. math::</span>
</span><span id="L-1615"><a href="#L-1615"><span class="linenos">1615</span></a>
</span><span id="L-1616"><a href="#L-1616"><span class="linenos">1616</span></a><span class="sd">            S(t \\mid x) = S_0(t)^{\\exp(f(x)} ,</span>
</span><span id="L-1617"><a href="#L-1617"><span class="linenos">1617</span></a>
</span><span id="L-1618"><a href="#L-1618"><span class="linenos">1618</span></a><span class="sd">        where :math:`f(\\cdot)` is the additive ensemble of base learners,</span>
</span><span id="L-1619"><a href="#L-1619"><span class="linenos">1619</span></a><span class="sd">        and :math:`S_0(t)` is the baseline survival function,</span>
</span><span id="L-1620"><a href="#L-1620"><span class="linenos">1620</span></a><span class="sd">        estimated by Breslow&#39;s estimator.</span>
</span><span id="L-1621"><a href="#L-1621"><span class="linenos">1621</span></a>
</span><span id="L-1622"><a href="#L-1622"><span class="linenos">1622</span></a><span class="sd">        Parameters</span>
</span><span id="L-1623"><a href="#L-1623"><span class="linenos">1623</span></a><span class="sd">        ----------</span>
</span><span id="L-1624"><a href="#L-1624"><span class="linenos">1624</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="L-1625"><a href="#L-1625"><span class="linenos">1625</span></a><span class="sd">            Data matrix.</span>
</span><span id="L-1626"><a href="#L-1626"><span class="linenos">1626</span></a>
</span><span id="L-1627"><a href="#L-1627"><span class="linenos">1627</span></a><span class="sd">        return_array : boolean, default: False</span>
</span><span id="L-1628"><a href="#L-1628"><span class="linenos">1628</span></a><span class="sd">            If set, return an array with the probability</span>
</span><span id="L-1629"><a href="#L-1629"><span class="linenos">1629</span></a><span class="sd">            of survival for each `self.unique_times_`,</span>
</span><span id="L-1630"><a href="#L-1630"><span class="linenos">1630</span></a><span class="sd">            otherwise an array of :class:`survivalist.functions.StepFunction`.</span>
</span><span id="L-1631"><a href="#L-1631"><span class="linenos">1631</span></a>
</span><span id="L-1632"><a href="#L-1632"><span class="linenos">1632</span></a><span class="sd">        Returns</span>
</span><span id="L-1633"><a href="#L-1633"><span class="linenos">1633</span></a><span class="sd">        -------</span>
</span><span id="L-1634"><a href="#L-1634"><span class="linenos">1634</span></a><span class="sd">        survival : ndarray</span>
</span><span id="L-1635"><a href="#L-1635"><span class="linenos">1635</span></a><span class="sd">            If `return_array` is set, an array with the probability of</span>
</span><span id="L-1636"><a href="#L-1636"><span class="linenos">1636</span></a><span class="sd">            survival for each `self.unique_times_`, otherwise an array of</span>
</span><span id="L-1637"><a href="#L-1637"><span class="linenos">1637</span></a><span class="sd">            length `n_samples` of :class:`survivalist.functions.StepFunction`</span>
</span><span id="L-1638"><a href="#L-1638"><span class="linenos">1638</span></a><span class="sd">            instances will be returned.</span>
</span><span id="L-1639"><a href="#L-1639"><span class="linenos">1639</span></a>
</span><span id="L-1640"><a href="#L-1640"><span class="linenos">1640</span></a><span class="sd">        Examples</span>
</span><span id="L-1641"><a href="#L-1641"><span class="linenos">1641</span></a><span class="sd">        --------</span>
</span><span id="L-1642"><a href="#L-1642"><span class="linenos">1642</span></a><span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
</span><span id="L-1643"><a href="#L-1643"><span class="linenos">1643</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.datasets import load_whas500</span>
</span><span id="L-1644"><a href="#L-1644"><span class="linenos">1644</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.ensemble import GradientBoostingSurvivalAnalysis</span>
</span><span id="L-1645"><a href="#L-1645"><span class="linenos">1645</span></a>
</span><span id="L-1646"><a href="#L-1646"><span class="linenos">1646</span></a><span class="sd">        Load the data.</span>
</span><span id="L-1647"><a href="#L-1647"><span class="linenos">1647</span></a>
</span><span id="L-1648"><a href="#L-1648"><span class="linenos">1648</span></a><span class="sd">        &gt;&gt;&gt; X, y = load_whas500()</span>
</span><span id="L-1649"><a href="#L-1649"><span class="linenos">1649</span></a><span class="sd">        &gt;&gt;&gt; X = X.astype(float)</span>
</span><span id="L-1650"><a href="#L-1650"><span class="linenos">1650</span></a>
</span><span id="L-1651"><a href="#L-1651"><span class="linenos">1651</span></a><span class="sd">        Fit the model.</span>
</span><span id="L-1652"><a href="#L-1652"><span class="linenos">1652</span></a>
</span><span id="L-1653"><a href="#L-1653"><span class="linenos">1653</span></a><span class="sd">        &gt;&gt;&gt; estimator = GradientBoostingSurvivalAnalysis(loss=&quot;coxph&quot;).fit(X, y)</span>
</span><span id="L-1654"><a href="#L-1654"><span class="linenos">1654</span></a>
</span><span id="L-1655"><a href="#L-1655"><span class="linenos">1655</span></a><span class="sd">        Estimate the survival function for the first 10 samples.</span>
</span><span id="L-1656"><a href="#L-1656"><span class="linenos">1656</span></a>
</span><span id="L-1657"><a href="#L-1657"><span class="linenos">1657</span></a><span class="sd">        &gt;&gt;&gt; surv_funcs = estimator.predict_survival_function(X.iloc[:10])</span>
</span><span id="L-1658"><a href="#L-1658"><span class="linenos">1658</span></a>
</span><span id="L-1659"><a href="#L-1659"><span class="linenos">1659</span></a><span class="sd">        Plot the estimated survival functions.</span>
</span><span id="L-1660"><a href="#L-1660"><span class="linenos">1660</span></a>
</span><span id="L-1661"><a href="#L-1661"><span class="linenos">1661</span></a><span class="sd">        &gt;&gt;&gt; for fn in surv_funcs:</span>
</span><span id="L-1662"><a href="#L-1662"><span class="linenos">1662</span></a><span class="sd">        ...     plt.step(fn.x, fn(fn.x), where=&quot;post&quot;)</span>
</span><span id="L-1663"><a href="#L-1663"><span class="linenos">1663</span></a><span class="sd">        ...</span>
</span><span id="L-1664"><a href="#L-1664"><span class="linenos">1664</span></a><span class="sd">        &gt;&gt;&gt; plt.ylim(0, 1)</span>
</span><span id="L-1665"><a href="#L-1665"><span class="linenos">1665</span></a><span class="sd">        &gt;&gt;&gt; plt.show()</span>
</span><span id="L-1666"><a href="#L-1666"><span class="linenos">1666</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1667"><a href="#L-1667"><span class="linenos">1667</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_survival_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">return_array</span><span class="p">)</span>
</span><span id="L-1668"><a href="#L-1668"><span class="linenos">1668</span></a>
</span><span id="L-1669"><a href="#L-1669"><span class="linenos">1669</span></a>    <span class="nd">@property</span>
</span><span id="L-1670"><a href="#L-1670"><span class="linenos">1670</span></a>    <span class="k">def</span> <span class="nf">unique_times_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-1671"><a href="#L-1671"><span class="linenos">1671</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">()</span><span class="o">.</span><span class="n">unique_times_</span>
</span></pre></div>


            </section>
                <section id="ComponentwiseGradientBoostingSurvivalAnalysis">
                            <input id="ComponentwiseGradientBoostingSurvivalAnalysis-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ComponentwiseGradientBoostingSurvivalAnalysis</span><wbr>(<span class="base">sklearn.ensemble._base.BaseEnsemble</span>, <span class="base"><a href="../base.html#SurvivalAnalysisMixin">survivalist.base.SurvivalAnalysisMixin</a></span>):

                <label class="view-source-button" for="ComponentwiseGradientBoostingSurvivalAnalysis-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ComponentwiseGradientBoostingSurvivalAnalysis"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-98"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-98"><span class="linenos"> 98</span></a><span class="k">class</span> <span class="nc">ComponentwiseGradientBoostingSurvivalAnalysis</span><span class="p">(</span><span class="n">BaseEnsemble</span><span class="p">,</span> <span class="n">SurvivalAnalysisMixin</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-99"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-99"><span class="linenos"> 99</span></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gradient boosting with component-wise least squares as base learner.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-100"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-100"><span class="linenos">100</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-101"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-101"><span class="linenos">101</span></a><span class="sd">    See the :ref:`User Guide &lt;/user_guide/boosting.ipynb&gt;` and [1]_ for further description.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-102"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-102"><span class="linenos">102</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-103"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-103"><span class="linenos">103</span></a><span class="sd">    Parameters</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-104"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-104"><span class="linenos">104</span></a><span class="sd">    ----------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-105"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-105"><span class="linenos">105</span></a><span class="sd">    loss : {&#39;coxph&#39;, &#39;squared&#39;, &#39;ipcwls&#39;}, optional, default: &#39;coxph&#39;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-106"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-106"><span class="linenos">106</span></a><span class="sd">        loss function to be optimized. &#39;coxph&#39; refers to partial likelihood loss</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-107"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-107"><span class="linenos">107</span></a><span class="sd">        of Cox&#39;s proportional hazards model. The loss &#39;squared&#39; minimizes a</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-108"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-108"><span class="linenos">108</span></a><span class="sd">        squared regression loss that ignores predictions beyond the time of censoring,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-109"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-109"><span class="linenos">109</span></a><span class="sd">        and &#39;ipcwls&#39; refers to inverse-probability of censoring weighted least squares error.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-110"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-110"><span class="linenos">110</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-111"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-111"><span class="linenos">111</span></a><span class="sd">    learning_rate : float, optional, default: 0.1</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-112"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-112"><span class="linenos">112</span></a><span class="sd">        learning rate shrinks the contribution of each base learner by `learning_rate`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-113"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-113"><span class="linenos">113</span></a><span class="sd">        There is a trade-off between `learning_rate` and `n_estimators`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-114"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-114"><span class="linenos">114</span></a><span class="sd">        Values must be in the range `[0.0, inf)`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-115"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-115"><span class="linenos">115</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-116"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-116"><span class="linenos">116</span></a><span class="sd">    n_estimators : int, default: 100</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-117"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-117"><span class="linenos">117</span></a><span class="sd">        The number of boosting stages to perform. Gradient boosting</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-118"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-118"><span class="linenos">118</span></a><span class="sd">        is fairly robust to over-fitting so a large number usually</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-119"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-119"><span class="linenos">119</span></a><span class="sd">        results in better performance.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-120"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-120"><span class="linenos">120</span></a><span class="sd">        Values must be in the range `[1, inf)`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-121"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-121"><span class="linenos">121</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-122"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-122"><span class="linenos">122</span></a><span class="sd">    subsample : float, optional, default: 1.0</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-123"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-123"><span class="linenos">123</span></a><span class="sd">        The fraction of samples to be used for fitting the individual base</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-124"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-124"><span class="linenos">124</span></a><span class="sd">        learners. If smaller than 1.0 this results in Stochastic Gradient</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-125"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-125"><span class="linenos">125</span></a><span class="sd">        Boosting. `subsample` interacts with the parameter `n_estimators`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-126"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-126"><span class="linenos">126</span></a><span class="sd">        Choosing `subsample &lt; 1.0` leads to a reduction of variance</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-127"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-127"><span class="linenos">127</span></a><span class="sd">        and an increase in bias.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-128"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-128"><span class="linenos">128</span></a><span class="sd">        Values must be in the range `(0.0, 1.0]`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-129"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-129"><span class="linenos">129</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-130"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-130"><span class="linenos">130</span></a><span class="sd">    warm_start : bool, default: False</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-131"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-131"><span class="linenos">131</span></a><span class="sd">        When set to ``True``, reuse the solution of the previous call to fit</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-132"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-132"><span class="linenos">132</span></a><span class="sd">        and add more estimators to the ensemble, otherwise, just erase the</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-133"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-133"><span class="linenos">133</span></a><span class="sd">        previous solution.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-134"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-134"><span class="linenos">134</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-135"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-135"><span class="linenos">135</span></a><span class="sd">    dropout_rate : float, optional, default: 0.0</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-136"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-136"><span class="linenos">136</span></a><span class="sd">        If larger than zero, the residuals at each iteration are only computed</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-137"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-137"><span class="linenos">137</span></a><span class="sd">        from a random subset of base learners. The value corresponds to the</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-138"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-138"><span class="linenos">138</span></a><span class="sd">        percentage of base learners that are dropped. In each iteration,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-139"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-139"><span class="linenos">139</span></a><span class="sd">        at least one base learner is dropped. This is an alternative regularization</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-140"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-140"><span class="linenos">140</span></a><span class="sd">        to shrinkage, i.e., setting `learning_rate &lt; 1.0`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-141"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-141"><span class="linenos">141</span></a><span class="sd">        Values must be in the range `[0.0, 1.0)`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-142"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-142"><span class="linenos">142</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-143"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-143"><span class="linenos">143</span></a><span class="sd">    random_state : int seed, RandomState instance, or None, default: None</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-144"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-144"><span class="linenos">144</span></a><span class="sd">        The seed of the pseudo random number generator to use when</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-145"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-145"><span class="linenos">145</span></a><span class="sd">        shuffling the data.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-146"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-146"><span class="linenos">146</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-147"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-147"><span class="linenos">147</span></a><span class="sd">    verbose : int, default: 0</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-148"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-148"><span class="linenos">148</span></a><span class="sd">        Enable verbose output. If 1 then it prints progress and performance</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-149"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-149"><span class="linenos">149</span></a><span class="sd">        once in a while.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-150"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-150"><span class="linenos">150</span></a><span class="sd">        Values must be in the range `[0, inf)`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-151"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-151"><span class="linenos">151</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-152"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-152"><span class="linenos">152</span></a><span class="sd">    Attributes</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-153"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-153"><span class="linenos">153</span></a><span class="sd">    ----------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-154"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-154"><span class="linenos">154</span></a><span class="sd">    coef_ : array, shape = (n_features + 1,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-155"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-155"><span class="linenos">155</span></a><span class="sd">        The aggregated coefficients. The first element `coef\_[0]` corresponds</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-156"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-156"><span class="linenos">156</span></a><span class="sd">        to the intercept. If loss is `coxph`, the intercept will always be zero.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-157"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-157"><span class="linenos">157</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-158"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-158"><span class="linenos">158</span></a><span class="sd">    estimators_ : list of base learners</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-159"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-159"><span class="linenos">159</span></a><span class="sd">        The collection of fitted sub-estimators.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-160"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-160"><span class="linenos">160</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-161"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-161"><span class="linenos">161</span></a><span class="sd">    train_score_ : ndarray, shape = (n_estimators,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-162"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-162"><span class="linenos">162</span></a><span class="sd">        The i-th score ``train_score_[i]`` is the loss of the</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-163"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-163"><span class="linenos">163</span></a><span class="sd">        model at iteration ``i`` on the in-bag sample.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-164"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-164"><span class="linenos">164</span></a><span class="sd">        If ``subsample == 1`` this is the loss on the training data.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-165"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-165"><span class="linenos">165</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-166"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-166"><span class="linenos">166</span></a><span class="sd">    oob_improvement_ : ndarray, shape = (n_estimators,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-167"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-167"><span class="linenos">167</span></a><span class="sd">        The improvement in loss on the out-of-bag samples</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-168"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-168"><span class="linenos">168</span></a><span class="sd">        relative to the previous iteration.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-169"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-169"><span class="linenos">169</span></a><span class="sd">        ``oob_improvement_[0]`` is the improvement in</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-170"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-170"><span class="linenos">170</span></a><span class="sd">        loss of the first stage over the ``init`` estimator.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-171"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-171"><span class="linenos">171</span></a><span class="sd">        Only available if ``subsample &lt; 1.0``.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-172"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-172"><span class="linenos">172</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-173"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-173"><span class="linenos">173</span></a><span class="sd">    oob_scores_ : ndarray of shape (n_estimators,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-174"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-174"><span class="linenos">174</span></a><span class="sd">        The full history of the loss values on the out-of-bag</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-175"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-175"><span class="linenos">175</span></a><span class="sd">        samples. Only available if ``subsample &lt; 1.0``.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-176"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-176"><span class="linenos">176</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-177"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-177"><span class="linenos">177</span></a><span class="sd">    oob_score_ : float</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-178"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-178"><span class="linenos">178</span></a><span class="sd">        The last value of the loss on the out-of-bag samples. It is</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-179"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-179"><span class="linenos">179</span></a><span class="sd">        the same as ``oob_scores_[-1]``. Only available if ``subsample &lt; 1.0``.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-180"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-180"><span class="linenos">180</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-181"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-181"><span class="linenos">181</span></a><span class="sd">    n_features_in_ : int</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-182"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-182"><span class="linenos">182</span></a><span class="sd">        Number of features seen during ``fit``.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-183"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-183"><span class="linenos">183</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-184"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-184"><span class="linenos">184</span></a><span class="sd">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-185"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-185"><span class="linenos">185</span></a><span class="sd">        Names of features seen during ``fit``. Defined only when `X`</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-186"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-186"><span class="linenos">186</span></a><span class="sd">        has feature names that are all strings.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-187"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-187"><span class="linenos">187</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-188"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-188"><span class="linenos">188</span></a><span class="sd">    unique_times_ : array of shape = (n_unique_times,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-189"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-189"><span class="linenos">189</span></a><span class="sd">        Unique time points.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-190"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-190"><span class="linenos">190</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-191"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-191"><span class="linenos">191</span></a><span class="sd">    References</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-192"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-192"><span class="linenos">192</span></a><span class="sd">    ----------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-193"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-193"><span class="linenos">193</span></a><span class="sd">    .. [1] Hothorn, T., Bhlmann, P., Dudoit, S., Molinaro, A., van der Laan, M. J.,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-194"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-194"><span class="linenos">194</span></a><span class="sd">           &quot;Survival ensembles&quot;, Biostatistics, 7(3), 355-73, 2006</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-195"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-195"><span class="linenos">195</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-196"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-196"><span class="linenos">196</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-197"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-197"><span class="linenos">197</span></a>    <span class="n">_parameter_constraints</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-198"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-198"><span class="linenos">198</span></a>        <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">LOSS_FUNCTIONS</span><span class="o">.</span><span class="n">keys</span><span class="p">()))],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-199"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-199"><span class="linenos">199</span></a>        <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-200"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-200"><span class="linenos">200</span></a>        <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-201"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-201"><span class="linenos">201</span></a>        <span class="s2">&quot;subsample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-202"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-202"><span class="linenos">202</span></a>        <span class="s2">&quot;warm_start&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-203"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-203"><span class="linenos">203</span></a>        <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-204"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-204"><span class="linenos">204</span></a>        <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-205"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-205"><span class="linenos">205</span></a>        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-206"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-206"><span class="linenos">206</span></a>    <span class="p">}</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-207"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-207"><span class="linenos">207</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-208"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-208"><span class="linenos">208</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-209"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-209"><span class="linenos">209</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-210"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-210"><span class="linenos">210</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-211"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-211"><span class="linenos">211</span></a>        <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;coxph&quot;</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-212"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-212"><span class="linenos">212</span></a>        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-213"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-213"><span class="linenos">213</span></a>        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-214"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-214"><span class="linenos">214</span></a>        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-215"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-215"><span class="linenos">215</span></a>        <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-216"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-216"><span class="linenos">216</span></a>        <span class="n">dropout_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-217"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-217"><span class="linenos">217</span></a>        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-218"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-218"><span class="linenos">218</span></a>        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-219"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-219"><span class="linenos">219</span></a>    <span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-220"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-220"><span class="linenos">220</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-221"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-221"><span class="linenos">221</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-222"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-222"><span class="linenos">222</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-223"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-223"><span class="linenos">223</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">=</span> <span class="n">subsample</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-224"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-224"><span class="linenos">224</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span> <span class="o">=</span> <span class="n">warm_start</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-225"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-225"><span class="linenos">225</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-226"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-226"><span class="linenos">226</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-227"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-227"><span class="linenos">227</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-228"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-228"><span class="linenos">228</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-229"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-229"><span class="linenos">229</span></a>    <span class="nd">@property</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-230"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-230"><span class="linenos">230</span></a>    <span class="k">def</span> <span class="nf">_predict_risk_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-231"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-231"><span class="linenos">231</span></a>        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="n">CoxPH</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-232"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-232"><span class="linenos">232</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-233"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-233"><span class="linenos">233</span></a>    <span class="k">def</span> <span class="nf">_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-234"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-234"><span class="linenos">234</span></a>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">,</span> <span class="p">[]))</span> <span class="o">&gt;</span> <span class="mi">0</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-235"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-235"><span class="linenos">235</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-236"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-236"><span class="linenos">236</span></a>    <span class="k">def</span> <span class="nf">_init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-237"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-237"><span class="linenos">237</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-238"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-238"><span class="linenos">238</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-239"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-239"><span class="linenos">239</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-240"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-240"><span class="linenos">240</span></a>        <span class="c1"># do oob?</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-241"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-241"><span class="linenos">241</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-242"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-242"><span class="linenos">242</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-243"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-243"><span class="linenos">243</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-244"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-244"><span class="linenos">244</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-245"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-245"><span class="linenos">245</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-246"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-246"><span class="linenos">246</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-247"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-247"><span class="linenos">247</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-248"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-248"><span class="linenos">248</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-249"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-249"><span class="linenos">249</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-250"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-250"><span class="linenos">250</span></a>    <span class="k">def</span> <span class="nf">_resize_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-251"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-251"><span class="linenos">251</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Add additional ``n_estimators`` entries to all attributes.&quot;&quot;&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-252"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-252"><span class="linenos">252</span></a>        <span class="c1"># self.n_estimators is the number of additional est to fit</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-253"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-253"><span class="linenos">253</span></a>        <span class="n">total_n_estimators</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-254"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-254"><span class="linenos">254</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-255"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-255"><span class="linenos">255</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-256"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-256"><span class="linenos">256</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-257"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-257"><span class="linenos">257</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_improvement_&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-258"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-258"><span class="linenos">258</span></a>            <span class="c1"># if do oob resize arrays or create new if not available</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-259"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-259"><span class="linenos">259</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_improvement_&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-260"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-260"><span class="linenos">260</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-261"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-261"><span class="linenos">261</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-262"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-262"><span class="linenos">262</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-263"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-263"><span class="linenos">263</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-264"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-264"><span class="linenos">264</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-265"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-265"><span class="linenos">265</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-266"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-266"><span class="linenos">266</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-267"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-267"><span class="linenos">267</span></a>                    <span class="n">total_n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-268"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-268"><span class="linenos">268</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-269"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-269"><span class="linenos">269</span></a>                    <span class="p">(</span><span class="n">total_n_estimators</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-270"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-270"><span class="linenos">270</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-271"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-271"><span class="linenos">271</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-272"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-272"><span class="linenos">272</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-273"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-273"><span class="linenos">273</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-274"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-274"><span class="linenos">274</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-275"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-275"><span class="linenos">275</span></a>                    <span class="s2">&quot;fitting with warm_start=True and dropout_rate &gt; 0 is only &quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-276"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-276"><span class="linenos">276</span></a>                    <span class="s2">&quot;supported if the previous fit used dropout_rate &gt; 0 too&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-277"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-277"><span class="linenos">277</span></a>                <span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-278"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-278"><span class="linenos">278</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-279"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-279"><span class="linenos">279</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span> <span class="n">total_n_estimators</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-280"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-280"><span class="linenos">280</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-281"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-281"><span class="linenos">281</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-282"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-282"><span class="linenos">282</span></a>    <span class="k">def</span> <span class="nf">_clear_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-283"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-283"><span class="linenos">283</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear the state of the gradient boosting model.&quot;&quot;&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-284"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-284"><span class="linenos">284</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-285"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-285"><span class="linenos">285</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-286"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-286"><span class="linenos">286</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;train_score_&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-287"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-287"><span class="linenos">287</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-288"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-288"><span class="linenos">288</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_improvement_&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-289"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-289"><span class="linenos">289</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-290"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-290"><span class="linenos">290</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_scores_&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-291"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-291"><span class="linenos">291</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-292"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-292"><span class="linenos">292</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_score_&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-293"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-293"><span class="linenos">293</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-294"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-294"><span class="linenos">294</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_rng&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-295"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-295"><span class="linenos">295</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-296"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-296"><span class="linenos">296</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-297"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-297"><span class="linenos">297</span></a>            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-298"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-298"><span class="linenos">298</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-299"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-299"><span class="linenos">299</span></a>    <span class="k">def</span> <span class="nf">_update_with_dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-300"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-300"><span class="linenos">300</span></a>        <span class="c1"># select base learners to be dropped for next iteration</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-301"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-301"><span class="linenos">301</span></a>        <span class="n">drop_model</span><span class="p">,</span> <span class="n">n_dropped</span> <span class="o">=</span> <span class="n">_sample_binomial_plus_one</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-302"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-302"><span class="linenos">302</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-303"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-303"><span class="linenos">303</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-304"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-304"><span class="linenos">304</span></a>        <span class="c1"># adjust scaling factor of tree that is going to be trained in next iteration</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-305"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-305"><span class="linenos">305</span></a>        <span class="n">scale</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_dropped</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-306"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-306"><span class="linenos">306</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-307"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-307"><span class="linenos">307</span></a>        <span class="n">raw_predictions</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-308"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-308"><span class="linenos">308</span></a>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-309"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-309"><span class="linenos">309</span></a>            <span class="k">if</span> <span class="n">drop_model</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-310"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-310"><span class="linenos">310</span></a>                <span class="c1"># adjust scaling factor of dropped trees</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-311"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-311"><span class="linenos">311</span></a>                <span class="n">scale</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">*=</span> <span class="n">n_dropped</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_dropped</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-312"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-312"><span class="linenos">312</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-313"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-313"><span class="linenos">313</span></a>                <span class="c1"># pseudoresponse of next iteration (without contribution of dropped trees)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-314"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-314"><span class="linenos">314</span></a>                <span class="n">raw_predictions</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> \
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-315"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-315"><span class="linenos">315</span></a>                    <span class="n">scale</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">m</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-316"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-316"><span class="linenos">316</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-317"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-317"><span class="linenos">317</span></a>    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-318"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-318"><span class="linenos">318</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-319"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-319"><span class="linenos">319</span></a>        <span class="n">X</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-320"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-320"><span class="linenos">320</span></a>        <span class="n">event</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-321"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-321"><span class="linenos">321</span></a>        <span class="n">time</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-322"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-322"><span class="linenos">322</span></a>        <span class="n">y_pred</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-323"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-323"><span class="linenos">323</span></a>        <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-324"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-324"><span class="linenos">324</span></a>        <span class="n">random_state</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-325"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-325"><span class="linenos">325</span></a>        <span class="n">begin_at_stage</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-326"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-326"><span class="linenos">326</span></a>    <span class="p">):</span>  <span class="c1"># noqa: C901</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-327"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-327"><span class="linenos">327</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-328"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-328"><span class="linenos">328</span></a>        <span class="c1"># account for intercept</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-329"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-329"><span class="linenos">329</span></a>        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-330"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-330"><span class="linenos">330</span></a>                        <span class="p">(</span><span class="s2">&quot;event&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)])</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-331"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-331"><span class="linenos">331</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-332"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-332"><span class="linenos">332</span></a>        <span class="n">do_oob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mf">1.0</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-333"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-333"><span class="linenos">333</span></a>        <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-334"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-334"><span class="linenos">334</span></a>            <span class="n">n_inbag</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">))</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-335"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-335"><span class="linenos">335</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-336"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-336"><span class="linenos">336</span></a>        <span class="n">do_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-337"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-337"><span class="linenos">337</span></a>        <span class="k">if</span> <span class="n">do_dropout</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-338"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-338"><span class="linenos">338</span></a>            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-339"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-339"><span class="linenos">339</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-340"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-340"><span class="linenos">340</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-341"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-341"><span class="linenos">341</span></a>            <span class="n">verbose_reporter</span> <span class="o">=</span> <span class="n">VerboseReporter</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-342"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-342"><span class="linenos">342</span></a>            <span class="n">verbose_reporter</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-343"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-343"><span class="linenos">343</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-344"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-344"><span class="linenos">344</span></a>        <span class="c1"># perform boosting iterations</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-345"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-345"><span class="linenos">345</span></a>        <span class="n">i</span> <span class="o">=</span> <span class="n">begin_at_stage</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-346"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-346"><span class="linenos">346</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">begin_at_stage</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">)):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-347"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-347"><span class="linenos">347</span></a>            <span class="c1"># subsampling</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-348"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-348"><span class="linenos">348</span></a>            <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-349"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-349"><span class="linenos">349</span></a>                <span class="n">sample_mask</span> <span class="o">=</span> <span class="n">_random_sample_mask</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-350"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-350"><span class="linenos">350</span></a>                    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_inbag</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-351"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-351"><span class="linenos">351</span></a>                <span class="n">subsample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="o">*</span> \
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-352"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-352"><span class="linenos">352</span></a>                    <span class="n">sample_mask</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-353"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-353"><span class="linenos">353</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-354"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-354"><span class="linenos">354</span></a>                <span class="c1"># OOB score before adding this stage</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-355"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-355"><span class="linenos">355</span></a>                <span class="n">y_oob_masked</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-356"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-356"><span class="linenos">356</span></a>                <span class="n">sample_weight_oob_masked</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-357"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-357"><span class="linenos">357</span></a>                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># store the initial loss to compute the OOB score</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-358"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-358"><span class="linenos">358</span></a>                    <span class="n">initial_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-359"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-359"><span class="linenos">359</span></a>                        <span class="n">y_true</span><span class="o">=</span><span class="n">y_oob_masked</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-360"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-360"><span class="linenos">360</span></a>                        <span class="n">raw_prediction</span><span class="o">=</span><span class="n">y_pred</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-361"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-361"><span class="linenos">361</span></a>                        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight_oob_masked</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-362"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-362"><span class="linenos">362</span></a>                    <span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-363"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-363"><span class="linenos">363</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-364"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-364"><span class="linenos">364</span></a>                <span class="n">subsample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-365"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-365"><span class="linenos">365</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-366"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-366"><span class="linenos">366</span></a>            <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-367"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-367"><span class="linenos">367</span></a>                <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-368"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-368"><span class="linenos">368</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-369"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-369"><span class="linenos">369</span></a>            <span class="n">best_learner</span> <span class="o">=</span> <span class="n">_fit_stage_componentwise</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-370"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-370"><span class="linenos">370</span></a>                <span class="n">X</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">subsample_weight</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-371"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-371"><span class="linenos">371</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_learner</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-372"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-372"><span class="linenos">372</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-373"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-373"><span class="linenos">373</span></a>            <span class="k">if</span> <span class="n">do_dropout</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-374"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-374"><span class="linenos">374</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-375"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-375"><span class="linenos">375</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-376"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-376"><span class="linenos">376</span></a>                <span class="n">y_pred</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">best_learner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-377"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-377"><span class="linenos">377</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-378"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-378"><span class="linenos">378</span></a>            <span class="c1"># track loss</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-379"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-379"><span class="linenos">379</span></a>            <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-380"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-380"><span class="linenos">380</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-381"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-381"><span class="linenos">381</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-382"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-382"><span class="linenos">382</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">y_pred</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-383"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-383"><span class="linenos">383</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-384"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-384"><span class="linenos">384</span></a>                <span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-385"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-385"><span class="linenos">385</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-386"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-386"><span class="linenos">386</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y_oob_masked</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-387"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-387"><span class="linenos">387</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">y_pred</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-388"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-388"><span class="linenos">388</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight_oob_masked</span><span class="p">,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-389"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-389"><span class="linenos">389</span></a>                <span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-390"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-390"><span class="linenos">390</span></a>                <span class="n">previous_loss</span> <span class="o">=</span> <span class="n">initial_loss</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-391"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-391"><span class="linenos">391</span></a>                    <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-392"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-392"><span class="linenos">392</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">previous_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-393"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-393"><span class="linenos">393</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-394"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-394"><span class="linenos">394</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-395"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-395"><span class="linenos">395</span></a>                <span class="c1"># no need to fancy index w/ no subsampling</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-396"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-396"><span class="linenos">396</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-397"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-397"><span class="linenos">397</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">raw_prediction</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-398"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-398"><span class="linenos">398</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-399"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-399"><span class="linenos">399</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-400"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-400"><span class="linenos">400</span></a>                <span class="n">verbose_reporter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-401"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-401"><span class="linenos">401</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-402"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-402"><span class="linenos">402</span></a>        <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-403"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-403"><span class="linenos">403</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-404"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-404"><span class="linenos">404</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-405"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-405"><span class="linenos">405</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit estimator.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-406"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-406"><span class="linenos">406</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-407"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-407"><span class="linenos">407</span></a><span class="sd">        Parameters</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-408"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-408"><span class="linenos">408</span></a><span class="sd">        ----------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-409"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-409"><span class="linenos">409</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-410"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-410"><span class="linenos">410</span></a><span class="sd">            Data matrix</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-411"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-411"><span class="linenos">411</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-412"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-412"><span class="linenos">412</span></a><span class="sd">        y : structured array, shape = (n_samples,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-413"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-413"><span class="linenos">413</span></a><span class="sd">            A structured array containing the binary event indicator</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-414"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-414"><span class="linenos">414</span></a><span class="sd">            as first field, and time of event or time of censoring as</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-415"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-415"><span class="linenos">415</span></a><span class="sd">            second field.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-416"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-416"><span class="linenos">416</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-417"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-417"><span class="linenos">417</span></a><span class="sd">        sample_weight : array-like, shape = (n_samples,), optional</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-418"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-418"><span class="linenos">418</span></a><span class="sd">            Weights given to each sample. If omitted, all samples have weight 1.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-419"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-419"><span class="linenos">419</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-420"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-420"><span class="linenos">420</span></a><span class="sd">        Returns</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-421"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-421"><span class="linenos">421</span></a><span class="sd">        -------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-422"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-422"><span class="linenos">422</span></a><span class="sd">        self</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-423"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-423"><span class="linenos">423</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-424"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-424"><span class="linenos">424</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-425"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-425"><span class="linenos">425</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-426"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-426"><span class="linenos">426</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-427"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-427"><span class="linenos">427</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_state</span><span class="p">()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-428"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-428"><span class="linenos">428</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-429"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-429"><span class="linenos">429</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">ensure_min_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-430"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-430"><span class="linenos">430</span></a>        <span class="n">event</span><span class="p">,</span> <span class="n">time</span> <span class="o">=</span> <span class="n">check_array_survival</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-431"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-431"><span class="linenos">431</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-432"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-432"><span class="linenos">432</span></a>        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-433"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-433"><span class="linenos">433</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-434"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-434"><span class="linenos">434</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-435"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-435"><span class="linenos">435</span></a>        <span class="n">Xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-436"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-436"><span class="linenos">436</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-437"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-437"><span class="linenos">437</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="n">LOSS_FUNCTIONS</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">]()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-438"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-438"><span class="linenos">438</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="p">(</span><span class="n">CensoredSquaredLoss</span><span class="p">,</span> <span class="n">IPCWLeastSquaresError</span><span class="p">)):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-439"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-439"><span class="linenos">439</span></a>            <span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-440"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-440"><span class="linenos">440</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-441"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-441"><span class="linenos">441</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_fitted</span><span class="p">():</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-442"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-442"><span class="linenos">442</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_init_state</span><span class="p">()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-443"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-443"><span class="linenos">443</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-444"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-444"><span class="linenos">444</span></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-445"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-445"><span class="linenos">445</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-446"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-446"><span class="linenos">446</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-447"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-447"><span class="linenos">447</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-448"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-448"><span class="linenos">448</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-449"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-449"><span class="linenos">449</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-450"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-450"><span class="linenos">450</span></a>            <span class="c1"># add more estimators to fitted model</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-451"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-451"><span class="linenos">451</span></a>            <span class="c1"># invariant: warm_start = True</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-452"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-452"><span class="linenos">452</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-453"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-453"><span class="linenos">453</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-454"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-454"><span class="linenos">454</span></a>                    <span class="s2">&quot;n_estimators=</span><span class="si">%d</span><span class="s2"> must be larger or equal to &quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-455"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-455"><span class="linenos">455</span></a>                    <span class="s2">&quot;estimators_.shape[0]=</span><span class="si">%d</span><span class="s2"> when &quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-456"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-456"><span class="linenos">456</span></a>                    <span class="s2">&quot;warm_start==True&quot;</span> <span class="o">%</span> <span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-457"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-457"><span class="linenos">457</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-458"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-458"><span class="linenos">458</span></a>                <span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-459"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-459"><span class="linenos">459</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-460"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-460"><span class="linenos">460</span></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">Xi</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-461"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-461"><span class="linenos">461</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_resize_state</span><span class="p">()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-462"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-462"><span class="linenos">462</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-463"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-463"><span class="linenos">463</span></a>            <span class="c1"># apply dropout to last stage of previous fit</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-464"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-464"><span class="linenos">464</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-465"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-465"><span class="linenos">465</span></a>                <span class="c1"># pylint: disable-next=access-member-before-definition</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-466"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-466"><span class="linenos">466</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-467"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-467"><span class="linenos">467</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Xi</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-468"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-468"><span class="linenos">468</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-469"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-469"><span class="linenos">469</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-470"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-470"><span class="linenos">470</span></a>            <span class="n">Xi</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">,</span> <span class="n">begin_at_stage</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-471"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-471"><span class="linenos">471</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-472"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-472"><span class="linenos">472</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_baseline_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-473"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-473"><span class="linenos">473</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-474"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-474"><span class="linenos">474</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-475"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-475"><span class="linenos">475</span></a>    <span class="k">def</span> <span class="nf">_set_baseline_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-476"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-476"><span class="linenos">476</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="n">CoxPH</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-477"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-477"><span class="linenos">477</span></a>            <span class="n">risk_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-478"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-478"><span class="linenos">478</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="o">=</span> <span class="n">BreslowEstimator</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">risk_scores</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-479"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-479"><span class="linenos">479</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-480"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-480"><span class="linenos">480</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-481"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-481"><span class="linenos">481</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-482"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-482"><span class="linenos">482</span></a>    <span class="k">def</span> <span class="nf">_raw_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-483"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-483"><span class="linenos">483</span></a>        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-484"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-484"><span class="linenos">484</span></a>        <span class="k">for</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-485"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-485"><span class="linenos">485</span></a>            <span class="n">pred</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-486"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-486"><span class="linenos">486</span></a>        <span class="k">return</span> <span class="n">pred</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-487"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-487"><span class="linenos">487</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-488"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-488"><span class="linenos">488</span></a>    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-489"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-489"><span class="linenos">489</span></a>        <span class="c1"># account for intercept</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-490"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-490"><span class="linenos">490</span></a>        <span class="n">Xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">X</span><span class="p">))</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-491"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-491"><span class="linenos">491</span></a>        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">Xi</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-492"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-492"><span class="linenos">492</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">_scale_raw_prediction</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-493"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-493"><span class="linenos">493</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-494"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-494"><span class="linenos">494</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-495"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-495"><span class="linenos">495</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict risk scores.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-496"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-496"><span class="linenos">496</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-497"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-497"><span class="linenos">497</span></a><span class="sd">        If `loss=&#39;coxph&#39;`, predictions can be interpreted as log hazard ratio</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-498"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-498"><span class="linenos">498</span></a><span class="sd">        corresponding to the linear predictor of a Cox proportional hazards</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-499"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-499"><span class="linenos">499</span></a><span class="sd">        model. If `loss=&#39;squared&#39;` or `loss=&#39;ipcwls&#39;`, predictions are the</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-500"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-500"><span class="linenos">500</span></a><span class="sd">        time to event.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-501"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-501"><span class="linenos">501</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-502"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-502"><span class="linenos">502</span></a><span class="sd">        Parameters</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-503"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-503"><span class="linenos">503</span></a><span class="sd">        ----------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-504"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-504"><span class="linenos">504</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-505"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-505"><span class="linenos">505</span></a><span class="sd">            Data matrix.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-506"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-506"><span class="linenos">506</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-507"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-507"><span class="linenos">507</span></a><span class="sd">        Returns</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-508"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-508"><span class="linenos">508</span></a><span class="sd">        -------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-509"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-509"><span class="linenos">509</span></a><span class="sd">        risk_score : array, shape = (n_samples,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-510"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-510"><span class="linenos">510</span></a><span class="sd">            Predicted risk scores.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-511"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-511"><span class="linenos">511</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-512"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-512"><span class="linenos">512</span></a>        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-513"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-513"><span class="linenos">513</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-514"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-514"><span class="linenos">514</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-515"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-515"><span class="linenos">515</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-516"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-516"><span class="linenos">516</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-517"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-517"><span class="linenos">517</span></a>    <span class="k">def</span> <span class="nf">_get_baseline_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-518"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-518"><span class="linenos">518</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-519"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-519"><span class="linenos">519</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-520"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-520"><span class="linenos">520</span></a>                <span class="s2">&quot;`fit` must be called with the loss option set to &#39;coxph&#39;.&quot;</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-521"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-521"><span class="linenos">521</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-522"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-522"><span class="linenos">522</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-523"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-523"><span class="linenos">523</span></a>    <span class="k">def</span> <span class="nf">predict_cumulative_hazard_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-524"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-524"><span class="linenos">524</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict cumulative hazard function.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-525"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-525"><span class="linenos">525</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-526"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-526"><span class="linenos">526</span></a><span class="sd">        Only available if :meth:`fit` has been called with `loss = &quot;coxph&quot;`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-527"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-527"><span class="linenos">527</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-528"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-528"><span class="linenos">528</span></a><span class="sd">        The cumulative hazard function for an individual</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-529"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-529"><span class="linenos">529</span></a><span class="sd">        with feature vector :math:`x` is defined as</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-530"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-530"><span class="linenos">530</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-531"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-531"><span class="linenos">531</span></a><span class="sd">        .. math::</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-532"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-532"><span class="linenos">532</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-533"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-533"><span class="linenos">533</span></a><span class="sd">            H(t \\mid x) = \\exp(f(x)) H_0(t) ,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-534"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-534"><span class="linenos">534</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-535"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-535"><span class="linenos">535</span></a><span class="sd">        where :math:`f(\\cdot)` is the additive ensemble of base learners,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-536"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-536"><span class="linenos">536</span></a><span class="sd">        and :math:`H_0(t)` is the baseline hazard function,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-537"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-537"><span class="linenos">537</span></a><span class="sd">        estimated by Breslow&#39;s estimator.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-538"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-538"><span class="linenos">538</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-539"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-539"><span class="linenos">539</span></a><span class="sd">        Parameters</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-540"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-540"><span class="linenos">540</span></a><span class="sd">        ----------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-541"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-541"><span class="linenos">541</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-542"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-542"><span class="linenos">542</span></a><span class="sd">            Data matrix.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-543"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-543"><span class="linenos">543</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-544"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-544"><span class="linenos">544</span></a><span class="sd">        return_array : boolean, default: False</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-545"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-545"><span class="linenos">545</span></a><span class="sd">            If set, return an array with the cumulative hazard rate</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-546"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-546"><span class="linenos">546</span></a><span class="sd">            for each `self.unique_times_`, otherwise an array of</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-547"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-547"><span class="linenos">547</span></a><span class="sd">            :class:`survivalist.functions.StepFunction`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-548"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-548"><span class="linenos">548</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-549"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-549"><span class="linenos">549</span></a><span class="sd">        Returns</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-550"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-550"><span class="linenos">550</span></a><span class="sd">        -------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-551"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-551"><span class="linenos">551</span></a><span class="sd">        cum_hazard : ndarray</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-552"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-552"><span class="linenos">552</span></a><span class="sd">            If `return_array` is set, an array with the cumulative hazard rate</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-553"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-553"><span class="linenos">553</span></a><span class="sd">            for each `self.unique_times_`, otherwise an array of length `n_samples`</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-554"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-554"><span class="linenos">554</span></a><span class="sd">            of :class:`survivalist.functions.StepFunction` instances will be returned.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-555"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-555"><span class="linenos">555</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-556"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-556"><span class="linenos">556</span></a><span class="sd">        Examples</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-557"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-557"><span class="linenos">557</span></a><span class="sd">        --------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-558"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-558"><span class="linenos">558</span></a><span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-559"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-559"><span class="linenos">559</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.datasets import load_whas500</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-560"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-560"><span class="linenos">560</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-561"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-561"><span class="linenos">561</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-562"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-562"><span class="linenos">562</span></a><span class="sd">        Load the data.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-563"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-563"><span class="linenos">563</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-564"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-564"><span class="linenos">564</span></a><span class="sd">        &gt;&gt;&gt; X, y = load_whas500()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-565"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-565"><span class="linenos">565</span></a><span class="sd">        &gt;&gt;&gt; X = X.astype(float)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-566"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-566"><span class="linenos">566</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-567"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-567"><span class="linenos">567</span></a><span class="sd">        Fit the model.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-568"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-568"><span class="linenos">568</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-569"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-569"><span class="linenos">569</span></a><span class="sd">        &gt;&gt;&gt; estimator = ComponentwiseGradientBoostingSurvivalAnalysis(loss=&quot;coxph&quot;).fit(X, y)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-570"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-570"><span class="linenos">570</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-571"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-571"><span class="linenos">571</span></a><span class="sd">        Estimate the cumulative hazard function for the first 10 samples.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-572"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-572"><span class="linenos">572</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-573"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-573"><span class="linenos">573</span></a><span class="sd">        &gt;&gt;&gt; chf_funcs = estimator.predict_cumulative_hazard_function(X.iloc[:10])</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-574"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-574"><span class="linenos">574</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-575"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-575"><span class="linenos">575</span></a><span class="sd">        Plot the estimated cumulative hazard functions.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-576"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-576"><span class="linenos">576</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-577"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-577"><span class="linenos">577</span></a><span class="sd">        &gt;&gt;&gt; for fn in chf_funcs:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-578"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-578"><span class="linenos">578</span></a><span class="sd">        ...     plt.step(fn.x, fn(fn.x), where=&quot;post&quot;)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-579"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-579"><span class="linenos">579</span></a><span class="sd">        ...</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-580"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-580"><span class="linenos">580</span></a><span class="sd">        &gt;&gt;&gt; plt.ylim(0, 1)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-581"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-581"><span class="linenos">581</span></a><span class="sd">        &gt;&gt;&gt; plt.show()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-582"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-582"><span class="linenos">582</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-583"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-583"><span class="linenos">583</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_cumulative_hazard_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">return_array</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-584"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-584"><span class="linenos">584</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-585"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-585"><span class="linenos">585</span></a>    <span class="k">def</span> <span class="nf">predict_survival_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-586"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-586"><span class="linenos">586</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict survival function.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-587"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-587"><span class="linenos">587</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-588"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-588"><span class="linenos">588</span></a><span class="sd">        Only available if :meth:`fit` has been called with `loss = &quot;coxph&quot;`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-589"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-589"><span class="linenos">589</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-590"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-590"><span class="linenos">590</span></a><span class="sd">        The survival function for an individual</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-591"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-591"><span class="linenos">591</span></a><span class="sd">        with feature vector :math:`x` is defined as</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-592"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-592"><span class="linenos">592</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-593"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-593"><span class="linenos">593</span></a><span class="sd">        .. math::</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-594"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-594"><span class="linenos">594</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-595"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-595"><span class="linenos">595</span></a><span class="sd">            S(t \\mid x) = S_0(t)^{\\exp(f(x)} ,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-596"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-596"><span class="linenos">596</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-597"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-597"><span class="linenos">597</span></a><span class="sd">        where :math:`f(\\cdot)` is the additive ensemble of base learners,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-598"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-598"><span class="linenos">598</span></a><span class="sd">        and :math:`S_0(t)` is the baseline survival function,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-599"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-599"><span class="linenos">599</span></a><span class="sd">        estimated by Breslow&#39;s estimator.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-600"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-600"><span class="linenos">600</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-601"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-601"><span class="linenos">601</span></a><span class="sd">        Parameters</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-602"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-602"><span class="linenos">602</span></a><span class="sd">        ----------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-603"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-603"><span class="linenos">603</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-604"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-604"><span class="linenos">604</span></a><span class="sd">            Data matrix.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-605"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-605"><span class="linenos">605</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-606"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-606"><span class="linenos">606</span></a><span class="sd">        return_array : boolean, default: False</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-607"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-607"><span class="linenos">607</span></a><span class="sd">            If set, return an array with the probability</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-608"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-608"><span class="linenos">608</span></a><span class="sd">            of survival for each `self.unique_times_`,</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-609"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-609"><span class="linenos">609</span></a><span class="sd">            otherwise an array of :class:`survivalist.functions.StepFunction`.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-610"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-610"><span class="linenos">610</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-611"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-611"><span class="linenos">611</span></a><span class="sd">        Returns</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-612"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-612"><span class="linenos">612</span></a><span class="sd">        -------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-613"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-613"><span class="linenos">613</span></a><span class="sd">        survival : ndarray</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-614"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-614"><span class="linenos">614</span></a><span class="sd">            If `return_array` is set, an array with the probability of</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-615"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-615"><span class="linenos">615</span></a><span class="sd">            survival for each `self.unique_times_`, otherwise an array of</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-616"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-616"><span class="linenos">616</span></a><span class="sd">            length `n_samples` of :class:`survivalist.functions.StepFunction`</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-617"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-617"><span class="linenos">617</span></a><span class="sd">            instances will be returned.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-618"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-618"><span class="linenos">618</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-619"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-619"><span class="linenos">619</span></a><span class="sd">        Examples</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-620"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-620"><span class="linenos">620</span></a><span class="sd">        --------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-621"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-621"><span class="linenos">621</span></a><span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-622"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-622"><span class="linenos">622</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.datasets import load_whas500</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-623"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-623"><span class="linenos">623</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-624"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-624"><span class="linenos">624</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-625"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-625"><span class="linenos">625</span></a><span class="sd">        Load the data.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-626"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-626"><span class="linenos">626</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-627"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-627"><span class="linenos">627</span></a><span class="sd">        &gt;&gt;&gt; X, y = load_whas500()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-628"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-628"><span class="linenos">628</span></a><span class="sd">        &gt;&gt;&gt; X = X.astype(float)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-629"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-629"><span class="linenos">629</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-630"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-630"><span class="linenos">630</span></a><span class="sd">        Fit the model.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-631"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-631"><span class="linenos">631</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-632"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-632"><span class="linenos">632</span></a><span class="sd">        &gt;&gt;&gt; estimator = ComponentwiseGradientBoostingSurvivalAnalysis(loss=&quot;coxph&quot;).fit(X, y)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-633"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-633"><span class="linenos">633</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-634"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-634"><span class="linenos">634</span></a><span class="sd">        Estimate the survival function for the first 10 samples.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-635"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-635"><span class="linenos">635</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-636"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-636"><span class="linenos">636</span></a><span class="sd">        &gt;&gt;&gt; surv_funcs = estimator.predict_survival_function(X.iloc[:10])</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-637"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-637"><span class="linenos">637</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-638"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-638"><span class="linenos">638</span></a><span class="sd">        Plot the estimated survival functions.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-639"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-639"><span class="linenos">639</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-640"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-640"><span class="linenos">640</span></a><span class="sd">        &gt;&gt;&gt; for fn in surv_funcs:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-641"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-641"><span class="linenos">641</span></a><span class="sd">        ...     plt.step(fn.x, fn(fn.x), where=&quot;post&quot;)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-642"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-642"><span class="linenos">642</span></a><span class="sd">        ...</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-643"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-643"><span class="linenos">643</span></a><span class="sd">        &gt;&gt;&gt; plt.ylim(0, 1)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-644"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-644"><span class="linenos">644</span></a><span class="sd">        &gt;&gt;&gt; plt.show()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-645"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-645"><span class="linenos">645</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-646"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-646"><span class="linenos">646</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_survival_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">return_array</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-647"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-647"><span class="linenos">647</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-648"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-648"><span class="linenos">648</span></a>    <span class="nd">@property</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-649"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-649"><span class="linenos">649</span></a>    <span class="k">def</span> <span class="nf">coef_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-650"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-650"><span class="linenos">650</span></a>        <span class="n">coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-651"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-651"><span class="linenos">651</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-652"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-652"><span class="linenos">652</span></a>        <span class="k">for</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-653"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-653"><span class="linenos">653</span></a>            <span class="n">coef</span><span class="p">[</span><span class="n">estimator</span><span class="o">.</span><span class="n">component</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-654"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-654"><span class="linenos">654</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-655"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-655"><span class="linenos">655</span></a>        <span class="k">return</span> <span class="n">coef</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-656"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-656"><span class="linenos">656</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-657"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-657"><span class="linenos">657</span></a>    <span class="nd">@property</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-658"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-658"><span class="linenos">658</span></a>    <span class="k">def</span> <span class="nf">unique_times_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-659"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-659"><span class="linenos">659</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">()</span><span class="o">.</span><span class="n">unique_times_</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-660"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-660"><span class="linenos">660</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-661"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-661"><span class="linenos">661</span></a>    <span class="nd">@property</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-662"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-662"><span class="linenos">662</span></a>    <span class="k">def</span> <span class="nf">feature_importances_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-663"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-663"><span class="linenos">663</span></a>        <span class="n">imp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-664"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-664"><span class="linenos">664</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">imp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-665"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-665"><span class="linenos">665</span></a>            <span class="n">imp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-666"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-666"><span class="linenos">666</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-667"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-667"><span class="linenos">667</span></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-668"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-668"><span class="linenos">668</span></a>            <span class="n">imp</span><span class="p">[</span><span class="n">estimator</span><span class="o">.</span><span class="n">component</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-669"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-669"><span class="linenos">669</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-670"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-670"><span class="linenos">670</span></a>        <span class="k">def</span> <span class="nf">_importance</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-671"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-671"><span class="linenos">671</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-672"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-672"><span class="linenos">672</span></a>                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-673"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-673"><span class="linenos">673</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-674"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-674"><span class="linenos">674</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-675"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-675"><span class="linenos">675</span></a>        <span class="n">ret</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">_importance</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">imp</span><span class="p">])</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-676"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-676"><span class="linenos">676</span></a>        <span class="k">return</span> <span class="n">ret</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-677"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-677"><span class="linenos">677</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-678"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-678"><span class="linenos">678</span></a>    <span class="k">def</span> <span class="nf">_make_estimator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-679"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-679"><span class="linenos">679</span></a>        <span class="c1"># we don&#39;t need _make_estimator</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis-680"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis-680"><span class="linenos">680</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Gradient boosting with component-wise least squares as base learner.</p>

<p>See the :ref:<code>User Guide &lt;/user_guide/boosting.ipynb&gt;</code> and <sup class="footnote-ref" id="fnref-1"><a href="#fn-1">1</a></sup> for further description.</p>

<h2 id="parameters">Parameters</h2>

<p>loss : {'coxph', 'squared', 'ipcwls'}, optional, default: 'coxph'
    loss function to be optimized. 'coxph' refers to partial likelihood loss
    of Cox's proportional hazards model. The loss 'squared' minimizes a
    squared regression loss that ignores predictions beyond the time of censoring,
    and 'ipcwls' refers to inverse-probability of censoring weighted least squares error.</p>

<p>learning_rate : float, optional, default: 0.1
    learning rate shrinks the contribution of each base learner by <code><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.learning_rate">learning_rate</a></code>.
    There is a trade-off between <code><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.learning_rate">learning_rate</a></code> and <code><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.n_estimators">n_estimators</a></code>.
    Values must be in the range <code>[0.0, inf)</code>.</p>

<p>n_estimators : int, default: 100
    The number of boosting stages to perform. Gradient boosting
    is fairly robust to over-fitting so a large number usually
    results in better performance.
    Values must be in the range <code>[1, inf)</code>.</p>

<p>subsample : float, optional, default: 1.0
    The fraction of samples to be used for fitting the individual base
    learners. If smaller than 1.0 this results in Stochastic Gradient
    Boosting. <code><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.subsample">subsample</a></code> interacts with the parameter <code><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.n_estimators">n_estimators</a></code>.
    Choosing <code>subsample &lt; 1.0</code> leads to a reduction of variance
    and an increase in bias.
    Values must be in the range <code>(0.0, 1.0]</code>.</p>

<p>warm_start : bool, default: False
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just erase the
    previous solution.</p>

<p>dropout_rate : float, optional, default: 0.0
    If larger than zero, the residuals at each iteration are only computed
    from a random subset of base learners. The value corresponds to the
    percentage of base learners that are dropped. In each iteration,
    at least one base learner is dropped. This is an alternative regularization
    to shrinkage, i.e., setting <code>learning_rate &lt; 1.0</code>.
    Values must be in the range <code>[0.0, 1.0)</code>.</p>

<p>random_state : int seed, RandomState instance, or None, default: None
    The seed of the pseudo random number generator to use when
    shuffling the data.</p>

<p>verbose : int, default: 0
    Enable verbose output. If 1 then it prints progress and performance
    once in a while.
    Values must be in the range <code>[0, inf)</code>.</p>

<h2 id="attributes">Attributes</h2>

<p>coef_ : array, shape = (n_features + 1,)
    The aggregated coefficients. The first element <code>coef\_[0]</code> corresponds
    to the intercept. If loss is <code>coxph</code>, the intercept will always be zero.</p>

<p>estimators_ : list of base learners
    The collection of fitted sub-estimators.</p>

<p>train_score_ : ndarray, shape = (n_estimators,)
    The i-th score <code>train_score_[i]</code> is the loss of the
    model at iteration <code>i</code> on the in-bag sample.
    If <code>subsample == 1</code> this is the loss on the training data.</p>

<p>oob_improvement_ : ndarray, shape = (n_estimators,)
    The improvement in loss on the out-of-bag samples
    relative to the previous iteration.
    <code>oob_improvement_[0]</code> is the improvement in
    loss of the first stage over the <code>init</code> estimator.
    Only available if <code>subsample &lt; 1.0</code>.</p>

<p>oob_scores_ : ndarray of shape (n_estimators,)
    The full history of the loss values on the out-of-bag
    samples. Only available if <code>subsample &lt; 1.0</code>.</p>

<p>oob_score_ : float
    The last value of the loss on the out-of-bag samples. It is
    the same as <code>oob_scores_[-1]</code>. Only available if <code>subsample &lt; 1.0</code>.</p>

<p>n_features_in_ : int
    Number of features seen during <code><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit">fit</a></code>.</p>

<p>feature_names_in_ : ndarray of shape (<code>n_features_in_</code>,)
    Names of features seen during <code><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit">fit</a></code>. Defined only when <code>X</code>
    has feature names that are all strings.</p>

<p>unique_times_ : array of shape = (n_unique_times,)
    Unique time points.</p>

<h2 id="references">References</h2>

<div class="footnotes">
<hr />
<ol>
<li id="fn-1">
<p>Hothorn, T., Bhlmann, P., Dudoit, S., Molinaro, A., van der Laan, M. J.,
"Survival ensembles", Biostatistics, 7(3), 355-73, 2006&#160;<a href="#fnref-1" class="footnoteBackLink" title="Jump back to footnote 1 in the text.">&#8617;</a></p>
</li>
</ol>
</div>
</div>


                                <div id="ComponentwiseGradientBoostingSurvivalAnalysis.subsample" class="classattr">
                                    <div class="attr variable">
            <span class="name">subsample</span>

        
    </div>
    <a class="headerlink" href="#ComponentwiseGradientBoostingSurvivalAnalysis.subsample"></a>
    
    

                                </div>
                                <div id="ComponentwiseGradientBoostingSurvivalAnalysis.fit" class="classattr">
                                            <input id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ComponentwiseGradientBoostingSurvivalAnalysis.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-404"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-404"><span class="linenos">404</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-405"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-405"><span class="linenos">405</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit estimator.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-406"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-406"><span class="linenos">406</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-407"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-407"><span class="linenos">407</span></a><span class="sd">        Parameters</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-408"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-408"><span class="linenos">408</span></a><span class="sd">        ----------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-409"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-409"><span class="linenos">409</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-410"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-410"><span class="linenos">410</span></a><span class="sd">            Data matrix</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-411"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-411"><span class="linenos">411</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-412"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-412"><span class="linenos">412</span></a><span class="sd">        y : structured array, shape = (n_samples,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-413"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-413"><span class="linenos">413</span></a><span class="sd">            A structured array containing the binary event indicator</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-414"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-414"><span class="linenos">414</span></a><span class="sd">            as first field, and time of event or time of censoring as</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-415"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-415"><span class="linenos">415</span></a><span class="sd">            second field.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-416"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-416"><span class="linenos">416</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-417"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-417"><span class="linenos">417</span></a><span class="sd">        sample_weight : array-like, shape = (n_samples,), optional</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-418"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-418"><span class="linenos">418</span></a><span class="sd">            Weights given to each sample. If omitted, all samples have weight 1.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-419"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-419"><span class="linenos">419</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-420"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-420"><span class="linenos">420</span></a><span class="sd">        Returns</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-421"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-421"><span class="linenos">421</span></a><span class="sd">        -------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-422"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-422"><span class="linenos">422</span></a><span class="sd">        self</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-423"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-423"><span class="linenos">423</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-424"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-424"><span class="linenos">424</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-425"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-425"><span class="linenos">425</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-426"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-426"><span class="linenos">426</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-427"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-427"><span class="linenos">427</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_state</span><span class="p">()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-428"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-428"><span class="linenos">428</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-429"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-429"><span class="linenos">429</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">ensure_min_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-430"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-430"><span class="linenos">430</span></a>        <span class="n">event</span><span class="p">,</span> <span class="n">time</span> <span class="o">=</span> <span class="n">check_array_survival</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-431"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-431"><span class="linenos">431</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-432"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-432"><span class="linenos">432</span></a>        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-433"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-433"><span class="linenos">433</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-434"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-434"><span class="linenos">434</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-435"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-435"><span class="linenos">435</span></a>        <span class="n">Xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">X</span><span class="p">))</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-436"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-436"><span class="linenos">436</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-437"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-437"><span class="linenos">437</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="n">LOSS_FUNCTIONS</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">]()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-438"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-438"><span class="linenos">438</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="p">(</span><span class="n">CensoredSquaredLoss</span><span class="p">,</span> <span class="n">IPCWLeastSquaresError</span><span class="p">)):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-439"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-439"><span class="linenos">439</span></a>            <span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-440"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-440"><span class="linenos">440</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-441"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-441"><span class="linenos">441</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_fitted</span><span class="p">():</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-442"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-442"><span class="linenos">442</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_init_state</span><span class="p">()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-443"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-443"><span class="linenos">443</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-444"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-444"><span class="linenos">444</span></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-445"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-445"><span class="linenos">445</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-446"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-446"><span class="linenos">446</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-447"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-447"><span class="linenos">447</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-448"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-448"><span class="linenos">448</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-449"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-449"><span class="linenos">449</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-450"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-450"><span class="linenos">450</span></a>            <span class="c1"># add more estimators to fitted model</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-451"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-451"><span class="linenos">451</span></a>            <span class="c1"># invariant: warm_start = True</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-452"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-452"><span class="linenos">452</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-453"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-453"><span class="linenos">453</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-454"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-454"><span class="linenos">454</span></a>                    <span class="s2">&quot;n_estimators=</span><span class="si">%d</span><span class="s2"> must be larger or equal to &quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-455"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-455"><span class="linenos">455</span></a>                    <span class="s2">&quot;estimators_.shape[0]=</span><span class="si">%d</span><span class="s2"> when &quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-456"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-456"><span class="linenos">456</span></a>                    <span class="s2">&quot;warm_start==True&quot;</span> <span class="o">%</span> <span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-457"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-457"><span class="linenos">457</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-458"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-458"><span class="linenos">458</span></a>                <span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-459"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-459"><span class="linenos">459</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-460"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-460"><span class="linenos">460</span></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">Xi</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-461"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-461"><span class="linenos">461</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_resize_state</span><span class="p">()</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-462"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-462"><span class="linenos">462</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-463"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-463"><span class="linenos">463</span></a>            <span class="c1"># apply dropout to last stage of previous fit</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-464"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-464"><span class="linenos">464</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-465"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-465"><span class="linenos">465</span></a>                <span class="c1"># pylint: disable-next=access-member-before-definition</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-466"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-466"><span class="linenos">466</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-467"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-467"><span class="linenos">467</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Xi</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-468"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-468"><span class="linenos">468</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-469"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-469"><span class="linenos">469</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-470"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-470"><span class="linenos">470</span></a>            <span class="n">Xi</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">,</span> <span class="n">begin_at_stage</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-471"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-471"><span class="linenos">471</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-472"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-472"><span class="linenos">472</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_baseline_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.fit-473"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.fit-473"><span class="linenos">473</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Fit estimator.</p>

<h2 id="parameters">Parameters</h2>

<p>X : array-like, shape = (n_samples, n_features)
    Data matrix</p>

<p>y : structured array, shape = (n_samples,)
    A structured array containing the binary event indicator
    as first field, and time of event or time of censoring as
    second field.</p>

<p>sample_weight : array-like, shape = (n_samples,), optional
    Weights given to each sample. If omitted, all samples have weight 1.</p>

<h2 id="returns">Returns</h2>

<p>self</p>
</div>


                                </div>
                                <div id="ComponentwiseGradientBoostingSurvivalAnalysis.predict" class="classattr">
                                            <input id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ComponentwiseGradientBoostingSurvivalAnalysis.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-494"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-494"><span class="linenos">494</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-495"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-495"><span class="linenos">495</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict risk scores.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-496"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-496"><span class="linenos">496</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-497"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-497"><span class="linenos">497</span></a><span class="sd">        If `loss=&#39;coxph&#39;`, predictions can be interpreted as log hazard ratio</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-498"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-498"><span class="linenos">498</span></a><span class="sd">        corresponding to the linear predictor of a Cox proportional hazards</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-499"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-499"><span class="linenos">499</span></a><span class="sd">        model. If `loss=&#39;squared&#39;` or `loss=&#39;ipcwls&#39;`, predictions are the</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-500"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-500"><span class="linenos">500</span></a><span class="sd">        time to event.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-501"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-501"><span class="linenos">501</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-502"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-502"><span class="linenos">502</span></a><span class="sd">        Parameters</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-503"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-503"><span class="linenos">503</span></a><span class="sd">        ----------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-504"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-504"><span class="linenos">504</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-505"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-505"><span class="linenos">505</span></a><span class="sd">            Data matrix.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-506"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-506"><span class="linenos">506</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-507"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-507"><span class="linenos">507</span></a><span class="sd">        Returns</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-508"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-508"><span class="linenos">508</span></a><span class="sd">        -------</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-509"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-509"><span class="linenos">509</span></a><span class="sd">        risk_score : array, shape = (n_samples,)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-510"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-510"><span class="linenos">510</span></a><span class="sd">            Predicted risk scores.</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-511"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-511"><span class="linenos">511</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-512"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-512"><span class="linenos">512</span></a>        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-513"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-513"><span class="linenos">513</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-514"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-514"><span class="linenos">514</span></a>
</span><span id="ComponentwiseGradientBoostingSurvivalAnalysis.predict-515"><a href="#ComponentwiseGradientBoostingSurvivalAnalysis.predict-515"><span class="linenos">515</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict risk scores.</p>

<p>If <code>loss='coxph'</code>, predictions can be interpreted as log hazard ratio
corresponding to the linear predictor of a Cox proportional hazards
model. If <code>loss='squared'</code> or <code>loss='ipcwls'</code>, predictions are the
time to event.</p>

<h2 id="parameters">Parameters</h2>

<p>X : array-like, shape = (n_samples, n_features)
    Data matrix.</p>

<h2 id="returns">Returns</h2>

<p>risk_score : array, shape = (n_samples,)
    Predicted risk scores.</p>
</div>


                                </div>
                        
                </section>
                <section id="GradientBoostingSurvivalAnalysis">
                            <input id="GradientBoostingSurvivalAnalysis-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">GradientBoostingSurvivalAnalysis</span><wbr>(<span class="base">sklearn.ensemble._gb.BaseGradientBoosting</span>, <span class="base"><a href="../base.html#SurvivalAnalysisMixin">survivalist.base.SurvivalAnalysisMixin</a></span>):

                <label class="view-source-button" for="GradientBoostingSurvivalAnalysis-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GradientBoostingSurvivalAnalysis"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GradientBoostingSurvivalAnalysis-683"><a href="#GradientBoostingSurvivalAnalysis-683"><span class="linenos"> 683</span></a><span class="k">class</span> <span class="nc">GradientBoostingSurvivalAnalysis</span><span class="p">(</span><span class="n">BaseGradientBoosting</span><span class="p">,</span> <span class="n">SurvivalAnalysisMixin</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-684"><a href="#GradientBoostingSurvivalAnalysis-684"><span class="linenos"> 684</span></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gradient-boosted Cox proportional hazard loss with</span>
</span><span id="GradientBoostingSurvivalAnalysis-685"><a href="#GradientBoostingSurvivalAnalysis-685"><span class="linenos"> 685</span></a><span class="sd">    regression trees as base learner.</span>
</span><span id="GradientBoostingSurvivalAnalysis-686"><a href="#GradientBoostingSurvivalAnalysis-686"><span class="linenos"> 686</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-687"><a href="#GradientBoostingSurvivalAnalysis-687"><span class="linenos"> 687</span></a><span class="sd">    In each stage, a regression tree is fit on the negative gradient</span>
</span><span id="GradientBoostingSurvivalAnalysis-688"><a href="#GradientBoostingSurvivalAnalysis-688"><span class="linenos"> 688</span></a><span class="sd">    of the loss function.</span>
</span><span id="GradientBoostingSurvivalAnalysis-689"><a href="#GradientBoostingSurvivalAnalysis-689"><span class="linenos"> 689</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-690"><a href="#GradientBoostingSurvivalAnalysis-690"><span class="linenos"> 690</span></a><span class="sd">    For more details on gradient boosting see [1]_ and [2]_. If `loss=&#39;coxph&#39;`,</span>
</span><span id="GradientBoostingSurvivalAnalysis-691"><a href="#GradientBoostingSurvivalAnalysis-691"><span class="linenos"> 691</span></a><span class="sd">    the partial likelihood of the proportional hazards model is optimized as</span>
</span><span id="GradientBoostingSurvivalAnalysis-692"><a href="#GradientBoostingSurvivalAnalysis-692"><span class="linenos"> 692</span></a><span class="sd">    described in [3]_. If `loss=&#39;ipcwls&#39;`, the accelerated failure time model with</span>
</span><span id="GradientBoostingSurvivalAnalysis-693"><a href="#GradientBoostingSurvivalAnalysis-693"><span class="linenos"> 693</span></a><span class="sd">    inverse-probability of censoring weighted least squares error is optimized as</span>
</span><span id="GradientBoostingSurvivalAnalysis-694"><a href="#GradientBoostingSurvivalAnalysis-694"><span class="linenos"> 694</span></a><span class="sd">    described in [4]_. When using a non-zero `dropout_rate`, regularization is</span>
</span><span id="GradientBoostingSurvivalAnalysis-695"><a href="#GradientBoostingSurvivalAnalysis-695"><span class="linenos"> 695</span></a><span class="sd">    applied during training following [5]_.</span>
</span><span id="GradientBoostingSurvivalAnalysis-696"><a href="#GradientBoostingSurvivalAnalysis-696"><span class="linenos"> 696</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-697"><a href="#GradientBoostingSurvivalAnalysis-697"><span class="linenos"> 697</span></a><span class="sd">    See the :ref:`User Guide &lt;/user_guide/boosting.ipynb&gt;` for examples.</span>
</span><span id="GradientBoostingSurvivalAnalysis-698"><a href="#GradientBoostingSurvivalAnalysis-698"><span class="linenos"> 698</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-699"><a href="#GradientBoostingSurvivalAnalysis-699"><span class="linenos"> 699</span></a><span class="sd">    Parameters</span>
</span><span id="GradientBoostingSurvivalAnalysis-700"><a href="#GradientBoostingSurvivalAnalysis-700"><span class="linenos"> 700</span></a><span class="sd">    ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis-701"><a href="#GradientBoostingSurvivalAnalysis-701"><span class="linenos"> 701</span></a><span class="sd">    loss : {&#39;coxph&#39;, &#39;squared&#39;, &#39;ipcwls&#39;}, optional, default: &#39;coxph&#39;</span>
</span><span id="GradientBoostingSurvivalAnalysis-702"><a href="#GradientBoostingSurvivalAnalysis-702"><span class="linenos"> 702</span></a><span class="sd">        loss function to be optimized. &#39;coxph&#39; refers to partial likelihood loss</span>
</span><span id="GradientBoostingSurvivalAnalysis-703"><a href="#GradientBoostingSurvivalAnalysis-703"><span class="linenos"> 703</span></a><span class="sd">        of Cox&#39;s proportional hazards model. The loss &#39;squared&#39; minimizes a</span>
</span><span id="GradientBoostingSurvivalAnalysis-704"><a href="#GradientBoostingSurvivalAnalysis-704"><span class="linenos"> 704</span></a><span class="sd">        squared regression loss that ignores predictions beyond the time of censoring,</span>
</span><span id="GradientBoostingSurvivalAnalysis-705"><a href="#GradientBoostingSurvivalAnalysis-705"><span class="linenos"> 705</span></a><span class="sd">        and &#39;ipcwls&#39; refers to inverse-probability of censoring weighted least squares error.</span>
</span><span id="GradientBoostingSurvivalAnalysis-706"><a href="#GradientBoostingSurvivalAnalysis-706"><span class="linenos"> 706</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-707"><a href="#GradientBoostingSurvivalAnalysis-707"><span class="linenos"> 707</span></a><span class="sd">    learning_rate : float, optional, default: 0.1</span>
</span><span id="GradientBoostingSurvivalAnalysis-708"><a href="#GradientBoostingSurvivalAnalysis-708"><span class="linenos"> 708</span></a><span class="sd">        learning rate shrinks the contribution of each tree by `learning_rate`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-709"><a href="#GradientBoostingSurvivalAnalysis-709"><span class="linenos"> 709</span></a><span class="sd">        There is a trade-off between `learning_rate` and `n_estimators`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-710"><a href="#GradientBoostingSurvivalAnalysis-710"><span class="linenos"> 710</span></a><span class="sd">        Values must be in the range `[0.0, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-711"><a href="#GradientBoostingSurvivalAnalysis-711"><span class="linenos"> 711</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-712"><a href="#GradientBoostingSurvivalAnalysis-712"><span class="linenos"> 712</span></a><span class="sd">    n_estimators : int, default: 100</span>
</span><span id="GradientBoostingSurvivalAnalysis-713"><a href="#GradientBoostingSurvivalAnalysis-713"><span class="linenos"> 713</span></a><span class="sd">        The number of regression trees to create. Gradient boosting</span>
</span><span id="GradientBoostingSurvivalAnalysis-714"><a href="#GradientBoostingSurvivalAnalysis-714"><span class="linenos"> 714</span></a><span class="sd">        is fairly robust to over-fitting so a large number usually</span>
</span><span id="GradientBoostingSurvivalAnalysis-715"><a href="#GradientBoostingSurvivalAnalysis-715"><span class="linenos"> 715</span></a><span class="sd">        results in better performance.</span>
</span><span id="GradientBoostingSurvivalAnalysis-716"><a href="#GradientBoostingSurvivalAnalysis-716"><span class="linenos"> 716</span></a><span class="sd">        Values must be in the range `[1, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-717"><a href="#GradientBoostingSurvivalAnalysis-717"><span class="linenos"> 717</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-718"><a href="#GradientBoostingSurvivalAnalysis-718"><span class="linenos"> 718</span></a><span class="sd">    subsample : float, optional, default: 1.0</span>
</span><span id="GradientBoostingSurvivalAnalysis-719"><a href="#GradientBoostingSurvivalAnalysis-719"><span class="linenos"> 719</span></a><span class="sd">        The fraction of samples to be used for fitting the individual base</span>
</span><span id="GradientBoostingSurvivalAnalysis-720"><a href="#GradientBoostingSurvivalAnalysis-720"><span class="linenos"> 720</span></a><span class="sd">        learners. If smaller than 1.0 this results in Stochastic Gradient</span>
</span><span id="GradientBoostingSurvivalAnalysis-721"><a href="#GradientBoostingSurvivalAnalysis-721"><span class="linenos"> 721</span></a><span class="sd">        Boosting. `subsample` interacts with the parameter `n_estimators`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-722"><a href="#GradientBoostingSurvivalAnalysis-722"><span class="linenos"> 722</span></a><span class="sd">        Choosing `subsample &lt; 1.0` leads to a reduction of variance</span>
</span><span id="GradientBoostingSurvivalAnalysis-723"><a href="#GradientBoostingSurvivalAnalysis-723"><span class="linenos"> 723</span></a><span class="sd">        and an increase in bias.</span>
</span><span id="GradientBoostingSurvivalAnalysis-724"><a href="#GradientBoostingSurvivalAnalysis-724"><span class="linenos"> 724</span></a><span class="sd">        Values must be in the range `(0.0, 1.0]`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-725"><a href="#GradientBoostingSurvivalAnalysis-725"><span class="linenos"> 725</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-726"><a href="#GradientBoostingSurvivalAnalysis-726"><span class="linenos"> 726</span></a><span class="sd">    criterion : {&#39;friedman_mse&#39;, &#39;squared_error&#39;}, default: &#39;friedman_mse&#39;</span>
</span><span id="GradientBoostingSurvivalAnalysis-727"><a href="#GradientBoostingSurvivalAnalysis-727"><span class="linenos"> 727</span></a><span class="sd">        The function to measure the quality of a split. Supported criteria are</span>
</span><span id="GradientBoostingSurvivalAnalysis-728"><a href="#GradientBoostingSurvivalAnalysis-728"><span class="linenos"> 728</span></a><span class="sd">        &#39;friedman_mse&#39; for the mean squared error with improvement score by</span>
</span><span id="GradientBoostingSurvivalAnalysis-729"><a href="#GradientBoostingSurvivalAnalysis-729"><span class="linenos"> 729</span></a><span class="sd">        Friedman, &#39;squared_error&#39; for mean squared error. The default value of</span>
</span><span id="GradientBoostingSurvivalAnalysis-730"><a href="#GradientBoostingSurvivalAnalysis-730"><span class="linenos"> 730</span></a><span class="sd">        &#39;friedman_mse&#39; is generally the best as it can provide a better</span>
</span><span id="GradientBoostingSurvivalAnalysis-731"><a href="#GradientBoostingSurvivalAnalysis-731"><span class="linenos"> 731</span></a><span class="sd">        approximation in some cases.</span>
</span><span id="GradientBoostingSurvivalAnalysis-732"><a href="#GradientBoostingSurvivalAnalysis-732"><span class="linenos"> 732</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-733"><a href="#GradientBoostingSurvivalAnalysis-733"><span class="linenos"> 733</span></a><span class="sd">    min_samples_split : int or float, optional, default: 2</span>
</span><span id="GradientBoostingSurvivalAnalysis-734"><a href="#GradientBoostingSurvivalAnalysis-734"><span class="linenos"> 734</span></a><span class="sd">        The minimum number of samples required to split an internal node:</span>
</span><span id="GradientBoostingSurvivalAnalysis-735"><a href="#GradientBoostingSurvivalAnalysis-735"><span class="linenos"> 735</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-736"><a href="#GradientBoostingSurvivalAnalysis-736"><span class="linenos"> 736</span></a><span class="sd">        - If int, values must be in the range `[2, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-737"><a href="#GradientBoostingSurvivalAnalysis-737"><span class="linenos"> 737</span></a><span class="sd">        - If float, values must be in the range `(0.0, 1.0]` and `min_samples_split`</span>
</span><span id="GradientBoostingSurvivalAnalysis-738"><a href="#GradientBoostingSurvivalAnalysis-738"><span class="linenos"> 738</span></a><span class="sd">          will be `ceil(min_samples_split * n_samples)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-739"><a href="#GradientBoostingSurvivalAnalysis-739"><span class="linenos"> 739</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-740"><a href="#GradientBoostingSurvivalAnalysis-740"><span class="linenos"> 740</span></a><span class="sd">    min_samples_leaf : int or float, default: 1</span>
</span><span id="GradientBoostingSurvivalAnalysis-741"><a href="#GradientBoostingSurvivalAnalysis-741"><span class="linenos"> 741</span></a><span class="sd">        The minimum number of samples required to be at a leaf node.</span>
</span><span id="GradientBoostingSurvivalAnalysis-742"><a href="#GradientBoostingSurvivalAnalysis-742"><span class="linenos"> 742</span></a><span class="sd">        A split point at any depth will only be considered if it leaves at</span>
</span><span id="GradientBoostingSurvivalAnalysis-743"><a href="#GradientBoostingSurvivalAnalysis-743"><span class="linenos"> 743</span></a><span class="sd">        least ``min_samples_leaf`` training samples in each of the left and</span>
</span><span id="GradientBoostingSurvivalAnalysis-744"><a href="#GradientBoostingSurvivalAnalysis-744"><span class="linenos"> 744</span></a><span class="sd">        right branches.  This may have the effect of smoothing the model,</span>
</span><span id="GradientBoostingSurvivalAnalysis-745"><a href="#GradientBoostingSurvivalAnalysis-745"><span class="linenos"> 745</span></a><span class="sd">        especially in regression.</span>
</span><span id="GradientBoostingSurvivalAnalysis-746"><a href="#GradientBoostingSurvivalAnalysis-746"><span class="linenos"> 746</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-747"><a href="#GradientBoostingSurvivalAnalysis-747"><span class="linenos"> 747</span></a><span class="sd">        - If int, values must be in the range `[1, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-748"><a href="#GradientBoostingSurvivalAnalysis-748"><span class="linenos"> 748</span></a><span class="sd">        - If float, values must be in the range `(0.0, 1.0)` and `min_samples_leaf`</span>
</span><span id="GradientBoostingSurvivalAnalysis-749"><a href="#GradientBoostingSurvivalAnalysis-749"><span class="linenos"> 749</span></a><span class="sd">          will be `ceil(min_samples_leaf * n_samples)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-750"><a href="#GradientBoostingSurvivalAnalysis-750"><span class="linenos"> 750</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-751"><a href="#GradientBoostingSurvivalAnalysis-751"><span class="linenos"> 751</span></a><span class="sd">    min_weight_fraction_leaf : float, optional, default: 0.</span>
</span><span id="GradientBoostingSurvivalAnalysis-752"><a href="#GradientBoostingSurvivalAnalysis-752"><span class="linenos"> 752</span></a><span class="sd">        The minimum weighted fraction of the sum total of weights (of all</span>
</span><span id="GradientBoostingSurvivalAnalysis-753"><a href="#GradientBoostingSurvivalAnalysis-753"><span class="linenos"> 753</span></a><span class="sd">        the input samples) required to be at a leaf node. Samples have</span>
</span><span id="GradientBoostingSurvivalAnalysis-754"><a href="#GradientBoostingSurvivalAnalysis-754"><span class="linenos"> 754</span></a><span class="sd">        equal weight when `sample_weight` is not provided.</span>
</span><span id="GradientBoostingSurvivalAnalysis-755"><a href="#GradientBoostingSurvivalAnalysis-755"><span class="linenos"> 755</span></a><span class="sd">        Values must be in the range `[0.0, 0.5]`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-756"><a href="#GradientBoostingSurvivalAnalysis-756"><span class="linenos"> 756</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-757"><a href="#GradientBoostingSurvivalAnalysis-757"><span class="linenos"> 757</span></a><span class="sd">    max_depth : int or None, optional, default: 3</span>
</span><span id="GradientBoostingSurvivalAnalysis-758"><a href="#GradientBoostingSurvivalAnalysis-758"><span class="linenos"> 758</span></a><span class="sd">        Maximum depth of the individual regression estimators. The maximum</span>
</span><span id="GradientBoostingSurvivalAnalysis-759"><a href="#GradientBoostingSurvivalAnalysis-759"><span class="linenos"> 759</span></a><span class="sd">        depth limits the number of nodes in the tree. Tune this parameter</span>
</span><span id="GradientBoostingSurvivalAnalysis-760"><a href="#GradientBoostingSurvivalAnalysis-760"><span class="linenos"> 760</span></a><span class="sd">        for best performance; the best value depends on the interaction</span>
</span><span id="GradientBoostingSurvivalAnalysis-761"><a href="#GradientBoostingSurvivalAnalysis-761"><span class="linenos"> 761</span></a><span class="sd">        of the input variables. If None, then nodes are expanded until</span>
</span><span id="GradientBoostingSurvivalAnalysis-762"><a href="#GradientBoostingSurvivalAnalysis-762"><span class="linenos"> 762</span></a><span class="sd">        all leaves are pure or until all leaves contain less than</span>
</span><span id="GradientBoostingSurvivalAnalysis-763"><a href="#GradientBoostingSurvivalAnalysis-763"><span class="linenos"> 763</span></a><span class="sd">        `min_samples_split` samples.</span>
</span><span id="GradientBoostingSurvivalAnalysis-764"><a href="#GradientBoostingSurvivalAnalysis-764"><span class="linenos"> 764</span></a><span class="sd">        If int, values must be in the range `[1, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-765"><a href="#GradientBoostingSurvivalAnalysis-765"><span class="linenos"> 765</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-766"><a href="#GradientBoostingSurvivalAnalysis-766"><span class="linenos"> 766</span></a><span class="sd">    min_impurity_decrease : float, optional, default: 0.</span>
</span><span id="GradientBoostingSurvivalAnalysis-767"><a href="#GradientBoostingSurvivalAnalysis-767"><span class="linenos"> 767</span></a><span class="sd">        A node will be split if this split induces a decrease of the impurity</span>
</span><span id="GradientBoostingSurvivalAnalysis-768"><a href="#GradientBoostingSurvivalAnalysis-768"><span class="linenos"> 768</span></a><span class="sd">        greater than or equal to this value.</span>
</span><span id="GradientBoostingSurvivalAnalysis-769"><a href="#GradientBoostingSurvivalAnalysis-769"><span class="linenos"> 769</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-770"><a href="#GradientBoostingSurvivalAnalysis-770"><span class="linenos"> 770</span></a><span class="sd">        The weighted impurity decrease equation is the following::</span>
</span><span id="GradientBoostingSurvivalAnalysis-771"><a href="#GradientBoostingSurvivalAnalysis-771"><span class="linenos"> 771</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-772"><a href="#GradientBoostingSurvivalAnalysis-772"><span class="linenos"> 772</span></a><span class="sd">            N_t / N * (impurity - N_t_R / N_t * right_impurity</span>
</span><span id="GradientBoostingSurvivalAnalysis-773"><a href="#GradientBoostingSurvivalAnalysis-773"><span class="linenos"> 773</span></a><span class="sd">                                - N_t_L / N_t * left_impurity)</span>
</span><span id="GradientBoostingSurvivalAnalysis-774"><a href="#GradientBoostingSurvivalAnalysis-774"><span class="linenos"> 774</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-775"><a href="#GradientBoostingSurvivalAnalysis-775"><span class="linenos"> 775</span></a><span class="sd">        where ``N`` is the total number of samples, ``N_t`` is the number of</span>
</span><span id="GradientBoostingSurvivalAnalysis-776"><a href="#GradientBoostingSurvivalAnalysis-776"><span class="linenos"> 776</span></a><span class="sd">        samples at the current node, ``N_t_L`` is the number of samples in the</span>
</span><span id="GradientBoostingSurvivalAnalysis-777"><a href="#GradientBoostingSurvivalAnalysis-777"><span class="linenos"> 777</span></a><span class="sd">        left child, and ``N_t_R`` is the number of samples in the right child.</span>
</span><span id="GradientBoostingSurvivalAnalysis-778"><a href="#GradientBoostingSurvivalAnalysis-778"><span class="linenos"> 778</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-779"><a href="#GradientBoostingSurvivalAnalysis-779"><span class="linenos"> 779</span></a><span class="sd">        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,</span>
</span><span id="GradientBoostingSurvivalAnalysis-780"><a href="#GradientBoostingSurvivalAnalysis-780"><span class="linenos"> 780</span></a><span class="sd">        if ``sample_weight`` is passed.</span>
</span><span id="GradientBoostingSurvivalAnalysis-781"><a href="#GradientBoostingSurvivalAnalysis-781"><span class="linenos"> 781</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-782"><a href="#GradientBoostingSurvivalAnalysis-782"><span class="linenos"> 782</span></a><span class="sd">    random_state : int seed, RandomState instance, or None, default: None</span>
</span><span id="GradientBoostingSurvivalAnalysis-783"><a href="#GradientBoostingSurvivalAnalysis-783"><span class="linenos"> 783</span></a><span class="sd">        Controls the random seed given to each Tree estimator at each</span>
</span><span id="GradientBoostingSurvivalAnalysis-784"><a href="#GradientBoostingSurvivalAnalysis-784"><span class="linenos"> 784</span></a><span class="sd">        boosting iteration.</span>
</span><span id="GradientBoostingSurvivalAnalysis-785"><a href="#GradientBoostingSurvivalAnalysis-785"><span class="linenos"> 785</span></a><span class="sd">        In addition, it controls the random permutation of the features at</span>
</span><span id="GradientBoostingSurvivalAnalysis-786"><a href="#GradientBoostingSurvivalAnalysis-786"><span class="linenos"> 786</span></a><span class="sd">        each split.</span>
</span><span id="GradientBoostingSurvivalAnalysis-787"><a href="#GradientBoostingSurvivalAnalysis-787"><span class="linenos"> 787</span></a><span class="sd">        It also controls the random splitting of the training data to obtain a</span>
</span><span id="GradientBoostingSurvivalAnalysis-788"><a href="#GradientBoostingSurvivalAnalysis-788"><span class="linenos"> 788</span></a><span class="sd">        validation set if `n_iter_no_change` is not None.</span>
</span><span id="GradientBoostingSurvivalAnalysis-789"><a href="#GradientBoostingSurvivalAnalysis-789"><span class="linenos"> 789</span></a><span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
</span><span id="GradientBoostingSurvivalAnalysis-790"><a href="#GradientBoostingSurvivalAnalysis-790"><span class="linenos"> 790</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-791"><a href="#GradientBoostingSurvivalAnalysis-791"><span class="linenos"> 791</span></a><span class="sd">    max_features : int, float, string or None, optional, default: None</span>
</span><span id="GradientBoostingSurvivalAnalysis-792"><a href="#GradientBoostingSurvivalAnalysis-792"><span class="linenos"> 792</span></a><span class="sd">        The number of features to consider when looking for the best split:</span>
</span><span id="GradientBoostingSurvivalAnalysis-793"><a href="#GradientBoostingSurvivalAnalysis-793"><span class="linenos"> 793</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-794"><a href="#GradientBoostingSurvivalAnalysis-794"><span class="linenos"> 794</span></a><span class="sd">        - If int, values must be in the range `[1, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-795"><a href="#GradientBoostingSurvivalAnalysis-795"><span class="linenos"> 795</span></a><span class="sd">        - If float, values must be in the range `(0.0, 1.0]` and the features</span>
</span><span id="GradientBoostingSurvivalAnalysis-796"><a href="#GradientBoostingSurvivalAnalysis-796"><span class="linenos"> 796</span></a><span class="sd">          considered at each split will be `max(1, int(max_features * n_features_in_))`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-797"><a href="#GradientBoostingSurvivalAnalysis-797"><span class="linenos"> 797</span></a><span class="sd">        - If &#39;sqrt&#39;, then `max_features=sqrt(n_features)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-798"><a href="#GradientBoostingSurvivalAnalysis-798"><span class="linenos"> 798</span></a><span class="sd">        - If &#39;log2&#39;, then `max_features=log2(n_features)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-799"><a href="#GradientBoostingSurvivalAnalysis-799"><span class="linenos"> 799</span></a><span class="sd">        - If None, then `max_features=n_features`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-800"><a href="#GradientBoostingSurvivalAnalysis-800"><span class="linenos"> 800</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-801"><a href="#GradientBoostingSurvivalAnalysis-801"><span class="linenos"> 801</span></a><span class="sd">        Choosing `max_features &lt; n_features` leads to a reduction of variance</span>
</span><span id="GradientBoostingSurvivalAnalysis-802"><a href="#GradientBoostingSurvivalAnalysis-802"><span class="linenos"> 802</span></a><span class="sd">        and an increase in bias.</span>
</span><span id="GradientBoostingSurvivalAnalysis-803"><a href="#GradientBoostingSurvivalAnalysis-803"><span class="linenos"> 803</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-804"><a href="#GradientBoostingSurvivalAnalysis-804"><span class="linenos"> 804</span></a><span class="sd">        Note: the search for a split does not stop until at least one</span>
</span><span id="GradientBoostingSurvivalAnalysis-805"><a href="#GradientBoostingSurvivalAnalysis-805"><span class="linenos"> 805</span></a><span class="sd">        valid partition of the node samples is found, even if it requires to</span>
</span><span id="GradientBoostingSurvivalAnalysis-806"><a href="#GradientBoostingSurvivalAnalysis-806"><span class="linenos"> 806</span></a><span class="sd">        effectively inspect more than ``max_features`` features.</span>
</span><span id="GradientBoostingSurvivalAnalysis-807"><a href="#GradientBoostingSurvivalAnalysis-807"><span class="linenos"> 807</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-808"><a href="#GradientBoostingSurvivalAnalysis-808"><span class="linenos"> 808</span></a><span class="sd">    max_leaf_nodes : int or None, optional, default: None</span>
</span><span id="GradientBoostingSurvivalAnalysis-809"><a href="#GradientBoostingSurvivalAnalysis-809"><span class="linenos"> 809</span></a><span class="sd">        Grow trees with ``max_leaf_nodes`` in best-first fashion.</span>
</span><span id="GradientBoostingSurvivalAnalysis-810"><a href="#GradientBoostingSurvivalAnalysis-810"><span class="linenos"> 810</span></a><span class="sd">        Best nodes are defined as relative reduction in impurity.</span>
</span><span id="GradientBoostingSurvivalAnalysis-811"><a href="#GradientBoostingSurvivalAnalysis-811"><span class="linenos"> 811</span></a><span class="sd">        Values must be in the range `[2, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-812"><a href="#GradientBoostingSurvivalAnalysis-812"><span class="linenos"> 812</span></a><span class="sd">        If `None`, then unlimited number of leaf nodes.</span>
</span><span id="GradientBoostingSurvivalAnalysis-813"><a href="#GradientBoostingSurvivalAnalysis-813"><span class="linenos"> 813</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-814"><a href="#GradientBoostingSurvivalAnalysis-814"><span class="linenos"> 814</span></a><span class="sd">    warm_start : bool, default: False</span>
</span><span id="GradientBoostingSurvivalAnalysis-815"><a href="#GradientBoostingSurvivalAnalysis-815"><span class="linenos"> 815</span></a><span class="sd">        When set to ``True``, reuse the solution of the previous call to fit</span>
</span><span id="GradientBoostingSurvivalAnalysis-816"><a href="#GradientBoostingSurvivalAnalysis-816"><span class="linenos"> 816</span></a><span class="sd">        and add more estimators to the ensemble, otherwise, just erase the</span>
</span><span id="GradientBoostingSurvivalAnalysis-817"><a href="#GradientBoostingSurvivalAnalysis-817"><span class="linenos"> 817</span></a><span class="sd">        previous solution.</span>
</span><span id="GradientBoostingSurvivalAnalysis-818"><a href="#GradientBoostingSurvivalAnalysis-818"><span class="linenos"> 818</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-819"><a href="#GradientBoostingSurvivalAnalysis-819"><span class="linenos"> 819</span></a><span class="sd">    validation_fraction : float, default: 0.1</span>
</span><span id="GradientBoostingSurvivalAnalysis-820"><a href="#GradientBoostingSurvivalAnalysis-820"><span class="linenos"> 820</span></a><span class="sd">        The proportion of training data to set aside as validation set for</span>
</span><span id="GradientBoostingSurvivalAnalysis-821"><a href="#GradientBoostingSurvivalAnalysis-821"><span class="linenos"> 821</span></a><span class="sd">        early stopping. Values must be in the range `(0.0, 1.0)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-822"><a href="#GradientBoostingSurvivalAnalysis-822"><span class="linenos"> 822</span></a><span class="sd">        Only used if ``n_iter_no_change`` is set to an integer.</span>
</span><span id="GradientBoostingSurvivalAnalysis-823"><a href="#GradientBoostingSurvivalAnalysis-823"><span class="linenos"> 823</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-824"><a href="#GradientBoostingSurvivalAnalysis-824"><span class="linenos"> 824</span></a><span class="sd">    n_iter_no_change : int, default: None</span>
</span><span id="GradientBoostingSurvivalAnalysis-825"><a href="#GradientBoostingSurvivalAnalysis-825"><span class="linenos"> 825</span></a><span class="sd">        ``n_iter_no_change`` is used to decide if early stopping will be used</span>
</span><span id="GradientBoostingSurvivalAnalysis-826"><a href="#GradientBoostingSurvivalAnalysis-826"><span class="linenos"> 826</span></a><span class="sd">        to terminate training when validation score is not improving. By</span>
</span><span id="GradientBoostingSurvivalAnalysis-827"><a href="#GradientBoostingSurvivalAnalysis-827"><span class="linenos"> 827</span></a><span class="sd">        default it is set to None to disable early stopping. If set to a</span>
</span><span id="GradientBoostingSurvivalAnalysis-828"><a href="#GradientBoostingSurvivalAnalysis-828"><span class="linenos"> 828</span></a><span class="sd">        number, it will set aside ``validation_fraction`` size of the training</span>
</span><span id="GradientBoostingSurvivalAnalysis-829"><a href="#GradientBoostingSurvivalAnalysis-829"><span class="linenos"> 829</span></a><span class="sd">        data as validation and terminate training when validation score is not</span>
</span><span id="GradientBoostingSurvivalAnalysis-830"><a href="#GradientBoostingSurvivalAnalysis-830"><span class="linenos"> 830</span></a><span class="sd">        improving in all of the previous ``n_iter_no_change`` numbers of</span>
</span><span id="GradientBoostingSurvivalAnalysis-831"><a href="#GradientBoostingSurvivalAnalysis-831"><span class="linenos"> 831</span></a><span class="sd">        iterations. The split is stratified.</span>
</span><span id="GradientBoostingSurvivalAnalysis-832"><a href="#GradientBoostingSurvivalAnalysis-832"><span class="linenos"> 832</span></a><span class="sd">        Values must be in the range `[1, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-833"><a href="#GradientBoostingSurvivalAnalysis-833"><span class="linenos"> 833</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-834"><a href="#GradientBoostingSurvivalAnalysis-834"><span class="linenos"> 834</span></a><span class="sd">    tol : float, default: 1e-4</span>
</span><span id="GradientBoostingSurvivalAnalysis-835"><a href="#GradientBoostingSurvivalAnalysis-835"><span class="linenos"> 835</span></a><span class="sd">        Tolerance for the early stopping. When the loss is not improving</span>
</span><span id="GradientBoostingSurvivalAnalysis-836"><a href="#GradientBoostingSurvivalAnalysis-836"><span class="linenos"> 836</span></a><span class="sd">        by at least tol for ``n_iter_no_change`` iterations (if set to a</span>
</span><span id="GradientBoostingSurvivalAnalysis-837"><a href="#GradientBoostingSurvivalAnalysis-837"><span class="linenos"> 837</span></a><span class="sd">        number), the training stops.</span>
</span><span id="GradientBoostingSurvivalAnalysis-838"><a href="#GradientBoostingSurvivalAnalysis-838"><span class="linenos"> 838</span></a><span class="sd">        Values must be in the range `[0.0, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-839"><a href="#GradientBoostingSurvivalAnalysis-839"><span class="linenos"> 839</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-840"><a href="#GradientBoostingSurvivalAnalysis-840"><span class="linenos"> 840</span></a><span class="sd">    dropout_rate : float, optional, default: 0.0</span>
</span><span id="GradientBoostingSurvivalAnalysis-841"><a href="#GradientBoostingSurvivalAnalysis-841"><span class="linenos"> 841</span></a><span class="sd">        If larger than zero, the residuals at each iteration are only computed</span>
</span><span id="GradientBoostingSurvivalAnalysis-842"><a href="#GradientBoostingSurvivalAnalysis-842"><span class="linenos"> 842</span></a><span class="sd">        from a random subset of base learners. The value corresponds to the</span>
</span><span id="GradientBoostingSurvivalAnalysis-843"><a href="#GradientBoostingSurvivalAnalysis-843"><span class="linenos"> 843</span></a><span class="sd">        percentage of base learners that are dropped. In each iteration,</span>
</span><span id="GradientBoostingSurvivalAnalysis-844"><a href="#GradientBoostingSurvivalAnalysis-844"><span class="linenos"> 844</span></a><span class="sd">        at least one base learner is dropped. This is an alternative regularization</span>
</span><span id="GradientBoostingSurvivalAnalysis-845"><a href="#GradientBoostingSurvivalAnalysis-845"><span class="linenos"> 845</span></a><span class="sd">        to shrinkage, i.e., setting `learning_rate &lt; 1.0`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-846"><a href="#GradientBoostingSurvivalAnalysis-846"><span class="linenos"> 846</span></a><span class="sd">        Values must be in the range `[0.0, 1.0)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-847"><a href="#GradientBoostingSurvivalAnalysis-847"><span class="linenos"> 847</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-848"><a href="#GradientBoostingSurvivalAnalysis-848"><span class="linenos"> 848</span></a><span class="sd">    verbose : int, default: 0</span>
</span><span id="GradientBoostingSurvivalAnalysis-849"><a href="#GradientBoostingSurvivalAnalysis-849"><span class="linenos"> 849</span></a><span class="sd">        Enable verbose output. If 1 then it prints progress and performance</span>
</span><span id="GradientBoostingSurvivalAnalysis-850"><a href="#GradientBoostingSurvivalAnalysis-850"><span class="linenos"> 850</span></a><span class="sd">        once in a while (the more trees the lower the frequency). If greater</span>
</span><span id="GradientBoostingSurvivalAnalysis-851"><a href="#GradientBoostingSurvivalAnalysis-851"><span class="linenos"> 851</span></a><span class="sd">        than 1 then it prints progress and performance for every tree.</span>
</span><span id="GradientBoostingSurvivalAnalysis-852"><a href="#GradientBoostingSurvivalAnalysis-852"><span class="linenos"> 852</span></a><span class="sd">        Values must be in the range `[0, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-853"><a href="#GradientBoostingSurvivalAnalysis-853"><span class="linenos"> 853</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-854"><a href="#GradientBoostingSurvivalAnalysis-854"><span class="linenos"> 854</span></a><span class="sd">    ccp_alpha : non-negative float, optional, default: 0.0.</span>
</span><span id="GradientBoostingSurvivalAnalysis-855"><a href="#GradientBoostingSurvivalAnalysis-855"><span class="linenos"> 855</span></a><span class="sd">        Complexity parameter used for Minimal Cost-Complexity Pruning. The</span>
</span><span id="GradientBoostingSurvivalAnalysis-856"><a href="#GradientBoostingSurvivalAnalysis-856"><span class="linenos"> 856</span></a><span class="sd">        subtree with the largest cost complexity that is smaller than</span>
</span><span id="GradientBoostingSurvivalAnalysis-857"><a href="#GradientBoostingSurvivalAnalysis-857"><span class="linenos"> 857</span></a><span class="sd">        ``ccp_alpha`` will be chosen. By default, no pruning is performed.</span>
</span><span id="GradientBoostingSurvivalAnalysis-858"><a href="#GradientBoostingSurvivalAnalysis-858"><span class="linenos"> 858</span></a><span class="sd">        Values must be in the range `[0.0, inf)`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-859"><a href="#GradientBoostingSurvivalAnalysis-859"><span class="linenos"> 859</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-860"><a href="#GradientBoostingSurvivalAnalysis-860"><span class="linenos"> 860</span></a><span class="sd">    Attributes</span>
</span><span id="GradientBoostingSurvivalAnalysis-861"><a href="#GradientBoostingSurvivalAnalysis-861"><span class="linenos"> 861</span></a><span class="sd">    ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis-862"><a href="#GradientBoostingSurvivalAnalysis-862"><span class="linenos"> 862</span></a><span class="sd">    n_estimators_ : int</span>
</span><span id="GradientBoostingSurvivalAnalysis-863"><a href="#GradientBoostingSurvivalAnalysis-863"><span class="linenos"> 863</span></a><span class="sd">        The number of estimators as selected by early stopping (if</span>
</span><span id="GradientBoostingSurvivalAnalysis-864"><a href="#GradientBoostingSurvivalAnalysis-864"><span class="linenos"> 864</span></a><span class="sd">        ``n_iter_no_change`` is specified). Otherwise it is set to</span>
</span><span id="GradientBoostingSurvivalAnalysis-865"><a href="#GradientBoostingSurvivalAnalysis-865"><span class="linenos"> 865</span></a><span class="sd">        ``n_estimators``.</span>
</span><span id="GradientBoostingSurvivalAnalysis-866"><a href="#GradientBoostingSurvivalAnalysis-866"><span class="linenos"> 866</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-867"><a href="#GradientBoostingSurvivalAnalysis-867"><span class="linenos"> 867</span></a><span class="sd">    feature_importances_ : ndarray, shape = (n_features,)</span>
</span><span id="GradientBoostingSurvivalAnalysis-868"><a href="#GradientBoostingSurvivalAnalysis-868"><span class="linenos"> 868</span></a><span class="sd">        The feature importances (the higher, the more important the feature).</span>
</span><span id="GradientBoostingSurvivalAnalysis-869"><a href="#GradientBoostingSurvivalAnalysis-869"><span class="linenos"> 869</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-870"><a href="#GradientBoostingSurvivalAnalysis-870"><span class="linenos"> 870</span></a><span class="sd">    estimators_ : ndarray of DecisionTreeRegressor, shape = (n_estimators, 1)</span>
</span><span id="GradientBoostingSurvivalAnalysis-871"><a href="#GradientBoostingSurvivalAnalysis-871"><span class="linenos"> 871</span></a><span class="sd">        The collection of fitted sub-estimators.</span>
</span><span id="GradientBoostingSurvivalAnalysis-872"><a href="#GradientBoostingSurvivalAnalysis-872"><span class="linenos"> 872</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-873"><a href="#GradientBoostingSurvivalAnalysis-873"><span class="linenos"> 873</span></a><span class="sd">    train_score_ : ndarray, shape = (n_estimators,)</span>
</span><span id="GradientBoostingSurvivalAnalysis-874"><a href="#GradientBoostingSurvivalAnalysis-874"><span class="linenos"> 874</span></a><span class="sd">        The i-th score ``train_score_[i]`` is the loss of the</span>
</span><span id="GradientBoostingSurvivalAnalysis-875"><a href="#GradientBoostingSurvivalAnalysis-875"><span class="linenos"> 875</span></a><span class="sd">        model at iteration ``i`` on the in-bag sample.</span>
</span><span id="GradientBoostingSurvivalAnalysis-876"><a href="#GradientBoostingSurvivalAnalysis-876"><span class="linenos"> 876</span></a><span class="sd">        If ``subsample == 1`` this is the loss on the training data.</span>
</span><span id="GradientBoostingSurvivalAnalysis-877"><a href="#GradientBoostingSurvivalAnalysis-877"><span class="linenos"> 877</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-878"><a href="#GradientBoostingSurvivalAnalysis-878"><span class="linenos"> 878</span></a><span class="sd">    oob_improvement_ : ndarray, shape = (n_estimators,)</span>
</span><span id="GradientBoostingSurvivalAnalysis-879"><a href="#GradientBoostingSurvivalAnalysis-879"><span class="linenos"> 879</span></a><span class="sd">        The improvement in loss on the out-of-bag samples</span>
</span><span id="GradientBoostingSurvivalAnalysis-880"><a href="#GradientBoostingSurvivalAnalysis-880"><span class="linenos"> 880</span></a><span class="sd">        relative to the previous iteration.</span>
</span><span id="GradientBoostingSurvivalAnalysis-881"><a href="#GradientBoostingSurvivalAnalysis-881"><span class="linenos"> 881</span></a><span class="sd">        ``oob_improvement_[0]`` is the improvement in</span>
</span><span id="GradientBoostingSurvivalAnalysis-882"><a href="#GradientBoostingSurvivalAnalysis-882"><span class="linenos"> 882</span></a><span class="sd">        loss of the first stage over the ``init`` estimator.</span>
</span><span id="GradientBoostingSurvivalAnalysis-883"><a href="#GradientBoostingSurvivalAnalysis-883"><span class="linenos"> 883</span></a><span class="sd">        Only available if ``subsample &lt; 1.0``.</span>
</span><span id="GradientBoostingSurvivalAnalysis-884"><a href="#GradientBoostingSurvivalAnalysis-884"><span class="linenos"> 884</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-885"><a href="#GradientBoostingSurvivalAnalysis-885"><span class="linenos"> 885</span></a><span class="sd">    oob_scores_ : ndarray of shape (n_estimators,)</span>
</span><span id="GradientBoostingSurvivalAnalysis-886"><a href="#GradientBoostingSurvivalAnalysis-886"><span class="linenos"> 886</span></a><span class="sd">        The full history of the loss values on the out-of-bag</span>
</span><span id="GradientBoostingSurvivalAnalysis-887"><a href="#GradientBoostingSurvivalAnalysis-887"><span class="linenos"> 887</span></a><span class="sd">        samples. Only available if ``subsample &lt; 1.0``.</span>
</span><span id="GradientBoostingSurvivalAnalysis-888"><a href="#GradientBoostingSurvivalAnalysis-888"><span class="linenos"> 888</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-889"><a href="#GradientBoostingSurvivalAnalysis-889"><span class="linenos"> 889</span></a><span class="sd">    oob_score_ : float</span>
</span><span id="GradientBoostingSurvivalAnalysis-890"><a href="#GradientBoostingSurvivalAnalysis-890"><span class="linenos"> 890</span></a><span class="sd">        The last value of the loss on the out-of-bag samples. It is</span>
</span><span id="GradientBoostingSurvivalAnalysis-891"><a href="#GradientBoostingSurvivalAnalysis-891"><span class="linenos"> 891</span></a><span class="sd">        the same as ``oob_scores_[-1]``. Only available if ``subsample &lt; 1.0``.</span>
</span><span id="GradientBoostingSurvivalAnalysis-892"><a href="#GradientBoostingSurvivalAnalysis-892"><span class="linenos"> 892</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-893"><a href="#GradientBoostingSurvivalAnalysis-893"><span class="linenos"> 893</span></a><span class="sd">    n_features_in_ : int</span>
</span><span id="GradientBoostingSurvivalAnalysis-894"><a href="#GradientBoostingSurvivalAnalysis-894"><span class="linenos"> 894</span></a><span class="sd">        Number of features seen during ``fit``.</span>
</span><span id="GradientBoostingSurvivalAnalysis-895"><a href="#GradientBoostingSurvivalAnalysis-895"><span class="linenos"> 895</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-896"><a href="#GradientBoostingSurvivalAnalysis-896"><span class="linenos"> 896</span></a><span class="sd">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span>
</span><span id="GradientBoostingSurvivalAnalysis-897"><a href="#GradientBoostingSurvivalAnalysis-897"><span class="linenos"> 897</span></a><span class="sd">        Names of features seen during ``fit``. Defined only when `X`</span>
</span><span id="GradientBoostingSurvivalAnalysis-898"><a href="#GradientBoostingSurvivalAnalysis-898"><span class="linenos"> 898</span></a><span class="sd">        has feature names that are all strings.</span>
</span><span id="GradientBoostingSurvivalAnalysis-899"><a href="#GradientBoostingSurvivalAnalysis-899"><span class="linenos"> 899</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-900"><a href="#GradientBoostingSurvivalAnalysis-900"><span class="linenos"> 900</span></a><span class="sd">    max_features_ : int</span>
</span><span id="GradientBoostingSurvivalAnalysis-901"><a href="#GradientBoostingSurvivalAnalysis-901"><span class="linenos"> 901</span></a><span class="sd">        The inferred value of max_features.</span>
</span><span id="GradientBoostingSurvivalAnalysis-902"><a href="#GradientBoostingSurvivalAnalysis-902"><span class="linenos"> 902</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-903"><a href="#GradientBoostingSurvivalAnalysis-903"><span class="linenos"> 903</span></a><span class="sd">    unique_times_ : array of shape = (n_unique_times,)</span>
</span><span id="GradientBoostingSurvivalAnalysis-904"><a href="#GradientBoostingSurvivalAnalysis-904"><span class="linenos"> 904</span></a><span class="sd">        Unique time points.</span>
</span><span id="GradientBoostingSurvivalAnalysis-905"><a href="#GradientBoostingSurvivalAnalysis-905"><span class="linenos"> 905</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-906"><a href="#GradientBoostingSurvivalAnalysis-906"><span class="linenos"> 906</span></a><span class="sd">    See also</span>
</span><span id="GradientBoostingSurvivalAnalysis-907"><a href="#GradientBoostingSurvivalAnalysis-907"><span class="linenos"> 907</span></a><span class="sd">    --------</span>
</span><span id="GradientBoostingSurvivalAnalysis-908"><a href="#GradientBoostingSurvivalAnalysis-908"><span class="linenos"> 908</span></a><span class="sd">    survivalist.ensemble.ComponentwiseGradientBoostingSurvivalAnalysis</span>
</span><span id="GradientBoostingSurvivalAnalysis-909"><a href="#GradientBoostingSurvivalAnalysis-909"><span class="linenos"> 909</span></a><span class="sd">        Gradient boosting with component-wise least squares as base learner.</span>
</span><span id="GradientBoostingSurvivalAnalysis-910"><a href="#GradientBoostingSurvivalAnalysis-910"><span class="linenos"> 910</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-911"><a href="#GradientBoostingSurvivalAnalysis-911"><span class="linenos"> 911</span></a><span class="sd">    References</span>
</span><span id="GradientBoostingSurvivalAnalysis-912"><a href="#GradientBoostingSurvivalAnalysis-912"><span class="linenos"> 912</span></a><span class="sd">    ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis-913"><a href="#GradientBoostingSurvivalAnalysis-913"><span class="linenos"> 913</span></a><span class="sd">    .. [1] J. H. Friedman, &quot;Greedy function approximation: A gradient boosting machine,&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-914"><a href="#GradientBoostingSurvivalAnalysis-914"><span class="linenos"> 914</span></a><span class="sd">           The Annals of Statistics, 29(5), 11891232, 2001.</span>
</span><span id="GradientBoostingSurvivalAnalysis-915"><a href="#GradientBoostingSurvivalAnalysis-915"><span class="linenos"> 915</span></a><span class="sd">    .. [2] J. H. Friedman, &quot;Stochastic gradient boosting,&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-916"><a href="#GradientBoostingSurvivalAnalysis-916"><span class="linenos"> 916</span></a><span class="sd">           Computational Statistics &amp; Data Analysis, 38(4), 367378, 2002.</span>
</span><span id="GradientBoostingSurvivalAnalysis-917"><a href="#GradientBoostingSurvivalAnalysis-917"><span class="linenos"> 917</span></a><span class="sd">    .. [3] G. Ridgeway, &quot;The state of boosting,&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-918"><a href="#GradientBoostingSurvivalAnalysis-918"><span class="linenos"> 918</span></a><span class="sd">           Computing Science and Statistics, 172181, 1999.</span>
</span><span id="GradientBoostingSurvivalAnalysis-919"><a href="#GradientBoostingSurvivalAnalysis-919"><span class="linenos"> 919</span></a><span class="sd">    .. [4] Hothorn, T., Bhlmann, P., Dudoit, S., Molinaro, A., van der Laan, M. J.,</span>
</span><span id="GradientBoostingSurvivalAnalysis-920"><a href="#GradientBoostingSurvivalAnalysis-920"><span class="linenos"> 920</span></a><span class="sd">           &quot;Survival ensembles&quot;, Biostatistics, 7(3), 355-73, 2006.</span>
</span><span id="GradientBoostingSurvivalAnalysis-921"><a href="#GradientBoostingSurvivalAnalysis-921"><span class="linenos"> 921</span></a><span class="sd">    .. [5] K. V. Rashmi and R. Gilad-Bachrach,</span>
</span><span id="GradientBoostingSurvivalAnalysis-922"><a href="#GradientBoostingSurvivalAnalysis-922"><span class="linenos"> 922</span></a><span class="sd">           &quot;DART: Dropouts meet multiple additive regression trees,&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-923"><a href="#GradientBoostingSurvivalAnalysis-923"><span class="linenos"> 923</span></a><span class="sd">           in 18th International Conference on Artificial Intelligence and Statistics,</span>
</span><span id="GradientBoostingSurvivalAnalysis-924"><a href="#GradientBoostingSurvivalAnalysis-924"><span class="linenos"> 924</span></a><span class="sd">           2015, 489497.</span>
</span><span id="GradientBoostingSurvivalAnalysis-925"><a href="#GradientBoostingSurvivalAnalysis-925"><span class="linenos"> 925</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-926"><a href="#GradientBoostingSurvivalAnalysis-926"><span class="linenos"> 926</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-927"><a href="#GradientBoostingSurvivalAnalysis-927"><span class="linenos"> 927</span></a>    <span class="n">_parameter_constraints</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="GradientBoostingSurvivalAnalysis-928"><a href="#GradientBoostingSurvivalAnalysis-928"><span class="linenos"> 928</span></a>        <span class="o">**</span><span class="n">BaseGradientBoosting</span><span class="o">.</span><span class="n">_parameter_constraints</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-929"><a href="#GradientBoostingSurvivalAnalysis-929"><span class="linenos"> 929</span></a>        <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">LOSS_FUNCTIONS</span><span class="o">.</span><span class="n">keys</span><span class="p">()))],</span>
</span><span id="GradientBoostingSurvivalAnalysis-930"><a href="#GradientBoostingSurvivalAnalysis-930"><span class="linenos"> 930</span></a>        <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
</span><span id="GradientBoostingSurvivalAnalysis-931"><a href="#GradientBoostingSurvivalAnalysis-931"><span class="linenos"> 931</span></a>    <span class="p">}</span>
</span><span id="GradientBoostingSurvivalAnalysis-932"><a href="#GradientBoostingSurvivalAnalysis-932"><span class="linenos"> 932</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-933"><a href="#GradientBoostingSurvivalAnalysis-933"><span class="linenos"> 933</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-934"><a href="#GradientBoostingSurvivalAnalysis-934"><span class="linenos"> 934</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-935"><a href="#GradientBoostingSurvivalAnalysis-935"><span class="linenos"> 935</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-936"><a href="#GradientBoostingSurvivalAnalysis-936"><span class="linenos"> 936</span></a>        <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;coxph&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-937"><a href="#GradientBoostingSurvivalAnalysis-937"><span class="linenos"> 937</span></a>        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-938"><a href="#GradientBoostingSurvivalAnalysis-938"><span class="linenos"> 938</span></a>        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-939"><a href="#GradientBoostingSurvivalAnalysis-939"><span class="linenos"> 939</span></a>        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-940"><a href="#GradientBoostingSurvivalAnalysis-940"><span class="linenos"> 940</span></a>        <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;friedman_mse&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-941"><a href="#GradientBoostingSurvivalAnalysis-941"><span class="linenos"> 941</span></a>        <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-942"><a href="#GradientBoostingSurvivalAnalysis-942"><span class="linenos"> 942</span></a>        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-943"><a href="#GradientBoostingSurvivalAnalysis-943"><span class="linenos"> 943</span></a>        <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-944"><a href="#GradientBoostingSurvivalAnalysis-944"><span class="linenos"> 944</span></a>        <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-945"><a href="#GradientBoostingSurvivalAnalysis-945"><span class="linenos"> 945</span></a>        <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-946"><a href="#GradientBoostingSurvivalAnalysis-946"><span class="linenos"> 946</span></a>        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-947"><a href="#GradientBoostingSurvivalAnalysis-947"><span class="linenos"> 947</span></a>        <span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-948"><a href="#GradientBoostingSurvivalAnalysis-948"><span class="linenos"> 948</span></a>        <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-949"><a href="#GradientBoostingSurvivalAnalysis-949"><span class="linenos"> 949</span></a>        <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-950"><a href="#GradientBoostingSurvivalAnalysis-950"><span class="linenos"> 950</span></a>        <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-951"><a href="#GradientBoostingSurvivalAnalysis-951"><span class="linenos"> 951</span></a>        <span class="n">n_iter_no_change</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-952"><a href="#GradientBoostingSurvivalAnalysis-952"><span class="linenos"> 952</span></a>        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-953"><a href="#GradientBoostingSurvivalAnalysis-953"><span class="linenos"> 953</span></a>        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-954"><a href="#GradientBoostingSurvivalAnalysis-954"><span class="linenos"> 954</span></a>        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-955"><a href="#GradientBoostingSurvivalAnalysis-955"><span class="linenos"> 955</span></a>        <span class="n">ccp_alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-956"><a href="#GradientBoostingSurvivalAnalysis-956"><span class="linenos"> 956</span></a>    <span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-957"><a href="#GradientBoostingSurvivalAnalysis-957"><span class="linenos"> 957</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-958"><a href="#GradientBoostingSurvivalAnalysis-958"><span class="linenos"> 958</span></a>            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-959"><a href="#GradientBoostingSurvivalAnalysis-959"><span class="linenos"> 959</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-960"><a href="#GradientBoostingSurvivalAnalysis-960"><span class="linenos"> 960</span></a>            <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-961"><a href="#GradientBoostingSurvivalAnalysis-961"><span class="linenos"> 961</span></a>            <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-962"><a href="#GradientBoostingSurvivalAnalysis-962"><span class="linenos"> 962</span></a>            <span class="n">min_samples_split</span><span class="o">=</span><span class="n">min_samples_split</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-963"><a href="#GradientBoostingSurvivalAnalysis-963"><span class="linenos"> 963</span></a>            <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_samples_leaf</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-964"><a href="#GradientBoostingSurvivalAnalysis-964"><span class="linenos"> 964</span></a>            <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="n">min_weight_fraction_leaf</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-965"><a href="#GradientBoostingSurvivalAnalysis-965"><span class="linenos"> 965</span></a>            <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-966"><a href="#GradientBoostingSurvivalAnalysis-966"><span class="linenos"> 966</span></a>            <span class="n">init</span><span class="o">=</span><span class="s2">&quot;zero&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-967"><a href="#GradientBoostingSurvivalAnalysis-967"><span class="linenos"> 967</span></a>            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-968"><a href="#GradientBoostingSurvivalAnalysis-968"><span class="linenos"> 968</span></a>            <span class="n">max_features</span><span class="o">=</span><span class="n">max_features</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-969"><a href="#GradientBoostingSurvivalAnalysis-969"><span class="linenos"> 969</span></a>            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-970"><a href="#GradientBoostingSurvivalAnalysis-970"><span class="linenos"> 970</span></a>            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-971"><a href="#GradientBoostingSurvivalAnalysis-971"><span class="linenos"> 971</span></a>            <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-972"><a href="#GradientBoostingSurvivalAnalysis-972"><span class="linenos"> 972</span></a>            <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-973"><a href="#GradientBoostingSurvivalAnalysis-973"><span class="linenos"> 973</span></a>            <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="n">min_impurity_decrease</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-974"><a href="#GradientBoostingSurvivalAnalysis-974"><span class="linenos"> 974</span></a>            <span class="n">validation_fraction</span><span class="o">=</span><span class="n">validation_fraction</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-975"><a href="#GradientBoostingSurvivalAnalysis-975"><span class="linenos"> 975</span></a>            <span class="n">n_iter_no_change</span><span class="o">=</span><span class="n">n_iter_no_change</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-976"><a href="#GradientBoostingSurvivalAnalysis-976"><span class="linenos"> 976</span></a>            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-977"><a href="#GradientBoostingSurvivalAnalysis-977"><span class="linenos"> 977</span></a>            <span class="n">ccp_alpha</span><span class="o">=</span><span class="n">ccp_alpha</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-978"><a href="#GradientBoostingSurvivalAnalysis-978"><span class="linenos"> 978</span></a>        <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-979"><a href="#GradientBoostingSurvivalAnalysis-979"><span class="linenos"> 979</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>
</span><span id="GradientBoostingSurvivalAnalysis-980"><a href="#GradientBoostingSurvivalAnalysis-980"><span class="linenos"> 980</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-981"><a href="#GradientBoostingSurvivalAnalysis-981"><span class="linenos"> 981</span></a>    <span class="k">def</span> <span class="nf">_encode_y</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-982"><a href="#GradientBoostingSurvivalAnalysis-982"><span class="linenos"> 982</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="GradientBoostingSurvivalAnalysis-983"><a href="#GradientBoostingSurvivalAnalysis-983"><span class="linenos"> 983</span></a>        <span class="k">return</span> <span class="n">y</span>
</span><span id="GradientBoostingSurvivalAnalysis-984"><a href="#GradientBoostingSurvivalAnalysis-984"><span class="linenos"> 984</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-985"><a href="#GradientBoostingSurvivalAnalysis-985"><span class="linenos"> 985</span></a>    <span class="k">def</span> <span class="nf">_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-986"><a href="#GradientBoostingSurvivalAnalysis-986"><span class="linenos"> 986</span></a>        <span class="k">return</span> <span class="n">LOSS_FUNCTIONS</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">]()</span>
</span><span id="GradientBoostingSurvivalAnalysis-987"><a href="#GradientBoostingSurvivalAnalysis-987"><span class="linenos"> 987</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-988"><a href="#GradientBoostingSurvivalAnalysis-988"><span class="linenos"> 988</span></a>    <span class="nd">@property</span>
</span><span id="GradientBoostingSurvivalAnalysis-989"><a href="#GradientBoostingSurvivalAnalysis-989"><span class="linenos"> 989</span></a>    <span class="k">def</span> <span class="nf">_predict_risk_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-990"><a href="#GradientBoostingSurvivalAnalysis-990"><span class="linenos"> 990</span></a>        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="n">CoxPH</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-991"><a href="#GradientBoostingSurvivalAnalysis-991"><span class="linenos"> 991</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-992"><a href="#GradientBoostingSurvivalAnalysis-992"><span class="linenos"> 992</span></a>    <span class="k">def</span> <span class="nf">_set_max_features</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-993"><a href="#GradientBoostingSurvivalAnalysis-993"><span class="linenos"> 993</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Set self.max_features_.&quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-994"><a href="#GradientBoostingSurvivalAnalysis-994"><span class="linenos"> 994</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-995"><a href="#GradientBoostingSurvivalAnalysis-995"><span class="linenos"> 995</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_features</span> <span class="o">==</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-996"><a href="#GradientBoostingSurvivalAnalysis-996"><span class="linenos"> 996</span></a>                <span class="n">max_features</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">)))</span>
</span><span id="GradientBoostingSurvivalAnalysis-997"><a href="#GradientBoostingSurvivalAnalysis-997"><span class="linenos"> 997</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_features</span> <span class="o">==</span> <span class="s2">&quot;log2&quot;</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-998"><a href="#GradientBoostingSurvivalAnalysis-998"><span class="linenos"> 998</span></a>                <span class="n">max_features</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">)))</span>
</span><span id="GradientBoostingSurvivalAnalysis-999"><a href="#GradientBoostingSurvivalAnalysis-999"><span class="linenos"> 999</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1000"><a href="#GradientBoostingSurvivalAnalysis-1000"><span class="linenos">1000</span></a>            <span class="n">max_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span>
</span><span id="GradientBoostingSurvivalAnalysis-1001"><a href="#GradientBoostingSurvivalAnalysis-1001"><span class="linenos">1001</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span><span class="p">,</span> <span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1002"><a href="#GradientBoostingSurvivalAnalysis-1002"><span class="linenos">1002</span></a>            <span class="n">max_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_features</span>
</span><span id="GradientBoostingSurvivalAnalysis-1003"><a href="#GradientBoostingSurvivalAnalysis-1003"><span class="linenos">1003</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># float</span>
</span><span id="GradientBoostingSurvivalAnalysis-1004"><a href="#GradientBoostingSurvivalAnalysis-1004"><span class="linenos">1004</span></a>            <span class="n">max_features</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">))</span>
</span><span id="GradientBoostingSurvivalAnalysis-1005"><a href="#GradientBoostingSurvivalAnalysis-1005"><span class="linenos">1005</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1006"><a href="#GradientBoostingSurvivalAnalysis-1006"><span class="linenos">1006</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_features_</span> <span class="o">=</span> <span class="n">max_features</span>
</span><span id="GradientBoostingSurvivalAnalysis-1007"><a href="#GradientBoostingSurvivalAnalysis-1007"><span class="linenos">1007</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1008"><a href="#GradientBoostingSurvivalAnalysis-1008"><span class="linenos">1008</span></a>    <span class="k">def</span> <span class="nf">_update_with_dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1009"><a href="#GradientBoostingSurvivalAnalysis-1009"><span class="linenos">1009</span></a>        <span class="c1"># select base learners to be dropped for next iteration</span>
</span><span id="GradientBoostingSurvivalAnalysis-1010"><a href="#GradientBoostingSurvivalAnalysis-1010"><span class="linenos">1010</span></a>        <span class="n">drop_model</span><span class="p">,</span> <span class="n">n_dropped</span> <span class="o">=</span> <span class="n">_sample_binomial_plus_one</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1011"><a href="#GradientBoostingSurvivalAnalysis-1011"><span class="linenos">1011</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1012"><a href="#GradientBoostingSurvivalAnalysis-1012"><span class="linenos">1012</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1013"><a href="#GradientBoostingSurvivalAnalysis-1013"><span class="linenos">1013</span></a>        <span class="c1"># adjust scaling factor of tree that is going to be trained in next iteration</span>
</span><span id="GradientBoostingSurvivalAnalysis-1014"><a href="#GradientBoostingSurvivalAnalysis-1014"><span class="linenos">1014</span></a>        <span class="n">scale</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_dropped</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1015"><a href="#GradientBoostingSurvivalAnalysis-1015"><span class="linenos">1015</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1016"><a href="#GradientBoostingSurvivalAnalysis-1016"><span class="linenos">1016</span></a>        <span class="n">raw_predictions</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="GradientBoostingSurvivalAnalysis-1017"><a href="#GradientBoostingSurvivalAnalysis-1017"><span class="linenos">1017</span></a>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1018"><a href="#GradientBoostingSurvivalAnalysis-1018"><span class="linenos">1018</span></a>            <span class="k">if</span> <span class="n">drop_model</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1019"><a href="#GradientBoostingSurvivalAnalysis-1019"><span class="linenos">1019</span></a>                <span class="c1"># adjust scaling factor of dropped trees</span>
</span><span id="GradientBoostingSurvivalAnalysis-1020"><a href="#GradientBoostingSurvivalAnalysis-1020"><span class="linenos">1020</span></a>                <span class="n">scale</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">*=</span> <span class="n">n_dropped</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_dropped</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1021"><a href="#GradientBoostingSurvivalAnalysis-1021"><span class="linenos">1021</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1022"><a href="#GradientBoostingSurvivalAnalysis-1022"><span class="linenos">1022</span></a>                <span class="c1"># pseudoresponse of next iteration (without contribution of dropped trees)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1023"><a href="#GradientBoostingSurvivalAnalysis-1023"><span class="linenos">1023</span></a>                <span class="n">raw_predictions</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> \
</span><span id="GradientBoostingSurvivalAnalysis-1024"><a href="#GradientBoostingSurvivalAnalysis-1024"><span class="linenos">1024</span></a>                    <span class="n">scale</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1025"><a href="#GradientBoostingSurvivalAnalysis-1025"><span class="linenos">1025</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1026"><a href="#GradientBoostingSurvivalAnalysis-1026"><span class="linenos">1026</span></a>    <span class="k">def</span> <span class="nf">_fit_stage</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1027"><a href="#GradientBoostingSurvivalAnalysis-1027"><span class="linenos">1027</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1028"><a href="#GradientBoostingSurvivalAnalysis-1028"><span class="linenos">1028</span></a>        <span class="n">i</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1029"><a href="#GradientBoostingSurvivalAnalysis-1029"><span class="linenos">1029</span></a>        <span class="n">X</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1030"><a href="#GradientBoostingSurvivalAnalysis-1030"><span class="linenos">1030</span></a>        <span class="n">y</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1031"><a href="#GradientBoostingSurvivalAnalysis-1031"><span class="linenos">1031</span></a>        <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1032"><a href="#GradientBoostingSurvivalAnalysis-1032"><span class="linenos">1032</span></a>        <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1033"><a href="#GradientBoostingSurvivalAnalysis-1033"><span class="linenos">1033</span></a>        <span class="n">sample_mask</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1034"><a href="#GradientBoostingSurvivalAnalysis-1034"><span class="linenos">1034</span></a>        <span class="n">random_state</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1035"><a href="#GradientBoostingSurvivalAnalysis-1035"><span class="linenos">1035</span></a>        <span class="n">scale</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1036"><a href="#GradientBoostingSurvivalAnalysis-1036"><span class="linenos">1036</span></a>        <span class="n">X_csc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1037"><a href="#GradientBoostingSurvivalAnalysis-1037"><span class="linenos">1037</span></a>        <span class="n">X_csr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1038"><a href="#GradientBoostingSurvivalAnalysis-1038"><span class="linenos">1038</span></a>    <span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1039"><a href="#GradientBoostingSurvivalAnalysis-1039"><span class="linenos">1039</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit another stage of ``n_classes_`` trees to the boosting model.&quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1040"><a href="#GradientBoostingSurvivalAnalysis-1040"><span class="linenos">1040</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1041"><a href="#GradientBoostingSurvivalAnalysis-1041"><span class="linenos">1041</span></a>        <span class="k">assert</span> <span class="n">sample_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">bool</span>
</span><span id="GradientBoostingSurvivalAnalysis-1042"><a href="#GradientBoostingSurvivalAnalysis-1042"><span class="linenos">1042</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1043"><a href="#GradientBoostingSurvivalAnalysis-1043"><span class="linenos">1043</span></a>        <span class="c1"># whether to use dropout in next iteration</span>
</span><span id="GradientBoostingSurvivalAnalysis-1044"><a href="#GradientBoostingSurvivalAnalysis-1044"><span class="linenos">1044</span></a>        <span class="n">do_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="GradientBoostingSurvivalAnalysis-1045"><a href="#GradientBoostingSurvivalAnalysis-1045"><span class="linenos">1045</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1046"><a href="#GradientBoostingSurvivalAnalysis-1046"><span class="linenos">1046</span></a>        <span class="c1"># Need to pass a copy of raw_predictions to negative_gradient()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1047"><a href="#GradientBoostingSurvivalAnalysis-1047"><span class="linenos">1047</span></a>        <span class="c1"># because raw_predictions is partially updated at the end of the loop</span>
</span><span id="GradientBoostingSurvivalAnalysis-1048"><a href="#GradientBoostingSurvivalAnalysis-1048"><span class="linenos">1048</span></a>        <span class="c1"># in update_terminal_regions(), and gradients need to be evaluated at</span>
</span><span id="GradientBoostingSurvivalAnalysis-1049"><a href="#GradientBoostingSurvivalAnalysis-1049"><span class="linenos">1049</span></a>        <span class="c1"># iteration i - 1.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1050"><a href="#GradientBoostingSurvivalAnalysis-1050"><span class="linenos">1050</span></a>        <span class="n">raw_predictions_copy</span> <span class="o">=</span> <span class="n">raw_predictions</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1051"><a href="#GradientBoostingSurvivalAnalysis-1051"><span class="linenos">1051</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1052"><a href="#GradientBoostingSurvivalAnalysis-1052"><span class="linenos">1052</span></a>        <span class="n">neg_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1053"><a href="#GradientBoostingSurvivalAnalysis-1053"><span class="linenos">1053</span></a>            <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1054"><a href="#GradientBoostingSurvivalAnalysis-1054"><span class="linenos">1054</span></a>            <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions_copy</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1055"><a href="#GradientBoostingSurvivalAnalysis-1055"><span class="linenos">1055</span></a>            <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># We pass sample_weights to the tree directly.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1056"><a href="#GradientBoostingSurvivalAnalysis-1056"><span class="linenos">1056</span></a>        <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1057"><a href="#GradientBoostingSurvivalAnalysis-1057"><span class="linenos">1057</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1058"><a href="#GradientBoostingSurvivalAnalysis-1058"><span class="linenos">1058</span></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1059"><a href="#GradientBoostingSurvivalAnalysis-1059"><span class="linenos">1059</span></a>            <span class="c1"># induce regression tree on the negative gradient</span>
</span><span id="GradientBoostingSurvivalAnalysis-1060"><a href="#GradientBoostingSurvivalAnalysis-1060"><span class="linenos">1060</span></a>            <span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1061"><a href="#GradientBoostingSurvivalAnalysis-1061"><span class="linenos">1061</span></a>                <span class="n">criterion</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1062"><a href="#GradientBoostingSurvivalAnalysis-1062"><span class="linenos">1062</span></a>                <span class="n">splitter</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1063"><a href="#GradientBoostingSurvivalAnalysis-1063"><span class="linenos">1063</span></a>                <span class="n">max_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1064"><a href="#GradientBoostingSurvivalAnalysis-1064"><span class="linenos">1064</span></a>                <span class="n">min_samples_split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_samples_split</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1065"><a href="#GradientBoostingSurvivalAnalysis-1065"><span class="linenos">1065</span></a>                <span class="n">min_samples_leaf</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_samples_leaf</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1066"><a href="#GradientBoostingSurvivalAnalysis-1066"><span class="linenos">1066</span></a>                <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_weight_fraction_leaf</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1067"><a href="#GradientBoostingSurvivalAnalysis-1067"><span class="linenos">1067</span></a>                <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_impurity_decrease</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1068"><a href="#GradientBoostingSurvivalAnalysis-1068"><span class="linenos">1068</span></a>                <span class="n">max_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1069"><a href="#GradientBoostingSurvivalAnalysis-1069"><span class="linenos">1069</span></a>                <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_leaf_nodes</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1070"><a href="#GradientBoostingSurvivalAnalysis-1070"><span class="linenos">1070</span></a>                <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1071"><a href="#GradientBoostingSurvivalAnalysis-1071"><span class="linenos">1071</span></a>                <span class="n">ccp_alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ccp_alpha</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1072"><a href="#GradientBoostingSurvivalAnalysis-1072"><span class="linenos">1072</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1073"><a href="#GradientBoostingSurvivalAnalysis-1073"><span class="linenos">1073</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1074"><a href="#GradientBoostingSurvivalAnalysis-1074"><span class="linenos">1074</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1075"><a href="#GradientBoostingSurvivalAnalysis-1075"><span class="linenos">1075</span></a>                <span class="c1"># no inplace multiplication!</span>
</span><span id="GradientBoostingSurvivalAnalysis-1076"><a href="#GradientBoostingSurvivalAnalysis-1076"><span class="linenos">1076</span></a>                <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="o">*</span> <span class="n">sample_mask</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1077"><a href="#GradientBoostingSurvivalAnalysis-1077"><span class="linenos">1077</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1078"><a href="#GradientBoostingSurvivalAnalysis-1078"><span class="linenos">1078</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X_csc</span> <span class="k">if</span> <span class="n">X_csc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>
</span><span id="GradientBoostingSurvivalAnalysis-1079"><a href="#GradientBoostingSurvivalAnalysis-1079"><span class="linenos">1079</span></a>            <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">neg_gradient</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1080"><a href="#GradientBoostingSurvivalAnalysis-1080"><span class="linenos">1080</span></a>                     <span class="n">check_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1081"><a href="#GradientBoostingSurvivalAnalysis-1081"><span class="linenos">1081</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1082"><a href="#GradientBoostingSurvivalAnalysis-1082"><span class="linenos">1082</span></a>            <span class="c1"># add tree to ensemble</span>
</span><span id="GradientBoostingSurvivalAnalysis-1083"><a href="#GradientBoostingSurvivalAnalysis-1083"><span class="linenos">1083</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tree</span>
</span><span id="GradientBoostingSurvivalAnalysis-1084"><a href="#GradientBoostingSurvivalAnalysis-1084"><span class="linenos">1084</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1085"><a href="#GradientBoostingSurvivalAnalysis-1085"><span class="linenos">1085</span></a>            <span class="c1"># update tree leaves</span>
</span><span id="GradientBoostingSurvivalAnalysis-1086"><a href="#GradientBoostingSurvivalAnalysis-1086"><span class="linenos">1086</span></a>            <span class="k">if</span> <span class="n">do_dropout</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1087"><a href="#GradientBoostingSurvivalAnalysis-1087"><span class="linenos">1087</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1088"><a href="#GradientBoostingSurvivalAnalysis-1088"><span class="linenos">1088</span></a>                    <span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1089"><a href="#GradientBoostingSurvivalAnalysis-1089"><span class="linenos">1089</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1090"><a href="#GradientBoostingSurvivalAnalysis-1090"><span class="linenos">1090</span></a>                <span class="c1"># update tree leaves</span>
</span><span id="GradientBoostingSurvivalAnalysis-1091"><a href="#GradientBoostingSurvivalAnalysis-1091"><span class="linenos">1091</span></a>                <span class="n">X_for_tree_update</span> <span class="o">=</span> <span class="n">X_csr</span> <span class="k">if</span> <span class="n">X_csr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>
</span><span id="GradientBoostingSurvivalAnalysis-1092"><a href="#GradientBoostingSurvivalAnalysis-1092"><span class="linenos">1092</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">update_terminal_regions</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1093"><a href="#GradientBoostingSurvivalAnalysis-1093"><span class="linenos">1093</span></a>                    <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1094"><a href="#GradientBoostingSurvivalAnalysis-1094"><span class="linenos">1094</span></a>                    <span class="n">X_for_tree_update</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1095"><a href="#GradientBoostingSurvivalAnalysis-1095"><span class="linenos">1095</span></a>                    <span class="n">y</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1096"><a href="#GradientBoostingSurvivalAnalysis-1096"><span class="linenos">1096</span></a>                    <span class="n">neg_gradient</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1097"><a href="#GradientBoostingSurvivalAnalysis-1097"><span class="linenos">1097</span></a>                    <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1098"><a href="#GradientBoostingSurvivalAnalysis-1098"><span class="linenos">1098</span></a>                    <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1099"><a href="#GradientBoostingSurvivalAnalysis-1099"><span class="linenos">1099</span></a>                    <span class="n">sample_mask</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1100"><a href="#GradientBoostingSurvivalAnalysis-1100"><span class="linenos">1100</span></a>                    <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1101"><a href="#GradientBoostingSurvivalAnalysis-1101"><span class="linenos">1101</span></a>                    <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1102"><a href="#GradientBoostingSurvivalAnalysis-1102"><span class="linenos">1102</span></a>                <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1103"><a href="#GradientBoostingSurvivalAnalysis-1103"><span class="linenos">1103</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1104"><a href="#GradientBoostingSurvivalAnalysis-1104"><span class="linenos">1104</span></a>        <span class="k">return</span> <span class="n">raw_predictions</span>
</span><span id="GradientBoostingSurvivalAnalysis-1105"><a href="#GradientBoostingSurvivalAnalysis-1105"><span class="linenos">1105</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1106"><a href="#GradientBoostingSurvivalAnalysis-1106"><span class="linenos">1106</span></a>    <span class="k">def</span> <span class="nf">_fit_stages</span><span class="p">(</span>  <span class="c1"># noqa: C901</span>
</span><span id="GradientBoostingSurvivalAnalysis-1107"><a href="#GradientBoostingSurvivalAnalysis-1107"><span class="linenos">1107</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1108"><a href="#GradientBoostingSurvivalAnalysis-1108"><span class="linenos">1108</span></a>        <span class="n">X</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1109"><a href="#GradientBoostingSurvivalAnalysis-1109"><span class="linenos">1109</span></a>        <span class="n">y</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1110"><a href="#GradientBoostingSurvivalAnalysis-1110"><span class="linenos">1110</span></a>        <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1111"><a href="#GradientBoostingSurvivalAnalysis-1111"><span class="linenos">1111</span></a>        <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1112"><a href="#GradientBoostingSurvivalAnalysis-1112"><span class="linenos">1112</span></a>        <span class="n">random_state</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1113"><a href="#GradientBoostingSurvivalAnalysis-1113"><span class="linenos">1113</span></a>        <span class="n">X_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1114"><a href="#GradientBoostingSurvivalAnalysis-1114"><span class="linenos">1114</span></a>        <span class="n">y_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1115"><a href="#GradientBoostingSurvivalAnalysis-1115"><span class="linenos">1115</span></a>        <span class="n">sample_weight_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1116"><a href="#GradientBoostingSurvivalAnalysis-1116"><span class="linenos">1116</span></a>        <span class="n">scale</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1117"><a href="#GradientBoostingSurvivalAnalysis-1117"><span class="linenos">1117</span></a>        <span class="n">begin_at_stage</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1118"><a href="#GradientBoostingSurvivalAnalysis-1118"><span class="linenos">1118</span></a>        <span class="n">monitor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1119"><a href="#GradientBoostingSurvivalAnalysis-1119"><span class="linenos">1119</span></a>    <span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1120"><a href="#GradientBoostingSurvivalAnalysis-1120"><span class="linenos">1120</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Iteratively fits the stages.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1121"><a href="#GradientBoostingSurvivalAnalysis-1121"><span class="linenos">1121</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1122"><a href="#GradientBoostingSurvivalAnalysis-1122"><span class="linenos">1122</span></a><span class="sd">        For each stage it computes the progress (OOB, train score)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1123"><a href="#GradientBoostingSurvivalAnalysis-1123"><span class="linenos">1123</span></a><span class="sd">        and delegates to ``_fit_stage``.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1124"><a href="#GradientBoostingSurvivalAnalysis-1124"><span class="linenos">1124</span></a><span class="sd">        Returns the number of stages fit; might differ from ``n_estimators``</span>
</span><span id="GradientBoostingSurvivalAnalysis-1125"><a href="#GradientBoostingSurvivalAnalysis-1125"><span class="linenos">1125</span></a><span class="sd">        due to early stopping.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1126"><a href="#GradientBoostingSurvivalAnalysis-1126"><span class="linenos">1126</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1127"><a href="#GradientBoostingSurvivalAnalysis-1127"><span class="linenos">1127</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1128"><a href="#GradientBoostingSurvivalAnalysis-1128"><span class="linenos">1128</span></a>        <span class="n">do_oob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">&lt;</span> <span class="mf">1.0</span>
</span><span id="GradientBoostingSurvivalAnalysis-1129"><a href="#GradientBoostingSurvivalAnalysis-1129"><span class="linenos">1129</span></a>        <span class="n">sample_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1130"><a href="#GradientBoostingSurvivalAnalysis-1130"><span class="linenos">1130</span></a>        <span class="n">n_inbag</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">subsample</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">))</span>
</span><span id="GradientBoostingSurvivalAnalysis-1131"><a href="#GradientBoostingSurvivalAnalysis-1131"><span class="linenos">1131</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1132"><a href="#GradientBoostingSurvivalAnalysis-1132"><span class="linenos">1132</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1133"><a href="#GradientBoostingSurvivalAnalysis-1133"><span class="linenos">1133</span></a>            <span class="n">verbose_reporter</span> <span class="o">=</span> <span class="n">VerboseReporter</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1134"><a href="#GradientBoostingSurvivalAnalysis-1134"><span class="linenos">1134</span></a>            <span class="n">verbose_reporter</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">begin_at_stage</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1135"><a href="#GradientBoostingSurvivalAnalysis-1135"><span class="linenos">1135</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1136"><a href="#GradientBoostingSurvivalAnalysis-1136"><span class="linenos">1136</span></a>        <span class="n">X_csc</span> <span class="o">=</span> <span class="n">csc_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="GradientBoostingSurvivalAnalysis-1137"><a href="#GradientBoostingSurvivalAnalysis-1137"><span class="linenos">1137</span></a>        <span class="n">X_csr</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="GradientBoostingSurvivalAnalysis-1138"><a href="#GradientBoostingSurvivalAnalysis-1138"><span class="linenos">1138</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1139"><a href="#GradientBoostingSurvivalAnalysis-1139"><span class="linenos">1139</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1140"><a href="#GradientBoostingSurvivalAnalysis-1140"><span class="linenos">1140</span></a>            <span class="n">loss_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1141"><a href="#GradientBoostingSurvivalAnalysis-1141"><span class="linenos">1141</span></a>            <span class="c1"># We create a generator to get the predictions for X_val after</span>
</span><span id="GradientBoostingSurvivalAnalysis-1142"><a href="#GradientBoostingSurvivalAnalysis-1142"><span class="linenos">1142</span></a>            <span class="c1"># the addition of each successive stage</span>
</span><span id="GradientBoostingSurvivalAnalysis-1143"><a href="#GradientBoostingSurvivalAnalysis-1143"><span class="linenos">1143</span></a>            <span class="n">y_val_pred_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_staged_raw_predict</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1144"><a href="#GradientBoostingSurvivalAnalysis-1144"><span class="linenos">1144</span></a>                <span class="n">X_val</span><span class="p">,</span> <span class="n">check_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1145"><a href="#GradientBoostingSurvivalAnalysis-1145"><span class="linenos">1145</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1146"><a href="#GradientBoostingSurvivalAnalysis-1146"><span class="linenos">1146</span></a>        <span class="c1"># perform boosting iterations</span>
</span><span id="GradientBoostingSurvivalAnalysis-1147"><a href="#GradientBoostingSurvivalAnalysis-1147"><span class="linenos">1147</span></a>        <span class="n">i</span> <span class="o">=</span> <span class="n">begin_at_stage</span>
</span><span id="GradientBoostingSurvivalAnalysis-1148"><a href="#GradientBoostingSurvivalAnalysis-1148"><span class="linenos">1148</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">begin_at_stage</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1149"><a href="#GradientBoostingSurvivalAnalysis-1149"><span class="linenos">1149</span></a>            <span class="c1"># subsampling</span>
</span><span id="GradientBoostingSurvivalAnalysis-1150"><a href="#GradientBoostingSurvivalAnalysis-1150"><span class="linenos">1150</span></a>            <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1151"><a href="#GradientBoostingSurvivalAnalysis-1151"><span class="linenos">1151</span></a>                <span class="n">sample_mask</span> <span class="o">=</span> <span class="n">_random_sample_mask</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1152"><a href="#GradientBoostingSurvivalAnalysis-1152"><span class="linenos">1152</span></a>                    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_inbag</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1153"><a href="#GradientBoostingSurvivalAnalysis-1153"><span class="linenos">1153</span></a>                <span class="c1"># OOB score before adding this stage</span>
</span><span id="GradientBoostingSurvivalAnalysis-1154"><a href="#GradientBoostingSurvivalAnalysis-1154"><span class="linenos">1154</span></a>                <span class="n">y_oob_masked</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1155"><a href="#GradientBoostingSurvivalAnalysis-1155"><span class="linenos">1155</span></a>                <span class="n">sample_weight_oob_masked</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1156"><a href="#GradientBoostingSurvivalAnalysis-1156"><span class="linenos">1156</span></a>                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># store the initial loss to compute the OOB score</span>
</span><span id="GradientBoostingSurvivalAnalysis-1157"><a href="#GradientBoostingSurvivalAnalysis-1157"><span class="linenos">1157</span></a>                    <span class="n">initial_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1158"><a href="#GradientBoostingSurvivalAnalysis-1158"><span class="linenos">1158</span></a>                        <span class="n">y_true</span><span class="o">=</span><span class="n">y_oob_masked</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1159"><a href="#GradientBoostingSurvivalAnalysis-1159"><span class="linenos">1159</span></a>                        <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="GradientBoostingSurvivalAnalysis-1160"><a href="#GradientBoostingSurvivalAnalysis-1160"><span class="linenos">1160</span></a>                        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight_oob_masked</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1161"><a href="#GradientBoostingSurvivalAnalysis-1161"><span class="linenos">1161</span></a>                    <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1162"><a href="#GradientBoostingSurvivalAnalysis-1162"><span class="linenos">1162</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1163"><a href="#GradientBoostingSurvivalAnalysis-1163"><span class="linenos">1163</span></a>            <span class="c1"># fit next stage of trees</span>
</span><span id="GradientBoostingSurvivalAnalysis-1164"><a href="#GradientBoostingSurvivalAnalysis-1164"><span class="linenos">1164</span></a>            <span class="n">raw_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_stage</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1165"><a href="#GradientBoostingSurvivalAnalysis-1165"><span class="linenos">1165</span></a>                <span class="n">i</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1166"><a href="#GradientBoostingSurvivalAnalysis-1166"><span class="linenos">1166</span></a>                <span class="n">X</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1167"><a href="#GradientBoostingSurvivalAnalysis-1167"><span class="linenos">1167</span></a>                <span class="n">y</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1168"><a href="#GradientBoostingSurvivalAnalysis-1168"><span class="linenos">1168</span></a>                <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1169"><a href="#GradientBoostingSurvivalAnalysis-1169"><span class="linenos">1169</span></a>                <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1170"><a href="#GradientBoostingSurvivalAnalysis-1170"><span class="linenos">1170</span></a>                <span class="n">sample_mask</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1171"><a href="#GradientBoostingSurvivalAnalysis-1171"><span class="linenos">1171</span></a>                <span class="n">random_state</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1172"><a href="#GradientBoostingSurvivalAnalysis-1172"><span class="linenos">1172</span></a>                <span class="n">scale</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1173"><a href="#GradientBoostingSurvivalAnalysis-1173"><span class="linenos">1173</span></a>                <span class="n">X_csc</span><span class="o">=</span><span class="n">X_csc</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1174"><a href="#GradientBoostingSurvivalAnalysis-1174"><span class="linenos">1174</span></a>                <span class="n">X_csr</span><span class="o">=</span><span class="n">X_csr</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1175"><a href="#GradientBoostingSurvivalAnalysis-1175"><span class="linenos">1175</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1176"><a href="#GradientBoostingSurvivalAnalysis-1176"><span class="linenos">1176</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1177"><a href="#GradientBoostingSurvivalAnalysis-1177"><span class="linenos">1177</span></a>            <span class="c1"># track loss</span>
</span><span id="GradientBoostingSurvivalAnalysis-1178"><a href="#GradientBoostingSurvivalAnalysis-1178"><span class="linenos">1178</span></a>            <span class="k">if</span> <span class="n">do_oob</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1179"><a href="#GradientBoostingSurvivalAnalysis-1179"><span class="linenos">1179</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1180"><a href="#GradientBoostingSurvivalAnalysis-1180"><span class="linenos">1180</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="GradientBoostingSurvivalAnalysis-1181"><a href="#GradientBoostingSurvivalAnalysis-1181"><span class="linenos">1181</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="GradientBoostingSurvivalAnalysis-1182"><a href="#GradientBoostingSurvivalAnalysis-1182"><span class="linenos">1182</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">[</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="GradientBoostingSurvivalAnalysis-1183"><a href="#GradientBoostingSurvivalAnalysis-1183"><span class="linenos">1183</span></a>                <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1184"><a href="#GradientBoostingSurvivalAnalysis-1184"><span class="linenos">1184</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1185"><a href="#GradientBoostingSurvivalAnalysis-1185"><span class="linenos">1185</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y_oob_masked</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1186"><a href="#GradientBoostingSurvivalAnalysis-1186"><span class="linenos">1186</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions</span><span class="p">[</span><span class="o">~</span><span class="n">sample_mask</span><span class="p">],</span>
</span><span id="GradientBoostingSurvivalAnalysis-1187"><a href="#GradientBoostingSurvivalAnalysis-1187"><span class="linenos">1187</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight_oob_masked</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1188"><a href="#GradientBoostingSurvivalAnalysis-1188"><span class="linenos">1188</span></a>                <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1189"><a href="#GradientBoostingSurvivalAnalysis-1189"><span class="linenos">1189</span></a>                <span class="n">previous_loss</span> <span class="o">=</span> <span class="n">initial_loss</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span>
</span><span id="GradientBoostingSurvivalAnalysis-1190"><a href="#GradientBoostingSurvivalAnalysis-1190"><span class="linenos">1190</span></a>                    <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1191"><a href="#GradientBoostingSurvivalAnalysis-1191"><span class="linenos">1191</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">previous_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1192"><a href="#GradientBoostingSurvivalAnalysis-1192"><span class="linenos">1192</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1193"><a href="#GradientBoostingSurvivalAnalysis-1193"><span class="linenos">1193</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1194"><a href="#GradientBoostingSurvivalAnalysis-1194"><span class="linenos">1194</span></a>                <span class="c1"># no need to fancy index w/ no subsampling</span>
</span><span id="GradientBoostingSurvivalAnalysis-1195"><a href="#GradientBoostingSurvivalAnalysis-1195"><span class="linenos">1195</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1196"><a href="#GradientBoostingSurvivalAnalysis-1196"><span class="linenos">1196</span></a>                    <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1197"><a href="#GradientBoostingSurvivalAnalysis-1197"><span class="linenos">1197</span></a>                    <span class="n">raw_prediction</span><span class="o">=</span><span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1198"><a href="#GradientBoostingSurvivalAnalysis-1198"><span class="linenos">1198</span></a>                    <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1199"><a href="#GradientBoostingSurvivalAnalysis-1199"><span class="linenos">1199</span></a>                <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1200"><a href="#GradientBoostingSurvivalAnalysis-1200"><span class="linenos">1200</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1201"><a href="#GradientBoostingSurvivalAnalysis-1201"><span class="linenos">1201</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1202"><a href="#GradientBoostingSurvivalAnalysis-1202"><span class="linenos">1202</span></a>                <span class="n">verbose_reporter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1203"><a href="#GradientBoostingSurvivalAnalysis-1203"><span class="linenos">1203</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1204"><a href="#GradientBoostingSurvivalAnalysis-1204"><span class="linenos">1204</span></a>            <span class="k">if</span> <span class="n">monitor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1205"><a href="#GradientBoostingSurvivalAnalysis-1205"><span class="linenos">1205</span></a>                <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">monitor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span>
</span><span id="GradientBoostingSurvivalAnalysis-1206"><a href="#GradientBoostingSurvivalAnalysis-1206"><span class="linenos">1206</span></a>                <span class="k">if</span> <span class="n">early_stopping</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1207"><a href="#GradientBoostingSurvivalAnalysis-1207"><span class="linenos">1207</span></a>                    <span class="k">break</span>
</span><span id="GradientBoostingSurvivalAnalysis-1208"><a href="#GradientBoostingSurvivalAnalysis-1208"><span class="linenos">1208</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1209"><a href="#GradientBoostingSurvivalAnalysis-1209"><span class="linenos">1209</span></a>            <span class="c1"># We also provide an early stopping based on the score from</span>
</span><span id="GradientBoostingSurvivalAnalysis-1210"><a href="#GradientBoostingSurvivalAnalysis-1210"><span class="linenos">1210</span></a>            <span class="c1"># validation set (X_val, y_val), if n_iter_no_change is set</span>
</span><span id="GradientBoostingSurvivalAnalysis-1211"><a href="#GradientBoostingSurvivalAnalysis-1211"><span class="linenos">1211</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1212"><a href="#GradientBoostingSurvivalAnalysis-1212"><span class="linenos">1212</span></a>                <span class="c1"># By calling next(y_val_pred_iter), we get the predictions</span>
</span><span id="GradientBoostingSurvivalAnalysis-1213"><a href="#GradientBoostingSurvivalAnalysis-1213"><span class="linenos">1213</span></a>                <span class="c1"># for X_val after the addition of the current stage</span>
</span><span id="GradientBoostingSurvivalAnalysis-1214"><a href="#GradientBoostingSurvivalAnalysis-1214"><span class="linenos">1214</span></a>                <span class="n">validation_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1215"><a href="#GradientBoostingSurvivalAnalysis-1215"><span class="linenos">1215</span></a>                    <span class="n">y_val_pred_iter</span><span class="p">),</span> <span class="n">sample_weight_val</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1216"><a href="#GradientBoostingSurvivalAnalysis-1216"><span class="linenos">1216</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1217"><a href="#GradientBoostingSurvivalAnalysis-1217"><span class="linenos">1217</span></a>                <span class="c1"># Require validation_score to be better (less) than at least</span>
</span><span id="GradientBoostingSurvivalAnalysis-1218"><a href="#GradientBoostingSurvivalAnalysis-1218"><span class="linenos">1218</span></a>                <span class="c1"># one of the last n_iter_no_change evaluations</span>
</span><span id="GradientBoostingSurvivalAnalysis-1219"><a href="#GradientBoostingSurvivalAnalysis-1219"><span class="linenos">1219</span></a>                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">validation_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">&lt;</span> <span class="n">loss_history</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1220"><a href="#GradientBoostingSurvivalAnalysis-1220"><span class="linenos">1220</span></a>                    <span class="n">loss_history</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_history</span><span class="p">)]</span> <span class="o">=</span> <span class="n">validation_loss</span>
</span><span id="GradientBoostingSurvivalAnalysis-1221"><a href="#GradientBoostingSurvivalAnalysis-1221"><span class="linenos">1221</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1222"><a href="#GradientBoostingSurvivalAnalysis-1222"><span class="linenos">1222</span></a>                    <span class="k">break</span>
</span><span id="GradientBoostingSurvivalAnalysis-1223"><a href="#GradientBoostingSurvivalAnalysis-1223"><span class="linenos">1223</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1224"><a href="#GradientBoostingSurvivalAnalysis-1224"><span class="linenos">1224</span></a>        <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="GradientBoostingSurvivalAnalysis-1225"><a href="#GradientBoostingSurvivalAnalysis-1225"><span class="linenos">1225</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1226"><a href="#GradientBoostingSurvivalAnalysis-1226"><span class="linenos">1226</span></a>    <span class="k">def</span> <span class="nf">_init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1227"><a href="#GradientBoostingSurvivalAnalysis-1227"><span class="linenos">1227</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_init_state</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1228"><a href="#GradientBoostingSurvivalAnalysis-1228"><span class="linenos">1228</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1229"><a href="#GradientBoostingSurvivalAnalysis-1229"><span class="linenos">1229</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1230"><a href="#GradientBoostingSurvivalAnalysis-1230"><span class="linenos">1230</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1231"><a href="#GradientBoostingSurvivalAnalysis-1231"><span class="linenos">1231</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1232"><a href="#GradientBoostingSurvivalAnalysis-1232"><span class="linenos">1232</span></a>    <span class="k">def</span> <span class="nf">_resize_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1233"><a href="#GradientBoostingSurvivalAnalysis-1233"><span class="linenos">1233</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_resize_state</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1234"><a href="#GradientBoostingSurvivalAnalysis-1234"><span class="linenos">1234</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1235"><a href="#GradientBoostingSurvivalAnalysis-1235"><span class="linenos">1235</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1236"><a href="#GradientBoostingSurvivalAnalysis-1236"><span class="linenos">1236</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1237"><a href="#GradientBoostingSurvivalAnalysis-1237"><span class="linenos">1237</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1238"><a href="#GradientBoostingSurvivalAnalysis-1238"><span class="linenos">1238</span></a>                    <span class="s2">&quot;fitting with warm_start=True and dropout_rate &gt; 0 is only &quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1239"><a href="#GradientBoostingSurvivalAnalysis-1239"><span class="linenos">1239</span></a>                    <span class="s2">&quot;supported if the previous fit used dropout_rate &gt; 0 too&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1240"><a href="#GradientBoostingSurvivalAnalysis-1240"><span class="linenos">1240</span></a>                <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1241"><a href="#GradientBoostingSurvivalAnalysis-1241"><span class="linenos">1241</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1242"><a href="#GradientBoostingSurvivalAnalysis-1242"><span class="linenos">1242</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1243"><a href="#GradientBoostingSurvivalAnalysis-1243"><span class="linenos">1243</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="GradientBoostingSurvivalAnalysis-1244"><a href="#GradientBoostingSurvivalAnalysis-1244"><span class="linenos">1244</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1245"><a href="#GradientBoostingSurvivalAnalysis-1245"><span class="linenos">1245</span></a>    <span class="k">def</span> <span class="nf">_shrink_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_stages</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1246"><a href="#GradientBoostingSurvivalAnalysis-1246"><span class="linenos">1246</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1247"><a href="#GradientBoostingSurvivalAnalysis-1247"><span class="linenos">1247</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score_</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1248"><a href="#GradientBoostingSurvivalAnalysis-1248"><span class="linenos">1248</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;oob_improvement_&quot;</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1249"><a href="#GradientBoostingSurvivalAnalysis-1249"><span class="linenos">1249</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_improvement_</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1250"><a href="#GradientBoostingSurvivalAnalysis-1250"><span class="linenos">1250</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1251"><a href="#GradientBoostingSurvivalAnalysis-1251"><span class="linenos">1251</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">oob_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oob_scores_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1252"><a href="#GradientBoostingSurvivalAnalysis-1252"><span class="linenos">1252</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1253"><a href="#GradientBoostingSurvivalAnalysis-1253"><span class="linenos">1253</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">[:</span><span class="n">n_stages</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1254"><a href="#GradientBoostingSurvivalAnalysis-1254"><span class="linenos">1254</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1255"><a href="#GradientBoostingSurvivalAnalysis-1255"><span class="linenos">1255</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1256"><a href="#GradientBoostingSurvivalAnalysis-1256"><span class="linenos">1256</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit the gradient boosting model.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1257"><a href="#GradientBoostingSurvivalAnalysis-1257"><span class="linenos">1257</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1258"><a href="#GradientBoostingSurvivalAnalysis-1258"><span class="linenos">1258</span></a><span class="sd">        Parameters</span>
</span><span id="GradientBoostingSurvivalAnalysis-1259"><a href="#GradientBoostingSurvivalAnalysis-1259"><span class="linenos">1259</span></a><span class="sd">        ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1260"><a href="#GradientBoostingSurvivalAnalysis-1260"><span class="linenos">1260</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1261"><a href="#GradientBoostingSurvivalAnalysis-1261"><span class="linenos">1261</span></a><span class="sd">            Data matrix</span>
</span><span id="GradientBoostingSurvivalAnalysis-1262"><a href="#GradientBoostingSurvivalAnalysis-1262"><span class="linenos">1262</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1263"><a href="#GradientBoostingSurvivalAnalysis-1263"><span class="linenos">1263</span></a><span class="sd">        y : structured array, shape = (n_samples,)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1264"><a href="#GradientBoostingSurvivalAnalysis-1264"><span class="linenos">1264</span></a><span class="sd">            A structured array containing the binary event indicator</span>
</span><span id="GradientBoostingSurvivalAnalysis-1265"><a href="#GradientBoostingSurvivalAnalysis-1265"><span class="linenos">1265</span></a><span class="sd">            as first field, and time of event or time of censoring as</span>
</span><span id="GradientBoostingSurvivalAnalysis-1266"><a href="#GradientBoostingSurvivalAnalysis-1266"><span class="linenos">1266</span></a><span class="sd">            second field.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1267"><a href="#GradientBoostingSurvivalAnalysis-1267"><span class="linenos">1267</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1268"><a href="#GradientBoostingSurvivalAnalysis-1268"><span class="linenos">1268</span></a><span class="sd">        sample_weight : array-like, shape = (n_samples,), optional</span>
</span><span id="GradientBoostingSurvivalAnalysis-1269"><a href="#GradientBoostingSurvivalAnalysis-1269"><span class="linenos">1269</span></a><span class="sd">            Weights given to each sample. If omitted, all samples have weight 1.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1270"><a href="#GradientBoostingSurvivalAnalysis-1270"><span class="linenos">1270</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1271"><a href="#GradientBoostingSurvivalAnalysis-1271"><span class="linenos">1271</span></a><span class="sd">        monitor : callable, optional</span>
</span><span id="GradientBoostingSurvivalAnalysis-1272"><a href="#GradientBoostingSurvivalAnalysis-1272"><span class="linenos">1272</span></a><span class="sd">            The monitor is called after each iteration with the current</span>
</span><span id="GradientBoostingSurvivalAnalysis-1273"><a href="#GradientBoostingSurvivalAnalysis-1273"><span class="linenos">1273</span></a><span class="sd">            iteration, a reference to the estimator and the local variables of</span>
</span><span id="GradientBoostingSurvivalAnalysis-1274"><a href="#GradientBoostingSurvivalAnalysis-1274"><span class="linenos">1274</span></a><span class="sd">            ``_fit_stages`` as keyword arguments ``callable(i, self,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1275"><a href="#GradientBoostingSurvivalAnalysis-1275"><span class="linenos">1275</span></a><span class="sd">            locals())``. If the callable returns ``True`` the fitting procedure</span>
</span><span id="GradientBoostingSurvivalAnalysis-1276"><a href="#GradientBoostingSurvivalAnalysis-1276"><span class="linenos">1276</span></a><span class="sd">            is stopped. The monitor can be used for various things such as</span>
</span><span id="GradientBoostingSurvivalAnalysis-1277"><a href="#GradientBoostingSurvivalAnalysis-1277"><span class="linenos">1277</span></a><span class="sd">            computing held-out estimates, early stopping, model introspect, and</span>
</span><span id="GradientBoostingSurvivalAnalysis-1278"><a href="#GradientBoostingSurvivalAnalysis-1278"><span class="linenos">1278</span></a><span class="sd">            snapshoting.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1279"><a href="#GradientBoostingSurvivalAnalysis-1279"><span class="linenos">1279</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1280"><a href="#GradientBoostingSurvivalAnalysis-1280"><span class="linenos">1280</span></a><span class="sd">        Returns</span>
</span><span id="GradientBoostingSurvivalAnalysis-1281"><a href="#GradientBoostingSurvivalAnalysis-1281"><span class="linenos">1281</span></a><span class="sd">        -------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1282"><a href="#GradientBoostingSurvivalAnalysis-1282"><span class="linenos">1282</span></a><span class="sd">        self : object</span>
</span><span id="GradientBoostingSurvivalAnalysis-1283"><a href="#GradientBoostingSurvivalAnalysis-1283"><span class="linenos">1283</span></a><span class="sd">            Returns self.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1284"><a href="#GradientBoostingSurvivalAnalysis-1284"><span class="linenos">1284</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1285"><a href="#GradientBoostingSurvivalAnalysis-1285"><span class="linenos">1285</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1286"><a href="#GradientBoostingSurvivalAnalysis-1286"><span class="linenos">1286</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1287"><a href="#GradientBoostingSurvivalAnalysis-1287"><span class="linenos">1287</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1288"><a href="#GradientBoostingSurvivalAnalysis-1288"><span class="linenos">1288</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_state</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1289"><a href="#GradientBoostingSurvivalAnalysis-1289"><span class="linenos">1289</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1290"><a href="#GradientBoostingSurvivalAnalysis-1290"><span class="linenos">1290</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1291"><a href="#GradientBoostingSurvivalAnalysis-1291"><span class="linenos">1291</span></a>            <span class="n">X</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1292"><a href="#GradientBoostingSurvivalAnalysis-1292"><span class="linenos">1292</span></a>            <span class="n">ensure_min_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1293"><a href="#GradientBoostingSurvivalAnalysis-1293"><span class="linenos">1293</span></a>            <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1294"><a href="#GradientBoostingSurvivalAnalysis-1294"><span class="linenos">1294</span></a>            <span class="n">accept_sparse</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">,</span> <span class="s2">&quot;coo&quot;</span><span class="p">],</span>
</span><span id="GradientBoostingSurvivalAnalysis-1295"><a href="#GradientBoostingSurvivalAnalysis-1295"><span class="linenos">1295</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1296"><a href="#GradientBoostingSurvivalAnalysis-1296"><span class="linenos">1296</span></a>        <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1297"><a href="#GradientBoostingSurvivalAnalysis-1297"><span class="linenos">1297</span></a>        <span class="n">event</span><span class="p">,</span> <span class="n">time</span> <span class="o">=</span> <span class="n">check_array_survival</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1298"><a href="#GradientBoostingSurvivalAnalysis-1298"><span class="linenos">1298</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1299"><a href="#GradientBoostingSurvivalAnalysis-1299"><span class="linenos">1299</span></a>        <span class="n">sample_weight_is_none</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="GradientBoostingSurvivalAnalysis-1300"><a href="#GradientBoostingSurvivalAnalysis-1300"><span class="linenos">1300</span></a>        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1301"><a href="#GradientBoostingSurvivalAnalysis-1301"><span class="linenos">1301</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1302"><a href="#GradientBoostingSurvivalAnalysis-1302"><span class="linenos">1302</span></a>        <span class="k">if</span> <span class="n">sample_weight_is_none</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1303"><a href="#GradientBoostingSurvivalAnalysis-1303"><span class="linenos">1303</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1304"><a href="#GradientBoostingSurvivalAnalysis-1304"><span class="linenos">1304</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1305"><a href="#GradientBoostingSurvivalAnalysis-1305"><span class="linenos">1305</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1306"><a href="#GradientBoostingSurvivalAnalysis-1306"><span class="linenos">1306</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1307"><a href="#GradientBoostingSurvivalAnalysis-1307"><span class="linenos">1307</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_features</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1308"><a href="#GradientBoostingSurvivalAnalysis-1308"><span class="linenos">1308</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1309"><a href="#GradientBoostingSurvivalAnalysis-1309"><span class="linenos">1309</span></a>        <span class="c1"># self.loss is guaranteed to be a string</span>
</span><span id="GradientBoostingSurvivalAnalysis-1310"><a href="#GradientBoostingSurvivalAnalysis-1310"><span class="linenos">1310</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss</span><span class="p">(</span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1311"><a href="#GradientBoostingSurvivalAnalysis-1311"><span class="linenos">1311</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1312"><a href="#GradientBoostingSurvivalAnalysis-1312"><span class="linenos">1312</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="p">(</span><span class="n">CensoredSquaredLoss</span><span class="p">,</span> <span class="n">IPCWLeastSquaresError</span><span class="p">)):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1313"><a href="#GradientBoostingSurvivalAnalysis-1313"><span class="linenos">1313</span></a>            <span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1314"><a href="#GradientBoostingSurvivalAnalysis-1314"><span class="linenos">1314</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1315"><a href="#GradientBoostingSurvivalAnalysis-1315"><span class="linenos">1315</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1316"><a href="#GradientBoostingSurvivalAnalysis-1316"><span class="linenos">1316</span></a>            <span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1317"><a href="#GradientBoostingSurvivalAnalysis-1317"><span class="linenos">1317</span></a>                <span class="n">X_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1318"><a href="#GradientBoostingSurvivalAnalysis-1318"><span class="linenos">1318</span></a>                <span class="n">X_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1319"><a href="#GradientBoostingSurvivalAnalysis-1319"><span class="linenos">1319</span></a>                <span class="n">event_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1320"><a href="#GradientBoostingSurvivalAnalysis-1320"><span class="linenos">1320</span></a>                <span class="n">event_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1321"><a href="#GradientBoostingSurvivalAnalysis-1321"><span class="linenos">1321</span></a>                <span class="n">time_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1322"><a href="#GradientBoostingSurvivalAnalysis-1322"><span class="linenos">1322</span></a>                <span class="n">time_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1323"><a href="#GradientBoostingSurvivalAnalysis-1323"><span class="linenos">1323</span></a>                <span class="n">sample_weight_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1324"><a href="#GradientBoostingSurvivalAnalysis-1324"><span class="linenos">1324</span></a>                <span class="n">sample_weight_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1325"><a href="#GradientBoostingSurvivalAnalysis-1325"><span class="linenos">1325</span></a>            <span class="p">)</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1326"><a href="#GradientBoostingSurvivalAnalysis-1326"><span class="linenos">1326</span></a>                <span class="n">X</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1327"><a href="#GradientBoostingSurvivalAnalysis-1327"><span class="linenos">1327</span></a>                <span class="n">event</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1328"><a href="#GradientBoostingSurvivalAnalysis-1328"><span class="linenos">1328</span></a>                <span class="n">time</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1329"><a href="#GradientBoostingSurvivalAnalysis-1329"><span class="linenos">1329</span></a>                <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1330"><a href="#GradientBoostingSurvivalAnalysis-1330"><span class="linenos">1330</span></a>                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1331"><a href="#GradientBoostingSurvivalAnalysis-1331"><span class="linenos">1331</span></a>                <span class="n">test_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_fraction</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1332"><a href="#GradientBoostingSurvivalAnalysis-1332"><span class="linenos">1332</span></a>                <span class="n">stratify</span><span class="o">=</span><span class="n">event</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1333"><a href="#GradientBoostingSurvivalAnalysis-1333"><span class="linenos">1333</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1334"><a href="#GradientBoostingSurvivalAnalysis-1334"><span class="linenos">1334</span></a>            <span class="n">y_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1335"><a href="#GradientBoostingSurvivalAnalysis-1335"><span class="linenos">1335</span></a>                <span class="nb">zip</span><span class="p">(</span><span class="n">event_val</span><span class="p">,</span> <span class="n">time_val</span><span class="p">),</span>
</span><span id="GradientBoostingSurvivalAnalysis-1336"><a href="#GradientBoostingSurvivalAnalysis-1336"><span class="linenos">1336</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;event&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span>
</span><span id="GradientBoostingSurvivalAnalysis-1337"><a href="#GradientBoostingSurvivalAnalysis-1337"><span class="linenos">1337</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1338"><a href="#GradientBoostingSurvivalAnalysis-1338"><span class="linenos">1338</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1339"><a href="#GradientBoostingSurvivalAnalysis-1339"><span class="linenos">1339</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">sample_weight_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span>
</span><span id="GradientBoostingSurvivalAnalysis-1340"><a href="#GradientBoostingSurvivalAnalysis-1340"><span class="linenos">1340</span></a>            <span class="n">event_train</span><span class="p">,</span> <span class="n">time_train</span> <span class="o">=</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span>
</span><span id="GradientBoostingSurvivalAnalysis-1341"><a href="#GradientBoostingSurvivalAnalysis-1341"><span class="linenos">1341</span></a>            <span class="n">X_val</span> <span class="o">=</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">sample_weight_val</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GradientBoostingSurvivalAnalysis-1342"><a href="#GradientBoostingSurvivalAnalysis-1342"><span class="linenos">1342</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1343"><a href="#GradientBoostingSurvivalAnalysis-1343"><span class="linenos">1343</span></a>        <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1344"><a href="#GradientBoostingSurvivalAnalysis-1344"><span class="linenos">1344</span></a>            <span class="nb">zip</span><span class="p">(</span><span class="n">event_train</span><span class="p">,</span> <span class="n">time_train</span><span class="p">),</span>
</span><span id="GradientBoostingSurvivalAnalysis-1345"><a href="#GradientBoostingSurvivalAnalysis-1345"><span class="linenos">1345</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;event&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span>
</span><span id="GradientBoostingSurvivalAnalysis-1346"><a href="#GradientBoostingSurvivalAnalysis-1346"><span class="linenos">1346</span></a>        <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1347"><a href="#GradientBoostingSurvivalAnalysis-1347"><span class="linenos">1347</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1348"><a href="#GradientBoostingSurvivalAnalysis-1348"><span class="linenos">1348</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1349"><a href="#GradientBoostingSurvivalAnalysis-1349"><span class="linenos">1349</span></a>        <span class="c1"># First time calling fit.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1350"><a href="#GradientBoostingSurvivalAnalysis-1350"><span class="linenos">1350</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_fitted</span><span class="p">():</span>
</span><span id="GradientBoostingSurvivalAnalysis-1351"><a href="#GradientBoostingSurvivalAnalysis-1351"><span class="linenos">1351</span></a>            <span class="c1"># init state</span>
</span><span id="GradientBoostingSurvivalAnalysis-1352"><a href="#GradientBoostingSurvivalAnalysis-1352"><span class="linenos">1352</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_init_state</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1353"><a href="#GradientBoostingSurvivalAnalysis-1353"><span class="linenos">1353</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1354"><a href="#GradientBoostingSurvivalAnalysis-1354"><span class="linenos">1354</span></a>            <span class="n">raw_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1355"><a href="#GradientBoostingSurvivalAnalysis-1355"><span class="linenos">1355</span></a>                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span><span class="p">),</span>
</span><span id="GradientBoostingSurvivalAnalysis-1356"><a href="#GradientBoostingSurvivalAnalysis-1356"><span class="linenos">1356</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1357"><a href="#GradientBoostingSurvivalAnalysis-1357"><span class="linenos">1357</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1358"><a href="#GradientBoostingSurvivalAnalysis-1358"><span class="linenos">1358</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1359"><a href="#GradientBoostingSurvivalAnalysis-1359"><span class="linenos">1359</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="GradientBoostingSurvivalAnalysis-1360"><a href="#GradientBoostingSurvivalAnalysis-1360"><span class="linenos">1360</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1361"><a href="#GradientBoostingSurvivalAnalysis-1361"><span class="linenos">1361</span></a>            <span class="c1"># The rng state must be preserved if warm_start is True</span>
</span><span id="GradientBoostingSurvivalAnalysis-1362"><a href="#GradientBoostingSurvivalAnalysis-1362"><span class="linenos">1362</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1363"><a href="#GradientBoostingSurvivalAnalysis-1363"><span class="linenos">1363</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1364"><a href="#GradientBoostingSurvivalAnalysis-1364"><span class="linenos">1364</span></a>        <span class="c1"># warm start: this is not the first time fit was called</span>
</span><span id="GradientBoostingSurvivalAnalysis-1365"><a href="#GradientBoostingSurvivalAnalysis-1365"><span class="linenos">1365</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1366"><a href="#GradientBoostingSurvivalAnalysis-1366"><span class="linenos">1366</span></a>            <span class="c1"># add more estimators to fitted model</span>
</span><span id="GradientBoostingSurvivalAnalysis-1367"><a href="#GradientBoostingSurvivalAnalysis-1367"><span class="linenos">1367</span></a>            <span class="c1"># invariant: warm_start = True</span>
</span><span id="GradientBoostingSurvivalAnalysis-1368"><a href="#GradientBoostingSurvivalAnalysis-1368"><span class="linenos">1368</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1369"><a href="#GradientBoostingSurvivalAnalysis-1369"><span class="linenos">1369</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1370"><a href="#GradientBoostingSurvivalAnalysis-1370"><span class="linenos">1370</span></a>                    <span class="s2">&quot;n_estimators=</span><span class="si">%d</span><span class="s2"> must be larger or equal to &quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1371"><a href="#GradientBoostingSurvivalAnalysis-1371"><span class="linenos">1371</span></a>                    <span class="s2">&quot;estimators_.shape[0]=</span><span class="si">%d</span><span class="s2"> when &quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1372"><a href="#GradientBoostingSurvivalAnalysis-1372"><span class="linenos">1372</span></a>                    <span class="s2">&quot;warm_start==True&quot;</span> <span class="o">%</span> <span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1373"><a href="#GradientBoostingSurvivalAnalysis-1373"><span class="linenos">1373</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="GradientBoostingSurvivalAnalysis-1374"><a href="#GradientBoostingSurvivalAnalysis-1374"><span class="linenos">1374</span></a>                <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1375"><a href="#GradientBoostingSurvivalAnalysis-1375"><span class="linenos">1375</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis-1376"><a href="#GradientBoostingSurvivalAnalysis-1376"><span class="linenos">1376</span></a>            <span class="c1"># The requirements of _raw_predict</span>
</span><span id="GradientBoostingSurvivalAnalysis-1377"><a href="#GradientBoostingSurvivalAnalysis-1377"><span class="linenos">1377</span></a>            <span class="c1"># are more constrained than fit. It accepts only CSR</span>
</span><span id="GradientBoostingSurvivalAnalysis-1378"><a href="#GradientBoostingSurvivalAnalysis-1378"><span class="linenos">1378</span></a>            <span class="c1"># matrices. Finite values have already been checked in _validate_data.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1379"><a href="#GradientBoostingSurvivalAnalysis-1379"><span class="linenos">1379</span></a>            <span class="n">X_train</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1380"><a href="#GradientBoostingSurvivalAnalysis-1380"><span class="linenos">1380</span></a>                <span class="n">X_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1381"><a href="#GradientBoostingSurvivalAnalysis-1381"><span class="linenos">1381</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1382"><a href="#GradientBoostingSurvivalAnalysis-1382"><span class="linenos">1382</span></a>                <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1383"><a href="#GradientBoostingSurvivalAnalysis-1383"><span class="linenos">1383</span></a>                <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1384"><a href="#GradientBoostingSurvivalAnalysis-1384"><span class="linenos">1384</span></a>                <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1385"><a href="#GradientBoostingSurvivalAnalysis-1385"><span class="linenos">1385</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1386"><a href="#GradientBoostingSurvivalAnalysis-1386"><span class="linenos">1386</span></a>            <span class="n">raw_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1387"><a href="#GradientBoostingSurvivalAnalysis-1387"><span class="linenos">1387</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_resize_state</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1388"><a href="#GradientBoostingSurvivalAnalysis-1388"><span class="linenos">1388</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1389"><a href="#GradientBoostingSurvivalAnalysis-1389"><span class="linenos">1389</span></a>            <span class="c1"># apply dropout to last stage of previous fit</span>
</span><span id="GradientBoostingSurvivalAnalysis-1390"><a href="#GradientBoostingSurvivalAnalysis-1390"><span class="linenos">1390</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1391"><a href="#GradientBoostingSurvivalAnalysis-1391"><span class="linenos">1391</span></a>                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1392"><a href="#GradientBoostingSurvivalAnalysis-1392"><span class="linenos">1392</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1393"><a href="#GradientBoostingSurvivalAnalysis-1393"><span class="linenos">1393</span></a>                        <span class="c1"># pylint: disable-next=access-member-before-definition</span>
</span><span id="GradientBoostingSurvivalAnalysis-1394"><a href="#GradientBoostingSurvivalAnalysis-1394"><span class="linenos">1394</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1395"><a href="#GradientBoostingSurvivalAnalysis-1395"><span class="linenos">1395</span></a>                        <span class="n">X_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1396"><a href="#GradientBoostingSurvivalAnalysis-1396"><span class="linenos">1396</span></a>                        <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1397"><a href="#GradientBoostingSurvivalAnalysis-1397"><span class="linenos">1397</span></a>                        <span class="n">k</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1398"><a href="#GradientBoostingSurvivalAnalysis-1398"><span class="linenos">1398</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1399"><a href="#GradientBoostingSurvivalAnalysis-1399"><span class="linenos">1399</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1400"><a href="#GradientBoostingSurvivalAnalysis-1400"><span class="linenos">1400</span></a>                    <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1401"><a href="#GradientBoostingSurvivalAnalysis-1401"><span class="linenos">1401</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1402"><a href="#GradientBoostingSurvivalAnalysis-1402"><span class="linenos">1402</span></a>        <span class="n">scale</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1403"><a href="#GradientBoostingSurvivalAnalysis-1403"><span class="linenos">1403</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1404"><a href="#GradientBoostingSurvivalAnalysis-1404"><span class="linenos">1404</span></a>        <span class="c1"># fit the boosting stages</span>
</span><span id="GradientBoostingSurvivalAnalysis-1405"><a href="#GradientBoostingSurvivalAnalysis-1405"><span class="linenos">1405</span></a>        <span class="n">n_stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_stages</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1406"><a href="#GradientBoostingSurvivalAnalysis-1406"><span class="linenos">1406</span></a>            <span class="n">X_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1407"><a href="#GradientBoostingSurvivalAnalysis-1407"><span class="linenos">1407</span></a>            <span class="n">y_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1408"><a href="#GradientBoostingSurvivalAnalysis-1408"><span class="linenos">1408</span></a>            <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1409"><a href="#GradientBoostingSurvivalAnalysis-1409"><span class="linenos">1409</span></a>            <span class="n">sample_weight_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1410"><a href="#GradientBoostingSurvivalAnalysis-1410"><span class="linenos">1410</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1411"><a href="#GradientBoostingSurvivalAnalysis-1411"><span class="linenos">1411</span></a>            <span class="n">X_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1412"><a href="#GradientBoostingSurvivalAnalysis-1412"><span class="linenos">1412</span></a>            <span class="n">y_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1413"><a href="#GradientBoostingSurvivalAnalysis-1413"><span class="linenos">1413</span></a>            <span class="n">sample_weight_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1414"><a href="#GradientBoostingSurvivalAnalysis-1414"><span class="linenos">1414</span></a>            <span class="n">scale</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1415"><a href="#GradientBoostingSurvivalAnalysis-1415"><span class="linenos">1415</span></a>            <span class="n">begin_at_stage</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1416"><a href="#GradientBoostingSurvivalAnalysis-1416"><span class="linenos">1416</span></a>            <span class="n">monitor</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1417"><a href="#GradientBoostingSurvivalAnalysis-1417"><span class="linenos">1417</span></a>        <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1418"><a href="#GradientBoostingSurvivalAnalysis-1418"><span class="linenos">1418</span></a>        <span class="c1"># change shape of arrays after fit (early-stopping or additional tests)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1419"><a href="#GradientBoostingSurvivalAnalysis-1419"><span class="linenos">1419</span></a>        <span class="k">if</span> <span class="n">n_stages</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1420"><a href="#GradientBoostingSurvivalAnalysis-1420"><span class="linenos">1420</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_shrink_state</span><span class="p">(</span><span class="n">n_stages</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1421"><a href="#GradientBoostingSurvivalAnalysis-1421"><span class="linenos">1421</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">=</span> <span class="n">n_stages</span>
</span><span id="GradientBoostingSurvivalAnalysis-1422"><a href="#GradientBoostingSurvivalAnalysis-1422"><span class="linenos">1422</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1423"><a href="#GradientBoostingSurvivalAnalysis-1423"><span class="linenos">1423</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_baseline_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">event_train</span><span class="p">,</span> <span class="n">time_train</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1424"><a href="#GradientBoostingSurvivalAnalysis-1424"><span class="linenos">1424</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1425"><a href="#GradientBoostingSurvivalAnalysis-1425"><span class="linenos">1425</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="GradientBoostingSurvivalAnalysis-1426"><a href="#GradientBoostingSurvivalAnalysis-1426"><span class="linenos">1426</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1427"><a href="#GradientBoostingSurvivalAnalysis-1427"><span class="linenos">1427</span></a>    <span class="k">def</span> <span class="nf">_set_baseline_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1428"><a href="#GradientBoostingSurvivalAnalysis-1428"><span class="linenos">1428</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="n">CoxPH</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1429"><a href="#GradientBoostingSurvivalAnalysis-1429"><span class="linenos">1429</span></a>            <span class="n">X_pred</span> <span class="o">=</span> <span class="n">X</span>
</span><span id="GradientBoostingSurvivalAnalysis-1430"><a href="#GradientBoostingSurvivalAnalysis-1430"><span class="linenos">1430</span></a>            <span class="k">if</span> <span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1431"><a href="#GradientBoostingSurvivalAnalysis-1431"><span class="linenos">1431</span></a>                <span class="n">X_pred</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">asformat</span><span class="p">(</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1432"><a href="#GradientBoostingSurvivalAnalysis-1432"><span class="linenos">1432</span></a>            <span class="n">risk_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X_pred</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1433"><a href="#GradientBoostingSurvivalAnalysis-1433"><span class="linenos">1433</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="o">=</span> <span class="n">BreslowEstimator</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">risk_scores</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1434"><a href="#GradientBoostingSurvivalAnalysis-1434"><span class="linenos">1434</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1435"><a href="#GradientBoostingSurvivalAnalysis-1435"><span class="linenos">1435</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GradientBoostingSurvivalAnalysis-1436"><a href="#GradientBoostingSurvivalAnalysis-1436"><span class="linenos">1436</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1437"><a href="#GradientBoostingSurvivalAnalysis-1437"><span class="linenos">1437</span></a>    <span class="k">def</span> <span class="nf">_dropout_predict_stage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">score</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1438"><a href="#GradientBoostingSurvivalAnalysis-1438"><span class="linenos">1438</span></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1439"><a href="#GradientBoostingSurvivalAnalysis-1439"><span class="linenos">1439</span></a>            <span class="n">tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">tree_</span>
</span><span id="GradientBoostingSurvivalAnalysis-1440"><a href="#GradientBoostingSurvivalAnalysis-1440"><span class="linenos">1440</span></a>            <span class="n">score</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> \
</span><span id="GradientBoostingSurvivalAnalysis-1441"><a href="#GradientBoostingSurvivalAnalysis-1441"><span class="linenos">1441</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="GradientBoostingSurvivalAnalysis-1442"><a href="#GradientBoostingSurvivalAnalysis-1442"><span class="linenos">1442</span></a>        <span class="k">return</span> <span class="n">score</span>
</span><span id="GradientBoostingSurvivalAnalysis-1443"><a href="#GradientBoostingSurvivalAnalysis-1443"><span class="linenos">1443</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1444"><a href="#GradientBoostingSurvivalAnalysis-1444"><span class="linenos">1444</span></a>    <span class="k">def</span> <span class="nf">_dropout_raw_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1445"><a href="#GradientBoostingSurvivalAnalysis-1445"><span class="linenos">1445</span></a>        <span class="n">raw_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict_init</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1446"><a href="#GradientBoostingSurvivalAnalysis-1446"><span class="linenos">1446</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1447"><a href="#GradientBoostingSurvivalAnalysis-1447"><span class="linenos">1447</span></a>        <span class="n">n_estimators</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span>
</span><span id="GradientBoostingSurvivalAnalysis-1448"><a href="#GradientBoostingSurvivalAnalysis-1448"><span class="linenos">1448</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1449"><a href="#GradientBoostingSurvivalAnalysis-1449"><span class="linenos">1449</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_dropout_predict_stage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1450"><a href="#GradientBoostingSurvivalAnalysis-1450"><span class="linenos">1450</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1451"><a href="#GradientBoostingSurvivalAnalysis-1451"><span class="linenos">1451</span></a>        <span class="k">return</span> <span class="n">raw_predictions</span>
</span><span id="GradientBoostingSurvivalAnalysis-1452"><a href="#GradientBoostingSurvivalAnalysis-1452"><span class="linenos">1452</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1453"><a href="#GradientBoostingSurvivalAnalysis-1453"><span class="linenos">1453</span></a>    <span class="k">def</span> <span class="nf">_dropout_staged_raw_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1454"><a href="#GradientBoostingSurvivalAnalysis-1454"><span class="linenos">1454</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1455"><a href="#GradientBoostingSurvivalAnalysis-1455"><span class="linenos">1455</span></a>        <span class="n">raw_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict_init</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1456"><a href="#GradientBoostingSurvivalAnalysis-1456"><span class="linenos">1456</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1457"><a href="#GradientBoostingSurvivalAnalysis-1457"><span class="linenos">1457</span></a>        <span class="n">n_estimators</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span>
</span><span id="GradientBoostingSurvivalAnalysis-1458"><a href="#GradientBoostingSurvivalAnalysis-1458"><span class="linenos">1458</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1459"><a href="#GradientBoostingSurvivalAnalysis-1459"><span class="linenos">1459</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_dropout_predict_stage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">raw_predictions</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1460"><a href="#GradientBoostingSurvivalAnalysis-1460"><span class="linenos">1460</span></a>            <span class="k">yield</span> <span class="n">raw_predictions</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1461"><a href="#GradientBoostingSurvivalAnalysis-1461"><span class="linenos">1461</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1462"><a href="#GradientBoostingSurvivalAnalysis-1462"><span class="linenos">1462</span></a>    <span class="k">def</span> <span class="nf">_raw_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1463"><a href="#GradientBoostingSurvivalAnalysis-1463"><span class="linenos">1463</span></a>        <span class="c1"># if dropout wasn&#39;t used during training, proceed as usual,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1464"><a href="#GradientBoostingSurvivalAnalysis-1464"><span class="linenos">1464</span></a>        <span class="c1"># otherwise consider scaling factor of individual trees</span>
</span><span id="GradientBoostingSurvivalAnalysis-1465"><a href="#GradientBoostingSurvivalAnalysis-1465"><span class="linenos">1465</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1466"><a href="#GradientBoostingSurvivalAnalysis-1466"><span class="linenos">1466</span></a>            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1467"><a href="#GradientBoostingSurvivalAnalysis-1467"><span class="linenos">1467</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dropout_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1468"><a href="#GradientBoostingSurvivalAnalysis-1468"><span class="linenos">1468</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1469"><a href="#GradientBoostingSurvivalAnalysis-1469"><span class="linenos">1469</span></a>    <span class="k">def</span> <span class="nf">_init_decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
</span><span id="GradientBoostingSurvivalAnalysis-1470"><a href="#GradientBoostingSurvivalAnalysis-1470"><span class="linenos">1470</span></a>        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_init_decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1471"><a href="#GradientBoostingSurvivalAnalysis-1471"><span class="linenos">1471</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1472"><a href="#GradientBoostingSurvivalAnalysis-1472"><span class="linenos">1472</span></a>    <span class="k">def</span> <span class="nf">_decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
</span><span id="GradientBoostingSurvivalAnalysis-1473"><a href="#GradientBoostingSurvivalAnalysis-1473"><span class="linenos">1473</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1474"><a href="#GradientBoostingSurvivalAnalysis-1474"><span class="linenos">1474</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1475"><a href="#GradientBoostingSurvivalAnalysis-1475"><span class="linenos">1475</span></a>    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1476"><a href="#GradientBoostingSurvivalAnalysis-1476"><span class="linenos">1476</span></a>        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1477"><a href="#GradientBoostingSurvivalAnalysis-1477"><span class="linenos">1477</span></a>        <span class="k">if</span> <span class="n">score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1478"><a href="#GradientBoostingSurvivalAnalysis-1478"><span class="linenos">1478</span></a>            <span class="n">score</span> <span class="o">=</span> <span class="n">score</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1479"><a href="#GradientBoostingSurvivalAnalysis-1479"><span class="linenos">1479</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">_scale_raw_prediction</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1480"><a href="#GradientBoostingSurvivalAnalysis-1480"><span class="linenos">1480</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1481"><a href="#GradientBoostingSurvivalAnalysis-1481"><span class="linenos">1481</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1482"><a href="#GradientBoostingSurvivalAnalysis-1482"><span class="linenos">1482</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict risk scores.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1483"><a href="#GradientBoostingSurvivalAnalysis-1483"><span class="linenos">1483</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1484"><a href="#GradientBoostingSurvivalAnalysis-1484"><span class="linenos">1484</span></a><span class="sd">        If `loss=&#39;coxph&#39;`, predictions can be interpreted as log hazard ratio</span>
</span><span id="GradientBoostingSurvivalAnalysis-1485"><a href="#GradientBoostingSurvivalAnalysis-1485"><span class="linenos">1485</span></a><span class="sd">        similar to the linear predictor of a Cox proportional hazards</span>
</span><span id="GradientBoostingSurvivalAnalysis-1486"><a href="#GradientBoostingSurvivalAnalysis-1486"><span class="linenos">1486</span></a><span class="sd">        model. If `loss=&#39;squared&#39;` or `loss=&#39;ipcwls&#39;`, predictions are the</span>
</span><span id="GradientBoostingSurvivalAnalysis-1487"><a href="#GradientBoostingSurvivalAnalysis-1487"><span class="linenos">1487</span></a><span class="sd">        time to event.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1488"><a href="#GradientBoostingSurvivalAnalysis-1488"><span class="linenos">1488</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1489"><a href="#GradientBoostingSurvivalAnalysis-1489"><span class="linenos">1489</span></a><span class="sd">        Parameters</span>
</span><span id="GradientBoostingSurvivalAnalysis-1490"><a href="#GradientBoostingSurvivalAnalysis-1490"><span class="linenos">1490</span></a><span class="sd">        ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1491"><a href="#GradientBoostingSurvivalAnalysis-1491"><span class="linenos">1491</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1492"><a href="#GradientBoostingSurvivalAnalysis-1492"><span class="linenos">1492</span></a><span class="sd">            The input samples.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1493"><a href="#GradientBoostingSurvivalAnalysis-1493"><span class="linenos">1493</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1494"><a href="#GradientBoostingSurvivalAnalysis-1494"><span class="linenos">1494</span></a><span class="sd">        Returns</span>
</span><span id="GradientBoostingSurvivalAnalysis-1495"><a href="#GradientBoostingSurvivalAnalysis-1495"><span class="linenos">1495</span></a><span class="sd">        -------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1496"><a href="#GradientBoostingSurvivalAnalysis-1496"><span class="linenos">1496</span></a><span class="sd">        y : ndarray, shape = (n_samples,)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1497"><a href="#GradientBoostingSurvivalAnalysis-1497"><span class="linenos">1497</span></a><span class="sd">            The risk scores.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1498"><a href="#GradientBoostingSurvivalAnalysis-1498"><span class="linenos">1498</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1499"><a href="#GradientBoostingSurvivalAnalysis-1499"><span class="linenos">1499</span></a>        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1500"><a href="#GradientBoostingSurvivalAnalysis-1500"><span class="linenos">1500</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1501"><a href="#GradientBoostingSurvivalAnalysis-1501"><span class="linenos">1501</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1502"><a href="#GradientBoostingSurvivalAnalysis-1502"><span class="linenos">1502</span></a>                                <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1503"><a href="#GradientBoostingSurvivalAnalysis-1503"><span class="linenos">1503</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1504"><a href="#GradientBoostingSurvivalAnalysis-1504"><span class="linenos">1504</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1505"><a href="#GradientBoostingSurvivalAnalysis-1505"><span class="linenos">1505</span></a>    <span class="k">def</span> <span class="nf">staged_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1506"><a href="#GradientBoostingSurvivalAnalysis-1506"><span class="linenos">1506</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict risk scores at each stage for X.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1507"><a href="#GradientBoostingSurvivalAnalysis-1507"><span class="linenos">1507</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1508"><a href="#GradientBoostingSurvivalAnalysis-1508"><span class="linenos">1508</span></a><span class="sd">        This method allows monitoring (i.e. determine error on testing set)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1509"><a href="#GradientBoostingSurvivalAnalysis-1509"><span class="linenos">1509</span></a><span class="sd">        after each stage.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1510"><a href="#GradientBoostingSurvivalAnalysis-1510"><span class="linenos">1510</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1511"><a href="#GradientBoostingSurvivalAnalysis-1511"><span class="linenos">1511</span></a><span class="sd">        If `loss=&#39;coxph&#39;`, predictions can be interpreted as log hazard ratio</span>
</span><span id="GradientBoostingSurvivalAnalysis-1512"><a href="#GradientBoostingSurvivalAnalysis-1512"><span class="linenos">1512</span></a><span class="sd">        similar to the linear predictor of a Cox proportional hazards</span>
</span><span id="GradientBoostingSurvivalAnalysis-1513"><a href="#GradientBoostingSurvivalAnalysis-1513"><span class="linenos">1513</span></a><span class="sd">        model. If `loss=&#39;squared&#39;` or `loss=&#39;ipcwls&#39;`, predictions are the</span>
</span><span id="GradientBoostingSurvivalAnalysis-1514"><a href="#GradientBoostingSurvivalAnalysis-1514"><span class="linenos">1514</span></a><span class="sd">        time to event.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1515"><a href="#GradientBoostingSurvivalAnalysis-1515"><span class="linenos">1515</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1516"><a href="#GradientBoostingSurvivalAnalysis-1516"><span class="linenos">1516</span></a><span class="sd">        Parameters</span>
</span><span id="GradientBoostingSurvivalAnalysis-1517"><a href="#GradientBoostingSurvivalAnalysis-1517"><span class="linenos">1517</span></a><span class="sd">        ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1518"><a href="#GradientBoostingSurvivalAnalysis-1518"><span class="linenos">1518</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1519"><a href="#GradientBoostingSurvivalAnalysis-1519"><span class="linenos">1519</span></a><span class="sd">            The input samples.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1520"><a href="#GradientBoostingSurvivalAnalysis-1520"><span class="linenos">1520</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1521"><a href="#GradientBoostingSurvivalAnalysis-1521"><span class="linenos">1521</span></a><span class="sd">        Returns</span>
</span><span id="GradientBoostingSurvivalAnalysis-1522"><a href="#GradientBoostingSurvivalAnalysis-1522"><span class="linenos">1522</span></a><span class="sd">        -------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1523"><a href="#GradientBoostingSurvivalAnalysis-1523"><span class="linenos">1523</span></a><span class="sd">        y : generator of array of shape = (n_samples,)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1524"><a href="#GradientBoostingSurvivalAnalysis-1524"><span class="linenos">1524</span></a><span class="sd">            The predicted value of the input samples.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1525"><a href="#GradientBoostingSurvivalAnalysis-1525"><span class="linenos">1525</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1526"><a href="#GradientBoostingSurvivalAnalysis-1526"><span class="linenos">1526</span></a>        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1527"><a href="#GradientBoostingSurvivalAnalysis-1527"><span class="linenos">1527</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1528"><a href="#GradientBoostingSurvivalAnalysis-1528"><span class="linenos">1528</span></a>        <span class="c1"># if dropout wasn&#39;t used during training, proceed as usual,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1529"><a href="#GradientBoostingSurvivalAnalysis-1529"><span class="linenos">1529</span></a>        <span class="c1"># otherwise consider scaling factor of individual trees</span>
</span><span id="GradientBoostingSurvivalAnalysis-1530"><a href="#GradientBoostingSurvivalAnalysis-1530"><span class="linenos">1530</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1531"><a href="#GradientBoostingSurvivalAnalysis-1531"><span class="linenos">1531</span></a>            <span class="n">predictions_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_staged_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1532"><a href="#GradientBoostingSurvivalAnalysis-1532"><span class="linenos">1532</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1533"><a href="#GradientBoostingSurvivalAnalysis-1533"><span class="linenos">1533</span></a>            <span class="n">predictions_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dropout_staged_raw_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1534"><a href="#GradientBoostingSurvivalAnalysis-1534"><span class="linenos">1534</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1535"><a href="#GradientBoostingSurvivalAnalysis-1535"><span class="linenos">1535</span></a>        <span class="k">for</span> <span class="n">raw_predictions</span> <span class="ow">in</span> <span class="n">predictions_iter</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1536"><a href="#GradientBoostingSurvivalAnalysis-1536"><span class="linenos">1536</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">_scale_raw_prediction</span><span class="p">(</span><span class="n">raw_predictions</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1537"><a href="#GradientBoostingSurvivalAnalysis-1537"><span class="linenos">1537</span></a>            <span class="k">yield</span> <span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1538"><a href="#GradientBoostingSurvivalAnalysis-1538"><span class="linenos">1538</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1539"><a href="#GradientBoostingSurvivalAnalysis-1539"><span class="linenos">1539</span></a>    <span class="k">def</span> <span class="nf">_get_baseline_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1540"><a href="#GradientBoostingSurvivalAnalysis-1540"><span class="linenos">1540</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1541"><a href="#GradientBoostingSurvivalAnalysis-1541"><span class="linenos">1541</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis-1542"><a href="#GradientBoostingSurvivalAnalysis-1542"><span class="linenos">1542</span></a>                <span class="s2">&quot;`fit` must be called with the loss option set to &#39;coxph&#39;.&quot;</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1543"><a href="#GradientBoostingSurvivalAnalysis-1543"><span class="linenos">1543</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model</span>
</span><span id="GradientBoostingSurvivalAnalysis-1544"><a href="#GradientBoostingSurvivalAnalysis-1544"><span class="linenos">1544</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1545"><a href="#GradientBoostingSurvivalAnalysis-1545"><span class="linenos">1545</span></a>    <span class="k">def</span> <span class="nf">predict_cumulative_hazard_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1546"><a href="#GradientBoostingSurvivalAnalysis-1546"><span class="linenos">1546</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict cumulative hazard function.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1547"><a href="#GradientBoostingSurvivalAnalysis-1547"><span class="linenos">1547</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1548"><a href="#GradientBoostingSurvivalAnalysis-1548"><span class="linenos">1548</span></a><span class="sd">        Only available if :meth:`fit` has been called with `loss = &quot;coxph&quot;`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1549"><a href="#GradientBoostingSurvivalAnalysis-1549"><span class="linenos">1549</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1550"><a href="#GradientBoostingSurvivalAnalysis-1550"><span class="linenos">1550</span></a><span class="sd">        The cumulative hazard function for an individual</span>
</span><span id="GradientBoostingSurvivalAnalysis-1551"><a href="#GradientBoostingSurvivalAnalysis-1551"><span class="linenos">1551</span></a><span class="sd">        with feature vector :math:`x` is defined as</span>
</span><span id="GradientBoostingSurvivalAnalysis-1552"><a href="#GradientBoostingSurvivalAnalysis-1552"><span class="linenos">1552</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1553"><a href="#GradientBoostingSurvivalAnalysis-1553"><span class="linenos">1553</span></a><span class="sd">        .. math::</span>
</span><span id="GradientBoostingSurvivalAnalysis-1554"><a href="#GradientBoostingSurvivalAnalysis-1554"><span class="linenos">1554</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1555"><a href="#GradientBoostingSurvivalAnalysis-1555"><span class="linenos">1555</span></a><span class="sd">            H(t \\mid x) = \\exp(f(x)) H_0(t) ,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1556"><a href="#GradientBoostingSurvivalAnalysis-1556"><span class="linenos">1556</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1557"><a href="#GradientBoostingSurvivalAnalysis-1557"><span class="linenos">1557</span></a><span class="sd">        where :math:`f(\\cdot)` is the additive ensemble of base learners,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1558"><a href="#GradientBoostingSurvivalAnalysis-1558"><span class="linenos">1558</span></a><span class="sd">        and :math:`H_0(t)` is the baseline hazard function,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1559"><a href="#GradientBoostingSurvivalAnalysis-1559"><span class="linenos">1559</span></a><span class="sd">        estimated by Breslow&#39;s estimator.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1560"><a href="#GradientBoostingSurvivalAnalysis-1560"><span class="linenos">1560</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1561"><a href="#GradientBoostingSurvivalAnalysis-1561"><span class="linenos">1561</span></a><span class="sd">        Parameters</span>
</span><span id="GradientBoostingSurvivalAnalysis-1562"><a href="#GradientBoostingSurvivalAnalysis-1562"><span class="linenos">1562</span></a><span class="sd">        ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1563"><a href="#GradientBoostingSurvivalAnalysis-1563"><span class="linenos">1563</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1564"><a href="#GradientBoostingSurvivalAnalysis-1564"><span class="linenos">1564</span></a><span class="sd">            Data matrix.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1565"><a href="#GradientBoostingSurvivalAnalysis-1565"><span class="linenos">1565</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1566"><a href="#GradientBoostingSurvivalAnalysis-1566"><span class="linenos">1566</span></a><span class="sd">        return_array : boolean, default: False</span>
</span><span id="GradientBoostingSurvivalAnalysis-1567"><a href="#GradientBoostingSurvivalAnalysis-1567"><span class="linenos">1567</span></a><span class="sd">            If set, return an array with the cumulative hazard rate</span>
</span><span id="GradientBoostingSurvivalAnalysis-1568"><a href="#GradientBoostingSurvivalAnalysis-1568"><span class="linenos">1568</span></a><span class="sd">            for each `self.unique_times_`, otherwise an array of</span>
</span><span id="GradientBoostingSurvivalAnalysis-1569"><a href="#GradientBoostingSurvivalAnalysis-1569"><span class="linenos">1569</span></a><span class="sd">            :class:`survivalist.functions.StepFunction`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1570"><a href="#GradientBoostingSurvivalAnalysis-1570"><span class="linenos">1570</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1571"><a href="#GradientBoostingSurvivalAnalysis-1571"><span class="linenos">1571</span></a><span class="sd">        Returns</span>
</span><span id="GradientBoostingSurvivalAnalysis-1572"><a href="#GradientBoostingSurvivalAnalysis-1572"><span class="linenos">1572</span></a><span class="sd">        -------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1573"><a href="#GradientBoostingSurvivalAnalysis-1573"><span class="linenos">1573</span></a><span class="sd">        cum_hazard : ndarray</span>
</span><span id="GradientBoostingSurvivalAnalysis-1574"><a href="#GradientBoostingSurvivalAnalysis-1574"><span class="linenos">1574</span></a><span class="sd">            If `return_array` is set, an array with the cumulative hazard rate</span>
</span><span id="GradientBoostingSurvivalAnalysis-1575"><a href="#GradientBoostingSurvivalAnalysis-1575"><span class="linenos">1575</span></a><span class="sd">            for each `self.unique_times_`, otherwise an array of length `n_samples`</span>
</span><span id="GradientBoostingSurvivalAnalysis-1576"><a href="#GradientBoostingSurvivalAnalysis-1576"><span class="linenos">1576</span></a><span class="sd">            of :class:`survivalist.functions.StepFunction` instances will be returned.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1577"><a href="#GradientBoostingSurvivalAnalysis-1577"><span class="linenos">1577</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1578"><a href="#GradientBoostingSurvivalAnalysis-1578"><span class="linenos">1578</span></a><span class="sd">        Examples</span>
</span><span id="GradientBoostingSurvivalAnalysis-1579"><a href="#GradientBoostingSurvivalAnalysis-1579"><span class="linenos">1579</span></a><span class="sd">        --------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1580"><a href="#GradientBoostingSurvivalAnalysis-1580"><span class="linenos">1580</span></a><span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
</span><span id="GradientBoostingSurvivalAnalysis-1581"><a href="#GradientBoostingSurvivalAnalysis-1581"><span class="linenos">1581</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.datasets import load_whas500</span>
</span><span id="GradientBoostingSurvivalAnalysis-1582"><a href="#GradientBoostingSurvivalAnalysis-1582"><span class="linenos">1582</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.ensemble import GradientBoostingSurvivalAnalysis</span>
</span><span id="GradientBoostingSurvivalAnalysis-1583"><a href="#GradientBoostingSurvivalAnalysis-1583"><span class="linenos">1583</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1584"><a href="#GradientBoostingSurvivalAnalysis-1584"><span class="linenos">1584</span></a><span class="sd">        Load the data.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1585"><a href="#GradientBoostingSurvivalAnalysis-1585"><span class="linenos">1585</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1586"><a href="#GradientBoostingSurvivalAnalysis-1586"><span class="linenos">1586</span></a><span class="sd">        &gt;&gt;&gt; X, y = load_whas500()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1587"><a href="#GradientBoostingSurvivalAnalysis-1587"><span class="linenos">1587</span></a><span class="sd">        &gt;&gt;&gt; X = X.astype(float)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1588"><a href="#GradientBoostingSurvivalAnalysis-1588"><span class="linenos">1588</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1589"><a href="#GradientBoostingSurvivalAnalysis-1589"><span class="linenos">1589</span></a><span class="sd">        Fit the model.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1590"><a href="#GradientBoostingSurvivalAnalysis-1590"><span class="linenos">1590</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1591"><a href="#GradientBoostingSurvivalAnalysis-1591"><span class="linenos">1591</span></a><span class="sd">        &gt;&gt;&gt; estimator = GradientBoostingSurvivalAnalysis(loss=&quot;coxph&quot;).fit(X, y)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1592"><a href="#GradientBoostingSurvivalAnalysis-1592"><span class="linenos">1592</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1593"><a href="#GradientBoostingSurvivalAnalysis-1593"><span class="linenos">1593</span></a><span class="sd">        Estimate the cumulative hazard function for the first 10 samples.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1594"><a href="#GradientBoostingSurvivalAnalysis-1594"><span class="linenos">1594</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1595"><a href="#GradientBoostingSurvivalAnalysis-1595"><span class="linenos">1595</span></a><span class="sd">        &gt;&gt;&gt; chf_funcs = estimator.predict_cumulative_hazard_function(X.iloc[:10])</span>
</span><span id="GradientBoostingSurvivalAnalysis-1596"><a href="#GradientBoostingSurvivalAnalysis-1596"><span class="linenos">1596</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1597"><a href="#GradientBoostingSurvivalAnalysis-1597"><span class="linenos">1597</span></a><span class="sd">        Plot the estimated cumulative hazard functions.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1598"><a href="#GradientBoostingSurvivalAnalysis-1598"><span class="linenos">1598</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1599"><a href="#GradientBoostingSurvivalAnalysis-1599"><span class="linenos">1599</span></a><span class="sd">        &gt;&gt;&gt; for fn in chf_funcs:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1600"><a href="#GradientBoostingSurvivalAnalysis-1600"><span class="linenos">1600</span></a><span class="sd">        ...     plt.step(fn.x, fn(fn.x), where=&quot;post&quot;)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1601"><a href="#GradientBoostingSurvivalAnalysis-1601"><span class="linenos">1601</span></a><span class="sd">        ...</span>
</span><span id="GradientBoostingSurvivalAnalysis-1602"><a href="#GradientBoostingSurvivalAnalysis-1602"><span class="linenos">1602</span></a><span class="sd">        &gt;&gt;&gt; plt.ylim(0, 1)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1603"><a href="#GradientBoostingSurvivalAnalysis-1603"><span class="linenos">1603</span></a><span class="sd">        &gt;&gt;&gt; plt.show()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1604"><a href="#GradientBoostingSurvivalAnalysis-1604"><span class="linenos">1604</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1605"><a href="#GradientBoostingSurvivalAnalysis-1605"><span class="linenos">1605</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_cumulative_hazard_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">return_array</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1606"><a href="#GradientBoostingSurvivalAnalysis-1606"><span class="linenos">1606</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1607"><a href="#GradientBoostingSurvivalAnalysis-1607"><span class="linenos">1607</span></a>    <span class="k">def</span> <span class="nf">predict_survival_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_array</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1608"><a href="#GradientBoostingSurvivalAnalysis-1608"><span class="linenos">1608</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict survival function.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1609"><a href="#GradientBoostingSurvivalAnalysis-1609"><span class="linenos">1609</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1610"><a href="#GradientBoostingSurvivalAnalysis-1610"><span class="linenos">1610</span></a><span class="sd">        Only available if :meth:`fit` has been called with `loss = &quot;coxph&quot;`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1611"><a href="#GradientBoostingSurvivalAnalysis-1611"><span class="linenos">1611</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1612"><a href="#GradientBoostingSurvivalAnalysis-1612"><span class="linenos">1612</span></a><span class="sd">        The survival function for an individual</span>
</span><span id="GradientBoostingSurvivalAnalysis-1613"><a href="#GradientBoostingSurvivalAnalysis-1613"><span class="linenos">1613</span></a><span class="sd">        with feature vector :math:`x` is defined as</span>
</span><span id="GradientBoostingSurvivalAnalysis-1614"><a href="#GradientBoostingSurvivalAnalysis-1614"><span class="linenos">1614</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1615"><a href="#GradientBoostingSurvivalAnalysis-1615"><span class="linenos">1615</span></a><span class="sd">        .. math::</span>
</span><span id="GradientBoostingSurvivalAnalysis-1616"><a href="#GradientBoostingSurvivalAnalysis-1616"><span class="linenos">1616</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1617"><a href="#GradientBoostingSurvivalAnalysis-1617"><span class="linenos">1617</span></a><span class="sd">            S(t \\mid x) = S_0(t)^{\\exp(f(x)} ,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1618"><a href="#GradientBoostingSurvivalAnalysis-1618"><span class="linenos">1618</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1619"><a href="#GradientBoostingSurvivalAnalysis-1619"><span class="linenos">1619</span></a><span class="sd">        where :math:`f(\\cdot)` is the additive ensemble of base learners,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1620"><a href="#GradientBoostingSurvivalAnalysis-1620"><span class="linenos">1620</span></a><span class="sd">        and :math:`S_0(t)` is the baseline survival function,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1621"><a href="#GradientBoostingSurvivalAnalysis-1621"><span class="linenos">1621</span></a><span class="sd">        estimated by Breslow&#39;s estimator.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1622"><a href="#GradientBoostingSurvivalAnalysis-1622"><span class="linenos">1622</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1623"><a href="#GradientBoostingSurvivalAnalysis-1623"><span class="linenos">1623</span></a><span class="sd">        Parameters</span>
</span><span id="GradientBoostingSurvivalAnalysis-1624"><a href="#GradientBoostingSurvivalAnalysis-1624"><span class="linenos">1624</span></a><span class="sd">        ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1625"><a href="#GradientBoostingSurvivalAnalysis-1625"><span class="linenos">1625</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1626"><a href="#GradientBoostingSurvivalAnalysis-1626"><span class="linenos">1626</span></a><span class="sd">            Data matrix.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1627"><a href="#GradientBoostingSurvivalAnalysis-1627"><span class="linenos">1627</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1628"><a href="#GradientBoostingSurvivalAnalysis-1628"><span class="linenos">1628</span></a><span class="sd">        return_array : boolean, default: False</span>
</span><span id="GradientBoostingSurvivalAnalysis-1629"><a href="#GradientBoostingSurvivalAnalysis-1629"><span class="linenos">1629</span></a><span class="sd">            If set, return an array with the probability</span>
</span><span id="GradientBoostingSurvivalAnalysis-1630"><a href="#GradientBoostingSurvivalAnalysis-1630"><span class="linenos">1630</span></a><span class="sd">            of survival for each `self.unique_times_`,</span>
</span><span id="GradientBoostingSurvivalAnalysis-1631"><a href="#GradientBoostingSurvivalAnalysis-1631"><span class="linenos">1631</span></a><span class="sd">            otherwise an array of :class:`survivalist.functions.StepFunction`.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1632"><a href="#GradientBoostingSurvivalAnalysis-1632"><span class="linenos">1632</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1633"><a href="#GradientBoostingSurvivalAnalysis-1633"><span class="linenos">1633</span></a><span class="sd">        Returns</span>
</span><span id="GradientBoostingSurvivalAnalysis-1634"><a href="#GradientBoostingSurvivalAnalysis-1634"><span class="linenos">1634</span></a><span class="sd">        -------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1635"><a href="#GradientBoostingSurvivalAnalysis-1635"><span class="linenos">1635</span></a><span class="sd">        survival : ndarray</span>
</span><span id="GradientBoostingSurvivalAnalysis-1636"><a href="#GradientBoostingSurvivalAnalysis-1636"><span class="linenos">1636</span></a><span class="sd">            If `return_array` is set, an array with the probability of</span>
</span><span id="GradientBoostingSurvivalAnalysis-1637"><a href="#GradientBoostingSurvivalAnalysis-1637"><span class="linenos">1637</span></a><span class="sd">            survival for each `self.unique_times_`, otherwise an array of</span>
</span><span id="GradientBoostingSurvivalAnalysis-1638"><a href="#GradientBoostingSurvivalAnalysis-1638"><span class="linenos">1638</span></a><span class="sd">            length `n_samples` of :class:`survivalist.functions.StepFunction`</span>
</span><span id="GradientBoostingSurvivalAnalysis-1639"><a href="#GradientBoostingSurvivalAnalysis-1639"><span class="linenos">1639</span></a><span class="sd">            instances will be returned.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1640"><a href="#GradientBoostingSurvivalAnalysis-1640"><span class="linenos">1640</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1641"><a href="#GradientBoostingSurvivalAnalysis-1641"><span class="linenos">1641</span></a><span class="sd">        Examples</span>
</span><span id="GradientBoostingSurvivalAnalysis-1642"><a href="#GradientBoostingSurvivalAnalysis-1642"><span class="linenos">1642</span></a><span class="sd">        --------</span>
</span><span id="GradientBoostingSurvivalAnalysis-1643"><a href="#GradientBoostingSurvivalAnalysis-1643"><span class="linenos">1643</span></a><span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
</span><span id="GradientBoostingSurvivalAnalysis-1644"><a href="#GradientBoostingSurvivalAnalysis-1644"><span class="linenos">1644</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.datasets import load_whas500</span>
</span><span id="GradientBoostingSurvivalAnalysis-1645"><a href="#GradientBoostingSurvivalAnalysis-1645"><span class="linenos">1645</span></a><span class="sd">        &gt;&gt;&gt; from survivalist.ensemble import GradientBoostingSurvivalAnalysis</span>
</span><span id="GradientBoostingSurvivalAnalysis-1646"><a href="#GradientBoostingSurvivalAnalysis-1646"><span class="linenos">1646</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1647"><a href="#GradientBoostingSurvivalAnalysis-1647"><span class="linenos">1647</span></a><span class="sd">        Load the data.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1648"><a href="#GradientBoostingSurvivalAnalysis-1648"><span class="linenos">1648</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1649"><a href="#GradientBoostingSurvivalAnalysis-1649"><span class="linenos">1649</span></a><span class="sd">        &gt;&gt;&gt; X, y = load_whas500()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1650"><a href="#GradientBoostingSurvivalAnalysis-1650"><span class="linenos">1650</span></a><span class="sd">        &gt;&gt;&gt; X = X.astype(float)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1651"><a href="#GradientBoostingSurvivalAnalysis-1651"><span class="linenos">1651</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1652"><a href="#GradientBoostingSurvivalAnalysis-1652"><span class="linenos">1652</span></a><span class="sd">        Fit the model.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1653"><a href="#GradientBoostingSurvivalAnalysis-1653"><span class="linenos">1653</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1654"><a href="#GradientBoostingSurvivalAnalysis-1654"><span class="linenos">1654</span></a><span class="sd">        &gt;&gt;&gt; estimator = GradientBoostingSurvivalAnalysis(loss=&quot;coxph&quot;).fit(X, y)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1655"><a href="#GradientBoostingSurvivalAnalysis-1655"><span class="linenos">1655</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1656"><a href="#GradientBoostingSurvivalAnalysis-1656"><span class="linenos">1656</span></a><span class="sd">        Estimate the survival function for the first 10 samples.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1657"><a href="#GradientBoostingSurvivalAnalysis-1657"><span class="linenos">1657</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1658"><a href="#GradientBoostingSurvivalAnalysis-1658"><span class="linenos">1658</span></a><span class="sd">        &gt;&gt;&gt; surv_funcs = estimator.predict_survival_function(X.iloc[:10])</span>
</span><span id="GradientBoostingSurvivalAnalysis-1659"><a href="#GradientBoostingSurvivalAnalysis-1659"><span class="linenos">1659</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1660"><a href="#GradientBoostingSurvivalAnalysis-1660"><span class="linenos">1660</span></a><span class="sd">        Plot the estimated survival functions.</span>
</span><span id="GradientBoostingSurvivalAnalysis-1661"><a href="#GradientBoostingSurvivalAnalysis-1661"><span class="linenos">1661</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1662"><a href="#GradientBoostingSurvivalAnalysis-1662"><span class="linenos">1662</span></a><span class="sd">        &gt;&gt;&gt; for fn in surv_funcs:</span>
</span><span id="GradientBoostingSurvivalAnalysis-1663"><a href="#GradientBoostingSurvivalAnalysis-1663"><span class="linenos">1663</span></a><span class="sd">        ...     plt.step(fn.x, fn(fn.x), where=&quot;post&quot;)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1664"><a href="#GradientBoostingSurvivalAnalysis-1664"><span class="linenos">1664</span></a><span class="sd">        ...</span>
</span><span id="GradientBoostingSurvivalAnalysis-1665"><a href="#GradientBoostingSurvivalAnalysis-1665"><span class="linenos">1665</span></a><span class="sd">        &gt;&gt;&gt; plt.ylim(0, 1)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1666"><a href="#GradientBoostingSurvivalAnalysis-1666"><span class="linenos">1666</span></a><span class="sd">        &gt;&gt;&gt; plt.show()</span>
</span><span id="GradientBoostingSurvivalAnalysis-1667"><a href="#GradientBoostingSurvivalAnalysis-1667"><span class="linenos">1667</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis-1668"><a href="#GradientBoostingSurvivalAnalysis-1668"><span class="linenos">1668</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_survival_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">return_array</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis-1669"><a href="#GradientBoostingSurvivalAnalysis-1669"><span class="linenos">1669</span></a>
</span><span id="GradientBoostingSurvivalAnalysis-1670"><a href="#GradientBoostingSurvivalAnalysis-1670"><span class="linenos">1670</span></a>    <span class="nd">@property</span>
</span><span id="GradientBoostingSurvivalAnalysis-1671"><a href="#GradientBoostingSurvivalAnalysis-1671"><span class="linenos">1671</span></a>    <span class="k">def</span> <span class="nf">unique_times_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis-1672"><a href="#GradientBoostingSurvivalAnalysis-1672"><span class="linenos">1672</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_baseline_model</span><span class="p">()</span><span class="o">.</span><span class="n">unique_times_</span>
</span></pre></div>


            <div class="docstring"><p>Gradient-boosted Cox proportional hazard loss with
regression trees as base learner.</p>

<p>In each stage, a regression tree is fit on the negative gradient
of the loss function.</p>

<p>For more details on gradient boosting see <sup class="footnote-ref" id="fnref-1"><a href="#fn-1">1</a></sup> and <sup class="footnote-ref" id="fnref-2"><a href="#fn-2">2</a></sup>. If <code>loss='coxph'</code>,
the partial likelihood of the proportional hazards model is optimized as
described in <sup class="footnote-ref" id="fnref-3"><a href="#fn-3">3</a></sup>. If <code>loss='ipcwls'</code>, the accelerated failure time model with
inverse-probability of censoring weighted least squares error is optimized as
described in <sup class="footnote-ref" id="fnref-4"><a href="#fn-4">4</a></sup>. When using a non-zero <code><a href="#GradientBoostingSurvivalAnalysis.dropout_rate">dropout_rate</a></code>, regularization is
applied during training following <sup class="footnote-ref" id="fnref-5"><a href="#fn-5">5</a></sup>.</p>

<p>See the :ref:<code>User Guide &lt;/user_guide/boosting.ipynb&gt;</code> for examples.</p>

<h2 id="parameters">Parameters</h2>

<p>loss : {'coxph', 'squared', 'ipcwls'}, optional, default: 'coxph'
    loss function to be optimized. 'coxph' refers to partial likelihood loss
    of Cox's proportional hazards model. The loss 'squared' minimizes a
    squared regression loss that ignores predictions beyond the time of censoring,
    and 'ipcwls' refers to inverse-probability of censoring weighted least squares error.</p>

<p>learning_rate : float, optional, default: 0.1
    learning rate shrinks the contribution of each tree by <code><a href="#GradientBoostingSurvivalAnalysis.learning_rate">learning_rate</a></code>.
    There is a trade-off between <code><a href="#GradientBoostingSurvivalAnalysis.learning_rate">learning_rate</a></code> and <code><a href="#GradientBoostingSurvivalAnalysis.n_estimators">n_estimators</a></code>.
    Values must be in the range <code>[0.0, inf)</code>.</p>

<p>n_estimators : int, default: 100
    The number of regression trees to create. Gradient boosting
    is fairly robust to over-fitting so a large number usually
    results in better performance.
    Values must be in the range <code>[1, inf)</code>.</p>

<p>subsample : float, optional, default: 1.0
    The fraction of samples to be used for fitting the individual base
    learners. If smaller than 1.0 this results in Stochastic Gradient
    Boosting. <code><a href="#GradientBoostingSurvivalAnalysis.subsample">subsample</a></code> interacts with the parameter <code><a href="#GradientBoostingSurvivalAnalysis.n_estimators">n_estimators</a></code>.
    Choosing <code>subsample &lt; 1.0</code> leads to a reduction of variance
    and an increase in bias.
    Values must be in the range <code>(0.0, 1.0]</code>.</p>

<p>criterion : {'friedman_mse', 'squared_error'}, default: 'friedman_mse'
    The function to measure the quality of a split. Supported criteria are
    'friedman_mse' for the mean squared error with improvement score by
    Friedman, 'squared_error' for mean squared error. The default value of
    'friedman_mse' is generally the best as it can provide a better
    approximation in some cases.</p>

<p>min_samples_split : int or float, optional, default: 2
    The minimum number of samples required to split an internal node:</p>

<pre><code>- If int, values must be in the range `[2, inf)`.
- If float, values must be in the range `(0.0, 1.0]` and `min_samples_split`
  will be `ceil(min_samples_split * n_samples)`.
</code></pre>

<p>min_samples_leaf : int or float, default: 1
    The minimum number of samples required to be at a leaf node.
    A split point at any depth will only be considered if it leaves at
    least <code><a href="#GradientBoostingSurvivalAnalysis.min_samples_leaf">min_samples_leaf</a></code> training samples in each of the left and
    right branches.  This may have the effect of smoothing the model,
    especially in regression.</p>

<pre><code>- If int, values must be in the range `[1, inf)`.
- If float, values must be in the range `(0.0, 1.0)` and `min_samples_leaf`
  will be `ceil(min_samples_leaf * n_samples)`.
</code></pre>

<p>min_weight_fraction_leaf : float, optional, default: 0.
    The minimum weighted fraction of the sum total of weights (of all
    the input samples) required to be at a leaf node. Samples have
    equal weight when <code>sample_weight</code> is not provided.
    Values must be in the range <code>[0.0, 0.5]</code>.</p>

<p>max_depth : int or None, optional, default: 3
    Maximum depth of the individual regression estimators. The maximum
    depth limits the number of nodes in the tree. Tune this parameter
    for best performance; the best value depends on the interaction
    of the input variables. If None, then nodes are expanded until
    all leaves are pure or until all leaves contain less than
    <code><a href="#GradientBoostingSurvivalAnalysis.min_samples_split">min_samples_split</a></code> samples.
    If int, values must be in the range <code>[1, inf)</code>.</p>

<p>min_impurity_decrease : float, optional, default: 0.
    A node will be split if this split induces a decrease of the impurity
    greater than or equal to this value.</p>

<pre><code>The weighted impurity decrease equation is the following::

    N_t / N * (impurity - N_t_R / N_t * right_impurity
                        - N_t_L / N_t * left_impurity)

where ``N`` is the total number of samples, ``N_t`` is the number of
samples at the current node, ``N_t_L`` is the number of samples in the
left child, and ``N_t_R`` is the number of samples in the right child.

``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,
if ``sample_weight`` is passed.
</code></pre>

<p>random_state : int seed, RandomState instance, or None, default: None
    Controls the random seed given to each Tree estimator at each
    boosting iteration.
    In addition, it controls the random permutation of the features at
    each split.
    It also controls the random splitting of the training data to obtain a
    validation set if <code><a href="#GradientBoostingSurvivalAnalysis.n_iter_no_change">n_iter_no_change</a></code> is not None.
    Pass an int for reproducible output across multiple function calls.</p>

<p>max_features : int, float, string or None, optional, default: None
    The number of features to consider when looking for the best split:</p>

<pre><code>- If int, values must be in the range `[1, inf)`.
- If float, values must be in the range `(0.0, 1.0]` and the features
  considered at each split will be `max(1, int(max_features * n_features_in_))`.
- If 'sqrt', then `max_features=sqrt(n_features)`.
- If 'log2', then `max_features=log2(n_features)`.
- If None, then `max_features=n_features`.

Choosing `max_features &lt; n_features` leads to a reduction of variance
and an increase in bias.

Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than ``max_features`` features.
</code></pre>

<p>max_leaf_nodes : int or None, optional, default: None
    Grow trees with <code><a href="#GradientBoostingSurvivalAnalysis.max_leaf_nodes">max_leaf_nodes</a></code> in best-first fashion.
    Best nodes are defined as relative reduction in impurity.
    Values must be in the range <code>[2, inf)</code>.
    If <code>None</code>, then unlimited number of leaf nodes.</p>

<p>warm_start : bool, default: False
    When set to <code>True</code>, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just erase the
    previous solution.</p>

<p>validation_fraction : float, default: 0.1
    The proportion of training data to set aside as validation set for
    early stopping. Values must be in the range <code>(0.0, 1.0)</code>.
    Only used if <code><a href="#GradientBoostingSurvivalAnalysis.n_iter_no_change">n_iter_no_change</a></code> is set to an integer.</p>

<p>n_iter_no_change : int, default: None
    <code><a href="#GradientBoostingSurvivalAnalysis.n_iter_no_change">n_iter_no_change</a></code> is used to decide if early stopping will be used
    to terminate training when validation score is not improving. By
    default it is set to None to disable early stopping. If set to a
    number, it will set aside <code><a href="#GradientBoostingSurvivalAnalysis.validation_fraction">validation_fraction</a></code> size of the training
    data as validation and terminate training when validation score is not
    improving in all of the previous <code><a href="#GradientBoostingSurvivalAnalysis.n_iter_no_change">n_iter_no_change</a></code> numbers of
    iterations. The split is stratified.
    Values must be in the range <code>[1, inf)</code>.</p>

<p>tol : float, default: 1e-4
    Tolerance for the early stopping. When the loss is not improving
    by at least tol for <code><a href="#GradientBoostingSurvivalAnalysis.n_iter_no_change">n_iter_no_change</a></code> iterations (if set to a
    number), the training stops.
    Values must be in the range <code>[0.0, inf)</code>.</p>

<p>dropout_rate : float, optional, default: 0.0
    If larger than zero, the residuals at each iteration are only computed
    from a random subset of base learners. The value corresponds to the
    percentage of base learners that are dropped. In each iteration,
    at least one base learner is dropped. This is an alternative regularization
    to shrinkage, i.e., setting <code>learning_rate &lt; 1.0</code>.
    Values must be in the range <code>[0.0, 1.0)</code>.</p>

<p>verbose : int, default: 0
    Enable verbose output. If 1 then it prints progress and performance
    once in a while (the more trees the lower the frequency). If greater
    than 1 then it prints progress and performance for every tree.
    Values must be in the range <code>[0, inf)</code>.</p>

<p>ccp_alpha : non-negative float, optional, default: 0.0.
    Complexity parameter used for Minimal Cost-Complexity Pruning. The
    subtree with the largest cost complexity that is smaller than
    <code><a href="#GradientBoostingSurvivalAnalysis.ccp_alpha">ccp_alpha</a></code> will be chosen. By default, no pruning is performed.
    Values must be in the range <code>[0.0, inf)</code>.</p>

<h2 id="attributes">Attributes</h2>

<p>n_estimators_ : int
    The number of estimators as selected by early stopping (if
    <code><a href="#GradientBoostingSurvivalAnalysis.n_iter_no_change">n_iter_no_change</a></code> is specified). Otherwise it is set to
    <code><a href="#GradientBoostingSurvivalAnalysis.n_estimators">n_estimators</a></code>.</p>

<p>feature_importances_ : ndarray, shape = (n_features,)
    The feature importances (the higher, the more important the feature).</p>

<p>estimators_ : ndarray of DecisionTreeRegressor, shape = (n_estimators, 1)
    The collection of fitted sub-estimators.</p>

<p>train_score_ : ndarray, shape = (n_estimators,)
    The i-th score <code>train_score_[i]</code> is the loss of the
    model at iteration <code>i</code> on the in-bag sample.
    If <code>subsample == 1</code> this is the loss on the training data.</p>

<p>oob_improvement_ : ndarray, shape = (n_estimators,)
    The improvement in loss on the out-of-bag samples
    relative to the previous iteration.
    <code>oob_improvement_[0]</code> is the improvement in
    loss of the first stage over the <code><a href="#GradientBoostingSurvivalAnalysis.init">init</a></code> estimator.
    Only available if <code>subsample &lt; 1.0</code>.</p>

<p>oob_scores_ : ndarray of shape (n_estimators,)
    The full history of the loss values on the out-of-bag
    samples. Only available if <code>subsample &lt; 1.0</code>.</p>

<p>oob_score_ : float
    The last value of the loss on the out-of-bag samples. It is
    the same as <code>oob_scores_[-1]</code>. Only available if <code>subsample &lt; 1.0</code>.</p>

<p>n_features_in_ : int
    Number of features seen during <code><a href="#GradientBoostingSurvivalAnalysis.fit">fit</a></code>.</p>

<p>feature_names_in_ : ndarray of shape (<code>n_features_in_</code>,)
    Names of features seen during <code><a href="#GradientBoostingSurvivalAnalysis.fit">fit</a></code>. Defined only when <code>X</code>
    has feature names that are all strings.</p>

<p>max_features_ : int
    The inferred value of max_features.</p>

<p>unique_times_ : array of shape = (n_unique_times,)
    Unique time points.</p>

<h2 id="see-also">See also</h2>

<p>survivalist.ensemble.ComponentwiseGradientBoostingSurvivalAnalysis
    Gradient boosting with component-wise least squares as base learner.</p>

<h2 id="references">References</h2>

<div class="footnotes">
<hr />
<ol>
<li id="fn-1">
<p>J. H. Friedman, "Greedy function approximation: A gradient boosting machine,"
The Annals of Statistics, 29(5), 11891232, 2001.&#160;<a href="#fnref-1" class="footnoteBackLink" title="Jump back to footnote 1 in the text.">&#8617;</a></p>
</li>

<li id="fn-2">
<p>J. H. Friedman, "Stochastic gradient boosting,"
Computational Statistics &amp; Data Analysis, 38(4), 367378, 2002.&#160;<a href="#fnref-2" class="footnoteBackLink" title="Jump back to footnote 2 in the text.">&#8617;</a></p>
</li>

<li id="fn-3">
<p>G. Ridgeway, "The state of boosting,"
Computing Science and Statistics, 172181, 1999.&#160;<a href="#fnref-3" class="footnoteBackLink" title="Jump back to footnote 3 in the text.">&#8617;</a></p>
</li>

<li id="fn-4">
<p>Hothorn, T., Bhlmann, P., Dudoit, S., Molinaro, A., van der Laan, M. J.,
"Survival ensembles", Biostatistics, 7(3), 355-73, 2006.&#160;<a href="#fnref-4" class="footnoteBackLink" title="Jump back to footnote 4 in the text.">&#8617;</a></p>
</li>

<li id="fn-5">
<p>K. V. Rashmi and R. Gilad-Bachrach,
"DART: Dropouts meet multiple additive regression trees,"
in 18th International Conference on Artificial Intelligence and Statistics,
2015, 489497.&#160;<a href="#fnref-5" class="footnoteBackLink" title="Jump back to footnote 5 in the text.">&#8617;</a></p>
</li>
</ol>
</div>
</div>


                                <div id="GradientBoostingSurvivalAnalysis.fit" class="classattr">
                                            <input id="GradientBoostingSurvivalAnalysis.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">monitor</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GradientBoostingSurvivalAnalysis.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GradientBoostingSurvivalAnalysis.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GradientBoostingSurvivalAnalysis.fit-1255"><a href="#GradientBoostingSurvivalAnalysis.fit-1255"><span class="linenos">1255</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1256"><a href="#GradientBoostingSurvivalAnalysis.fit-1256"><span class="linenos">1256</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit the gradient boosting model.</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1257"><a href="#GradientBoostingSurvivalAnalysis.fit-1257"><span class="linenos">1257</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1258"><a href="#GradientBoostingSurvivalAnalysis.fit-1258"><span class="linenos">1258</span></a><span class="sd">        Parameters</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1259"><a href="#GradientBoostingSurvivalAnalysis.fit-1259"><span class="linenos">1259</span></a><span class="sd">        ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1260"><a href="#GradientBoostingSurvivalAnalysis.fit-1260"><span class="linenos">1260</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1261"><a href="#GradientBoostingSurvivalAnalysis.fit-1261"><span class="linenos">1261</span></a><span class="sd">            Data matrix</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1262"><a href="#GradientBoostingSurvivalAnalysis.fit-1262"><span class="linenos">1262</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1263"><a href="#GradientBoostingSurvivalAnalysis.fit-1263"><span class="linenos">1263</span></a><span class="sd">        y : structured array, shape = (n_samples,)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1264"><a href="#GradientBoostingSurvivalAnalysis.fit-1264"><span class="linenos">1264</span></a><span class="sd">            A structured array containing the binary event indicator</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1265"><a href="#GradientBoostingSurvivalAnalysis.fit-1265"><span class="linenos">1265</span></a><span class="sd">            as first field, and time of event or time of censoring as</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1266"><a href="#GradientBoostingSurvivalAnalysis.fit-1266"><span class="linenos">1266</span></a><span class="sd">            second field.</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1267"><a href="#GradientBoostingSurvivalAnalysis.fit-1267"><span class="linenos">1267</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1268"><a href="#GradientBoostingSurvivalAnalysis.fit-1268"><span class="linenos">1268</span></a><span class="sd">        sample_weight : array-like, shape = (n_samples,), optional</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1269"><a href="#GradientBoostingSurvivalAnalysis.fit-1269"><span class="linenos">1269</span></a><span class="sd">            Weights given to each sample. If omitted, all samples have weight 1.</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1270"><a href="#GradientBoostingSurvivalAnalysis.fit-1270"><span class="linenos">1270</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1271"><a href="#GradientBoostingSurvivalAnalysis.fit-1271"><span class="linenos">1271</span></a><span class="sd">        monitor : callable, optional</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1272"><a href="#GradientBoostingSurvivalAnalysis.fit-1272"><span class="linenos">1272</span></a><span class="sd">            The monitor is called after each iteration with the current</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1273"><a href="#GradientBoostingSurvivalAnalysis.fit-1273"><span class="linenos">1273</span></a><span class="sd">            iteration, a reference to the estimator and the local variables of</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1274"><a href="#GradientBoostingSurvivalAnalysis.fit-1274"><span class="linenos">1274</span></a><span class="sd">            ``_fit_stages`` as keyword arguments ``callable(i, self,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1275"><a href="#GradientBoostingSurvivalAnalysis.fit-1275"><span class="linenos">1275</span></a><span class="sd">            locals())``. If the callable returns ``True`` the fitting procedure</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1276"><a href="#GradientBoostingSurvivalAnalysis.fit-1276"><span class="linenos">1276</span></a><span class="sd">            is stopped. The monitor can be used for various things such as</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1277"><a href="#GradientBoostingSurvivalAnalysis.fit-1277"><span class="linenos">1277</span></a><span class="sd">            computing held-out estimates, early stopping, model introspect, and</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1278"><a href="#GradientBoostingSurvivalAnalysis.fit-1278"><span class="linenos">1278</span></a><span class="sd">            snapshoting.</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1279"><a href="#GradientBoostingSurvivalAnalysis.fit-1279"><span class="linenos">1279</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1280"><a href="#GradientBoostingSurvivalAnalysis.fit-1280"><span class="linenos">1280</span></a><span class="sd">        Returns</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1281"><a href="#GradientBoostingSurvivalAnalysis.fit-1281"><span class="linenos">1281</span></a><span class="sd">        -------</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1282"><a href="#GradientBoostingSurvivalAnalysis.fit-1282"><span class="linenos">1282</span></a><span class="sd">        self : object</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1283"><a href="#GradientBoostingSurvivalAnalysis.fit-1283"><span class="linenos">1283</span></a><span class="sd">            Returns self.</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1284"><a href="#GradientBoostingSurvivalAnalysis.fit-1284"><span class="linenos">1284</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1285"><a href="#GradientBoostingSurvivalAnalysis.fit-1285"><span class="linenos">1285</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1286"><a href="#GradientBoostingSurvivalAnalysis.fit-1286"><span class="linenos">1286</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1287"><a href="#GradientBoostingSurvivalAnalysis.fit-1287"><span class="linenos">1287</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1288"><a href="#GradientBoostingSurvivalAnalysis.fit-1288"><span class="linenos">1288</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_state</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1289"><a href="#GradientBoostingSurvivalAnalysis.fit-1289"><span class="linenos">1289</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1290"><a href="#GradientBoostingSurvivalAnalysis.fit-1290"><span class="linenos">1290</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1291"><a href="#GradientBoostingSurvivalAnalysis.fit-1291"><span class="linenos">1291</span></a>            <span class="n">X</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1292"><a href="#GradientBoostingSurvivalAnalysis.fit-1292"><span class="linenos">1292</span></a>            <span class="n">ensure_min_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1293"><a href="#GradientBoostingSurvivalAnalysis.fit-1293"><span class="linenos">1293</span></a>            <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1294"><a href="#GradientBoostingSurvivalAnalysis.fit-1294"><span class="linenos">1294</span></a>            <span class="n">accept_sparse</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">,</span> <span class="s2">&quot;coo&quot;</span><span class="p">],</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1295"><a href="#GradientBoostingSurvivalAnalysis.fit-1295"><span class="linenos">1295</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1296"><a href="#GradientBoostingSurvivalAnalysis.fit-1296"><span class="linenos">1296</span></a>        <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1297"><a href="#GradientBoostingSurvivalAnalysis.fit-1297"><span class="linenos">1297</span></a>        <span class="n">event</span><span class="p">,</span> <span class="n">time</span> <span class="o">=</span> <span class="n">check_array_survival</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1298"><a href="#GradientBoostingSurvivalAnalysis.fit-1298"><span class="linenos">1298</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1299"><a href="#GradientBoostingSurvivalAnalysis.fit-1299"><span class="linenos">1299</span></a>        <span class="n">sample_weight_is_none</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1300"><a href="#GradientBoostingSurvivalAnalysis.fit-1300"><span class="linenos">1300</span></a>        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1301"><a href="#GradientBoostingSurvivalAnalysis.fit-1301"><span class="linenos">1301</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1302"><a href="#GradientBoostingSurvivalAnalysis.fit-1302"><span class="linenos">1302</span></a>        <span class="k">if</span> <span class="n">sample_weight_is_none</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1303"><a href="#GradientBoostingSurvivalAnalysis.fit-1303"><span class="linenos">1303</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1304"><a href="#GradientBoostingSurvivalAnalysis.fit-1304"><span class="linenos">1304</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1305"><a href="#GradientBoostingSurvivalAnalysis.fit-1305"><span class="linenos">1305</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1306"><a href="#GradientBoostingSurvivalAnalysis.fit-1306"><span class="linenos">1306</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1307"><a href="#GradientBoostingSurvivalAnalysis.fit-1307"><span class="linenos">1307</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_max_features</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1308"><a href="#GradientBoostingSurvivalAnalysis.fit-1308"><span class="linenos">1308</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1309"><a href="#GradientBoostingSurvivalAnalysis.fit-1309"><span class="linenos">1309</span></a>        <span class="c1"># self.loss is guaranteed to be a string</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1310"><a href="#GradientBoostingSurvivalAnalysis.fit-1310"><span class="linenos">1310</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss</span><span class="p">(</span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1311"><a href="#GradientBoostingSurvivalAnalysis.fit-1311"><span class="linenos">1311</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1312"><a href="#GradientBoostingSurvivalAnalysis.fit-1312"><span class="linenos">1312</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="p">(</span><span class="n">CensoredSquaredLoss</span><span class="p">,</span> <span class="n">IPCWLeastSquaresError</span><span class="p">)):</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1313"><a href="#GradientBoostingSurvivalAnalysis.fit-1313"><span class="linenos">1313</span></a>            <span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1314"><a href="#GradientBoostingSurvivalAnalysis.fit-1314"><span class="linenos">1314</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1315"><a href="#GradientBoostingSurvivalAnalysis.fit-1315"><span class="linenos">1315</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1316"><a href="#GradientBoostingSurvivalAnalysis.fit-1316"><span class="linenos">1316</span></a>            <span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1317"><a href="#GradientBoostingSurvivalAnalysis.fit-1317"><span class="linenos">1317</span></a>                <span class="n">X_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1318"><a href="#GradientBoostingSurvivalAnalysis.fit-1318"><span class="linenos">1318</span></a>                <span class="n">X_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1319"><a href="#GradientBoostingSurvivalAnalysis.fit-1319"><span class="linenos">1319</span></a>                <span class="n">event_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1320"><a href="#GradientBoostingSurvivalAnalysis.fit-1320"><span class="linenos">1320</span></a>                <span class="n">event_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1321"><a href="#GradientBoostingSurvivalAnalysis.fit-1321"><span class="linenos">1321</span></a>                <span class="n">time_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1322"><a href="#GradientBoostingSurvivalAnalysis.fit-1322"><span class="linenos">1322</span></a>                <span class="n">time_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1323"><a href="#GradientBoostingSurvivalAnalysis.fit-1323"><span class="linenos">1323</span></a>                <span class="n">sample_weight_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1324"><a href="#GradientBoostingSurvivalAnalysis.fit-1324"><span class="linenos">1324</span></a>                <span class="n">sample_weight_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1325"><a href="#GradientBoostingSurvivalAnalysis.fit-1325"><span class="linenos">1325</span></a>            <span class="p">)</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1326"><a href="#GradientBoostingSurvivalAnalysis.fit-1326"><span class="linenos">1326</span></a>                <span class="n">X</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1327"><a href="#GradientBoostingSurvivalAnalysis.fit-1327"><span class="linenos">1327</span></a>                <span class="n">event</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1328"><a href="#GradientBoostingSurvivalAnalysis.fit-1328"><span class="linenos">1328</span></a>                <span class="n">time</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1329"><a href="#GradientBoostingSurvivalAnalysis.fit-1329"><span class="linenos">1329</span></a>                <span class="n">sample_weight</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1330"><a href="#GradientBoostingSurvivalAnalysis.fit-1330"><span class="linenos">1330</span></a>                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1331"><a href="#GradientBoostingSurvivalAnalysis.fit-1331"><span class="linenos">1331</span></a>                <span class="n">test_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_fraction</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1332"><a href="#GradientBoostingSurvivalAnalysis.fit-1332"><span class="linenos">1332</span></a>                <span class="n">stratify</span><span class="o">=</span><span class="n">event</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1333"><a href="#GradientBoostingSurvivalAnalysis.fit-1333"><span class="linenos">1333</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1334"><a href="#GradientBoostingSurvivalAnalysis.fit-1334"><span class="linenos">1334</span></a>            <span class="n">y_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1335"><a href="#GradientBoostingSurvivalAnalysis.fit-1335"><span class="linenos">1335</span></a>                <span class="nb">zip</span><span class="p">(</span><span class="n">event_val</span><span class="p">,</span> <span class="n">time_val</span><span class="p">),</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1336"><a href="#GradientBoostingSurvivalAnalysis.fit-1336"><span class="linenos">1336</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;event&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1337"><a href="#GradientBoostingSurvivalAnalysis.fit-1337"><span class="linenos">1337</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1338"><a href="#GradientBoostingSurvivalAnalysis.fit-1338"><span class="linenos">1338</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1339"><a href="#GradientBoostingSurvivalAnalysis.fit-1339"><span class="linenos">1339</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">sample_weight_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1340"><a href="#GradientBoostingSurvivalAnalysis.fit-1340"><span class="linenos">1340</span></a>            <span class="n">event_train</span><span class="p">,</span> <span class="n">time_train</span> <span class="o">=</span> <span class="n">event</span><span class="p">,</span> <span class="n">time</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1341"><a href="#GradientBoostingSurvivalAnalysis.fit-1341"><span class="linenos">1341</span></a>            <span class="n">X_val</span> <span class="o">=</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">sample_weight_val</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1342"><a href="#GradientBoostingSurvivalAnalysis.fit-1342"><span class="linenos">1342</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1343"><a href="#GradientBoostingSurvivalAnalysis.fit-1343"><span class="linenos">1343</span></a>        <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1344"><a href="#GradientBoostingSurvivalAnalysis.fit-1344"><span class="linenos">1344</span></a>            <span class="nb">zip</span><span class="p">(</span><span class="n">event_train</span><span class="p">,</span> <span class="n">time_train</span><span class="p">),</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1345"><a href="#GradientBoostingSurvivalAnalysis.fit-1345"><span class="linenos">1345</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;event&quot;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1346"><a href="#GradientBoostingSurvivalAnalysis.fit-1346"><span class="linenos">1346</span></a>        <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1347"><a href="#GradientBoostingSurvivalAnalysis.fit-1347"><span class="linenos">1347</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1348"><a href="#GradientBoostingSurvivalAnalysis.fit-1348"><span class="linenos">1348</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1349"><a href="#GradientBoostingSurvivalAnalysis.fit-1349"><span class="linenos">1349</span></a>        <span class="c1"># First time calling fit.</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1350"><a href="#GradientBoostingSurvivalAnalysis.fit-1350"><span class="linenos">1350</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_fitted</span><span class="p">():</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1351"><a href="#GradientBoostingSurvivalAnalysis.fit-1351"><span class="linenos">1351</span></a>            <span class="c1"># init state</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1352"><a href="#GradientBoostingSurvivalAnalysis.fit-1352"><span class="linenos">1352</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_init_state</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1353"><a href="#GradientBoostingSurvivalAnalysis.fit-1353"><span class="linenos">1353</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1354"><a href="#GradientBoostingSurvivalAnalysis.fit-1354"><span class="linenos">1354</span></a>            <span class="n">raw_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1355"><a href="#GradientBoostingSurvivalAnalysis.fit-1355"><span class="linenos">1355</span></a>                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span><span class="p">),</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1356"><a href="#GradientBoostingSurvivalAnalysis.fit-1356"><span class="linenos">1356</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1357"><a href="#GradientBoostingSurvivalAnalysis.fit-1357"><span class="linenos">1357</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1358"><a href="#GradientBoostingSurvivalAnalysis.fit-1358"><span class="linenos">1358</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1359"><a href="#GradientBoostingSurvivalAnalysis.fit-1359"><span class="linenos">1359</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1360"><a href="#GradientBoostingSurvivalAnalysis.fit-1360"><span class="linenos">1360</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1361"><a href="#GradientBoostingSurvivalAnalysis.fit-1361"><span class="linenos">1361</span></a>            <span class="c1"># The rng state must be preserved if warm_start is True</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1362"><a href="#GradientBoostingSurvivalAnalysis.fit-1362"><span class="linenos">1362</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1363"><a href="#GradientBoostingSurvivalAnalysis.fit-1363"><span class="linenos">1363</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1364"><a href="#GradientBoostingSurvivalAnalysis.fit-1364"><span class="linenos">1364</span></a>        <span class="c1"># warm start: this is not the first time fit was called</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1365"><a href="#GradientBoostingSurvivalAnalysis.fit-1365"><span class="linenos">1365</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1366"><a href="#GradientBoostingSurvivalAnalysis.fit-1366"><span class="linenos">1366</span></a>            <span class="c1"># add more estimators to fitted model</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1367"><a href="#GradientBoostingSurvivalAnalysis.fit-1367"><span class="linenos">1367</span></a>            <span class="c1"># invariant: warm_start = True</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1368"><a href="#GradientBoostingSurvivalAnalysis.fit-1368"><span class="linenos">1368</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1369"><a href="#GradientBoostingSurvivalAnalysis.fit-1369"><span class="linenos">1369</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1370"><a href="#GradientBoostingSurvivalAnalysis.fit-1370"><span class="linenos">1370</span></a>                    <span class="s2">&quot;n_estimators=</span><span class="si">%d</span><span class="s2"> must be larger or equal to &quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1371"><a href="#GradientBoostingSurvivalAnalysis.fit-1371"><span class="linenos">1371</span></a>                    <span class="s2">&quot;estimators_.shape[0]=</span><span class="si">%d</span><span class="s2"> when &quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1372"><a href="#GradientBoostingSurvivalAnalysis.fit-1372"><span class="linenos">1372</span></a>                    <span class="s2">&quot;warm_start==True&quot;</span> <span class="o">%</span> <span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1373"><a href="#GradientBoostingSurvivalAnalysis.fit-1373"><span class="linenos">1373</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1374"><a href="#GradientBoostingSurvivalAnalysis.fit-1374"><span class="linenos">1374</span></a>                <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1375"><a href="#GradientBoostingSurvivalAnalysis.fit-1375"><span class="linenos">1375</span></a>            <span class="n">begin_at_stage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1376"><a href="#GradientBoostingSurvivalAnalysis.fit-1376"><span class="linenos">1376</span></a>            <span class="c1"># The requirements of _raw_predict</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1377"><a href="#GradientBoostingSurvivalAnalysis.fit-1377"><span class="linenos">1377</span></a>            <span class="c1"># are more constrained than fit. It accepts only CSR</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1378"><a href="#GradientBoostingSurvivalAnalysis.fit-1378"><span class="linenos">1378</span></a>            <span class="c1"># matrices. Finite values have already been checked in _validate_data.</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1379"><a href="#GradientBoostingSurvivalAnalysis.fit-1379"><span class="linenos">1379</span></a>            <span class="n">X_train</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1380"><a href="#GradientBoostingSurvivalAnalysis.fit-1380"><span class="linenos">1380</span></a>                <span class="n">X_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1381"><a href="#GradientBoostingSurvivalAnalysis.fit-1381"><span class="linenos">1381</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1382"><a href="#GradientBoostingSurvivalAnalysis.fit-1382"><span class="linenos">1382</span></a>                <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1383"><a href="#GradientBoostingSurvivalAnalysis.fit-1383"><span class="linenos">1383</span></a>                <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1384"><a href="#GradientBoostingSurvivalAnalysis.fit-1384"><span class="linenos">1384</span></a>                <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1385"><a href="#GradientBoostingSurvivalAnalysis.fit-1385"><span class="linenos">1385</span></a>            <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1386"><a href="#GradientBoostingSurvivalAnalysis.fit-1386"><span class="linenos">1386</span></a>            <span class="n">raw_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1387"><a href="#GradientBoostingSurvivalAnalysis.fit-1387"><span class="linenos">1387</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_resize_state</span><span class="p">()</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1388"><a href="#GradientBoostingSurvivalAnalysis.fit-1388"><span class="linenos">1388</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1389"><a href="#GradientBoostingSurvivalAnalysis.fit-1389"><span class="linenos">1389</span></a>            <span class="c1"># apply dropout to last stage of previous fit</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1390"><a href="#GradientBoostingSurvivalAnalysis.fit-1390"><span class="linenos">1390</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1391"><a href="#GradientBoostingSurvivalAnalysis.fit-1391"><span class="linenos">1391</span></a>                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_trees_per_iteration_</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1392"><a href="#GradientBoostingSurvivalAnalysis.fit-1392"><span class="linenos">1392</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_dropout</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1393"><a href="#GradientBoostingSurvivalAnalysis.fit-1393"><span class="linenos">1393</span></a>                        <span class="c1"># pylint: disable-next=access-member-before-definition</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1394"><a href="#GradientBoostingSurvivalAnalysis.fit-1394"><span class="linenos">1394</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1395"><a href="#GradientBoostingSurvivalAnalysis.fit-1395"><span class="linenos">1395</span></a>                        <span class="n">X_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1396"><a href="#GradientBoostingSurvivalAnalysis.fit-1396"><span class="linenos">1396</span></a>                        <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1397"><a href="#GradientBoostingSurvivalAnalysis.fit-1397"><span class="linenos">1397</span></a>                        <span class="n">k</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1398"><a href="#GradientBoostingSurvivalAnalysis.fit-1398"><span class="linenos">1398</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1399"><a href="#GradientBoostingSurvivalAnalysis.fit-1399"><span class="linenos">1399</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1400"><a href="#GradientBoostingSurvivalAnalysis.fit-1400"><span class="linenos">1400</span></a>                    <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1401"><a href="#GradientBoostingSurvivalAnalysis.fit-1401"><span class="linenos">1401</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1402"><a href="#GradientBoostingSurvivalAnalysis.fit-1402"><span class="linenos">1402</span></a>        <span class="n">scale</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_scale&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1403"><a href="#GradientBoostingSurvivalAnalysis.fit-1403"><span class="linenos">1403</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1404"><a href="#GradientBoostingSurvivalAnalysis.fit-1404"><span class="linenos">1404</span></a>        <span class="c1"># fit the boosting stages</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1405"><a href="#GradientBoostingSurvivalAnalysis.fit-1405"><span class="linenos">1405</span></a>        <span class="n">n_stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_stages</span><span class="p">(</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1406"><a href="#GradientBoostingSurvivalAnalysis.fit-1406"><span class="linenos">1406</span></a>            <span class="n">X_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1407"><a href="#GradientBoostingSurvivalAnalysis.fit-1407"><span class="linenos">1407</span></a>            <span class="n">y_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1408"><a href="#GradientBoostingSurvivalAnalysis.fit-1408"><span class="linenos">1408</span></a>            <span class="n">raw_predictions</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1409"><a href="#GradientBoostingSurvivalAnalysis.fit-1409"><span class="linenos">1409</span></a>            <span class="n">sample_weight_train</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1410"><a href="#GradientBoostingSurvivalAnalysis.fit-1410"><span class="linenos">1410</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1411"><a href="#GradientBoostingSurvivalAnalysis.fit-1411"><span class="linenos">1411</span></a>            <span class="n">X_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1412"><a href="#GradientBoostingSurvivalAnalysis.fit-1412"><span class="linenos">1412</span></a>            <span class="n">y_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1413"><a href="#GradientBoostingSurvivalAnalysis.fit-1413"><span class="linenos">1413</span></a>            <span class="n">sample_weight_val</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1414"><a href="#GradientBoostingSurvivalAnalysis.fit-1414"><span class="linenos">1414</span></a>            <span class="n">scale</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1415"><a href="#GradientBoostingSurvivalAnalysis.fit-1415"><span class="linenos">1415</span></a>            <span class="n">begin_at_stage</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1416"><a href="#GradientBoostingSurvivalAnalysis.fit-1416"><span class="linenos">1416</span></a>            <span class="n">monitor</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1417"><a href="#GradientBoostingSurvivalAnalysis.fit-1417"><span class="linenos">1417</span></a>        <span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1418"><a href="#GradientBoostingSurvivalAnalysis.fit-1418"><span class="linenos">1418</span></a>        <span class="c1"># change shape of arrays after fit (early-stopping or additional tests)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1419"><a href="#GradientBoostingSurvivalAnalysis.fit-1419"><span class="linenos">1419</span></a>        <span class="k">if</span> <span class="n">n_stages</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1420"><a href="#GradientBoostingSurvivalAnalysis.fit-1420"><span class="linenos">1420</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_shrink_state</span><span class="p">(</span><span class="n">n_stages</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1421"><a href="#GradientBoostingSurvivalAnalysis.fit-1421"><span class="linenos">1421</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators_</span> <span class="o">=</span> <span class="n">n_stages</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1422"><a href="#GradientBoostingSurvivalAnalysis.fit-1422"><span class="linenos">1422</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1423"><a href="#GradientBoostingSurvivalAnalysis.fit-1423"><span class="linenos">1423</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_baseline_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">event_train</span><span class="p">,</span> <span class="n">time_train</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1424"><a href="#GradientBoostingSurvivalAnalysis.fit-1424"><span class="linenos">1424</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.fit-1425"><a href="#GradientBoostingSurvivalAnalysis.fit-1425"><span class="linenos">1425</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Fit the gradient boosting model.</p>

<h2 id="parameters">Parameters</h2>

<p>X : array-like, shape = (n_samples, n_features)
    Data matrix</p>

<p>y : structured array, shape = (n_samples,)
    A structured array containing the binary event indicator
    as first field, and time of event or time of censoring as
    second field.</p>

<p>sample_weight : array-like, shape = (n_samples,), optional
    Weights given to each sample. If omitted, all samples have weight 1.</p>

<p>monitor : callable, optional
    The monitor is called after each iteration with the current
    iteration, a reference to the estimator and the local variables of
    <code>_fit_stages</code> as keyword arguments <code>callable(i, self,
    locals())</code>. If the callable returns <code>True</code> the fitting procedure
    is stopped. The monitor can be used for various things such as
    computing held-out estimates, early stopping, model introspect, and
    snapshoting.</p>

<h2 id="returns">Returns</h2>

<p>self : object
    Returns self.</p>
</div>


                                </div>
                                <div id="GradientBoostingSurvivalAnalysis.predict" class="classattr">
                                            <input id="GradientBoostingSurvivalAnalysis.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GradientBoostingSurvivalAnalysis.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GradientBoostingSurvivalAnalysis.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GradientBoostingSurvivalAnalysis.predict-1481"><a href="#GradientBoostingSurvivalAnalysis.predict-1481"><span class="linenos">1481</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1482"><a href="#GradientBoostingSurvivalAnalysis.predict-1482"><span class="linenos">1482</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict risk scores.</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1483"><a href="#GradientBoostingSurvivalAnalysis.predict-1483"><span class="linenos">1483</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1484"><a href="#GradientBoostingSurvivalAnalysis.predict-1484"><span class="linenos">1484</span></a><span class="sd">        If `loss=&#39;coxph&#39;`, predictions can be interpreted as log hazard ratio</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1485"><a href="#GradientBoostingSurvivalAnalysis.predict-1485"><span class="linenos">1485</span></a><span class="sd">        similar to the linear predictor of a Cox proportional hazards</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1486"><a href="#GradientBoostingSurvivalAnalysis.predict-1486"><span class="linenos">1486</span></a><span class="sd">        model. If `loss=&#39;squared&#39;` or `loss=&#39;ipcwls&#39;`, predictions are the</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1487"><a href="#GradientBoostingSurvivalAnalysis.predict-1487"><span class="linenos">1487</span></a><span class="sd">        time to event.</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1488"><a href="#GradientBoostingSurvivalAnalysis.predict-1488"><span class="linenos">1488</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1489"><a href="#GradientBoostingSurvivalAnalysis.predict-1489"><span class="linenos">1489</span></a><span class="sd">        Parameters</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1490"><a href="#GradientBoostingSurvivalAnalysis.predict-1490"><span class="linenos">1490</span></a><span class="sd">        ----------</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1491"><a href="#GradientBoostingSurvivalAnalysis.predict-1491"><span class="linenos">1491</span></a><span class="sd">        X : array-like, shape = (n_samples, n_features)</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1492"><a href="#GradientBoostingSurvivalAnalysis.predict-1492"><span class="linenos">1492</span></a><span class="sd">            The input samples.</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1493"><a href="#GradientBoostingSurvivalAnalysis.predict-1493"><span class="linenos">1493</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1494"><a href="#GradientBoostingSurvivalAnalysis.predict-1494"><span class="linenos">1494</span></a><span class="sd">        Returns</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1495"><a href="#GradientBoostingSurvivalAnalysis.predict-1495"><span class="linenos">1495</span></a><span class="sd">        -------</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1496"><a href="#GradientBoostingSurvivalAnalysis.predict-1496"><span class="linenos">1496</span></a><span class="sd">        y : ndarray, shape = (n_samples,)</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1497"><a href="#GradientBoostingSurvivalAnalysis.predict-1497"><span class="linenos">1497</span></a><span class="sd">            The risk scores.</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1498"><a href="#GradientBoostingSurvivalAnalysis.predict-1498"><span class="linenos">1498</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1499"><a href="#GradientBoostingSurvivalAnalysis.predict-1499"><span class="linenos">1499</span></a>        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;estimators_&quot;</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1500"><a href="#GradientBoostingSurvivalAnalysis.predict-1500"><span class="linenos">1500</span></a>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1501"><a href="#GradientBoostingSurvivalAnalysis.predict-1501"><span class="linenos">1501</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1502"><a href="#GradientBoostingSurvivalAnalysis.predict-1502"><span class="linenos">1502</span></a>                                <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">)</span>
</span><span id="GradientBoostingSurvivalAnalysis.predict-1503"><a href="#GradientBoostingSurvivalAnalysis.predict-1503"><span class="linenos">1503</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict risk scores.</p>

<p>If <code>loss='coxph'</code>, predictions can be interpreted as log hazard ratio
similar to the linear predictor of a Cox proportional hazards
model. If <code>loss='squared'</code> or <code>loss='ipcwls'</code>, predictions are the
time to event.</p>

<h2 id="parameters">Parameters</h2>

<p>X : array-like, shape = (n_samples, n_features)
    The input samples.</p>

<h2 id="returns">Returns</h2>

<p>y : ndarray, shape = (n_samples,)
    The risk scores.</p>
</div>


                                </div>
                        
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>