<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.0"/>
    <title>nnetsauce.nonconformist API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! theme.css */:root{--pdoc-background:#212529;}.pdoc{--text:#f7f7f7;--muted:#9d9d9d;--link:#58a6ff;--link-hover:#3989ff;--code:#333;--active:#555;--accent:#343434;--accent2:#555;--nav-hover:rgba(0, 0, 0, 0.1);--name:#77C1FF;--def:#0cdd0c;--annotation:#00c037;}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#49483e}.pdoc-code{background:#272822; color:#f8f8f2}.pdoc-code .c{color:#75715e}.pdoc-code .err{color:#960050; background-color:#1e0010}.pdoc-code .esc{color:#f8f8f2}.pdoc-code .g{color:#f8f8f2}.pdoc-code .k{color:#66d9ef}.pdoc-code .l{color:#ae81ff}.pdoc-code .n{color:#f8f8f2}.pdoc-code .o{color:#f92672}.pdoc-code .x{color:#f8f8f2}.pdoc-code .p{color:#f8f8f2}.pdoc-code .ch{color:#75715e}.pdoc-code .cm{color:#75715e}.pdoc-code .cp{color:#75715e}.pdoc-code .cpf{color:#75715e}.pdoc-code .c1{color:#75715e}.pdoc-code .cs{color:#75715e}.pdoc-code .gd{color:#f92672}.pdoc-code .ge{color:#f8f8f2; font-style:italic}.pdoc-code .gr{color:#f8f8f2}.pdoc-code .gh{color:#f8f8f2}.pdoc-code .gi{color:#a6e22e}.pdoc-code .go{color:#66d9ef}.pdoc-code .gp{color:#f92672; font-weight:bold}.pdoc-code .gs{color:#f8f8f2; font-weight:bold}.pdoc-code .gu{color:#75715e}.pdoc-code .gt{color:#f8f8f2}.pdoc-code .kc{color:#66d9ef}.pdoc-code .kd{color:#66d9ef}.pdoc-code .kn{color:#f92672}.pdoc-code .kp{color:#66d9ef}.pdoc-code .kr{color:#66d9ef}.pdoc-code .kt{color:#66d9ef}.pdoc-code .ld{color:#e6db74}.pdoc-code .m{color:#ae81ff}.pdoc-code .s{color:#e6db74}.pdoc-code .na{color:#a6e22e}.pdoc-code .nb{color:#f8f8f2}.pdoc-code .nc{color:#a6e22e}.pdoc-code .no{color:#66d9ef}.pdoc-code .nd{color:#a6e22e}.pdoc-code .ni{color:#f8f8f2}.pdoc-code .ne{color:#a6e22e}.pdoc-code .nf{color:#a6e22e}.pdoc-code .nl{color:#f8f8f2}.pdoc-code .nn{color:#f8f8f2}.pdoc-code .nx{color:#a6e22e}.pdoc-code .py{color:#f8f8f2}.pdoc-code .nt{color:#f92672}.pdoc-code .nv{color:#f8f8f2}.pdoc-code .ow{color:#f92672}.pdoc-code .w{color:#f8f8f2}.pdoc-code .mb{color:#ae81ff}.pdoc-code .mf{color:#ae81ff}.pdoc-code .mh{color:#ae81ff}.pdoc-code .mi{color:#ae81ff}.pdoc-code .mo{color:#ae81ff}.pdoc-code .sa{color:#e6db74}.pdoc-code .sb{color:#e6db74}.pdoc-code .sc{color:#e6db74}.pdoc-code .dl{color:#e6db74}.pdoc-code .sd{color:#e6db74}.pdoc-code .s2{color:#e6db74}.pdoc-code .se{color:#ae81ff}.pdoc-code .sh{color:#e6db74}.pdoc-code .si{color:#e6db74}.pdoc-code .sx{color:#e6db74}.pdoc-code .sr{color:#e6db74}.pdoc-code .s1{color:#e6db74}.pdoc-code .ss{color:#e6db74}.pdoc-code .bp{color:#f8f8f2}.pdoc-code .fm{color:#a6e22e}.pdoc-code .vc{color:#f8f8f2}.pdoc-code .vg{color:#f8f8f2}.pdoc-code .vi{color:#f8f8f2}.pdoc-code .vm{color:#f8f8f2}</style>
    <style>/*! theme.css */:root{--pdoc-background:#212529;}.pdoc{--text:#f7f7f7;--muted:#9d9d9d;--link:#58a6ff;--link-hover:#3989ff;--code:#333;--active:#555;--accent:#343434;--accent2:#555;--nav-hover:rgba(0, 0, 0, 0.1);--name:#77C1FF;--def:#0cdd0c;--annotation:#00c037;}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#49483e}.pdoc-code{background:#272822; color:#f8f8f2}.pdoc-code .c{color:#75715e}.pdoc-code .err{color:#960050; background-color:#1e0010}.pdoc-code .esc{color:#f8f8f2}.pdoc-code .g{color:#f8f8f2}.pdoc-code .k{color:#66d9ef}.pdoc-code .l{color:#ae81ff}.pdoc-code .n{color:#f8f8f2}.pdoc-code .o{color:#f92672}.pdoc-code .x{color:#f8f8f2}.pdoc-code .p{color:#f8f8f2}.pdoc-code .ch{color:#75715e}.pdoc-code .cm{color:#75715e}.pdoc-code .cp{color:#75715e}.pdoc-code .cpf{color:#75715e}.pdoc-code .c1{color:#75715e}.pdoc-code .cs{color:#75715e}.pdoc-code .gd{color:#f92672}.pdoc-code .ge{color:#f8f8f2; font-style:italic}.pdoc-code .gr{color:#f8f8f2}.pdoc-code .gh{color:#f8f8f2}.pdoc-code .gi{color:#a6e22e}.pdoc-code .go{color:#66d9ef}.pdoc-code .gp{color:#f92672; font-weight:bold}.pdoc-code .gs{color:#f8f8f2; font-weight:bold}.pdoc-code .gu{color:#75715e}.pdoc-code .gt{color:#f8f8f2}.pdoc-code .kc{color:#66d9ef}.pdoc-code .kd{color:#66d9ef}.pdoc-code .kn{color:#f92672}.pdoc-code .kp{color:#66d9ef}.pdoc-code .kr{color:#66d9ef}.pdoc-code .kt{color:#66d9ef}.pdoc-code .ld{color:#e6db74}.pdoc-code .m{color:#ae81ff}.pdoc-code .s{color:#e6db74}.pdoc-code .na{color:#a6e22e}.pdoc-code .nb{color:#f8f8f2}.pdoc-code .nc{color:#a6e22e}.pdoc-code .no{color:#66d9ef}.pdoc-code .nd{color:#a6e22e}.pdoc-code .ni{color:#f8f8f2}.pdoc-code .ne{color:#a6e22e}.pdoc-code .nf{color:#a6e22e}.pdoc-code .nl{color:#f8f8f2}.pdoc-code .nn{color:#f8f8f2}.pdoc-code .nx{color:#a6e22e}.pdoc-code .py{color:#f8f8f2}.pdoc-code .nt{color:#f92672}.pdoc-code .nv{color:#f8f8f2}.pdoc-code .ow{color:#f92672}.pdoc-code .w{color:#f8f8f2}.pdoc-code .mb{color:#ae81ff}.pdoc-code .mf{color:#ae81ff}.pdoc-code .mh{color:#ae81ff}.pdoc-code .mi{color:#ae81ff}.pdoc-code .mo{color:#ae81ff}.pdoc-code .sa{color:#e6db74}.pdoc-code .sb{color:#e6db74}.pdoc-code .sc{color:#e6db74}.pdoc-code .dl{color:#e6db74}.pdoc-code .sd{color:#e6db74}.pdoc-code .s2{color:#e6db74}.pdoc-code .se{color:#ae81ff}.pdoc-code .sh{color:#e6db74}.pdoc-code .si{color:#e6db74}.pdoc-code .sx{color:#e6db74}.pdoc-code .sr{color:#e6db74}.pdoc-code .s1{color:#e6db74}.pdoc-code .ss{color:#e6db74}.pdoc-code .bp{color:#f8f8f2}.pdoc-code .fm{color:#a6e22e}.pdoc-code .vc{color:#f8f8f2}.pdoc-code .vg{color:#f8f8f2}.pdoc-code .vi{color:#f8f8f2}.pdoc-code .vm{color:#f8f8f2}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../nnetsauce.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;nnetsauce</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>            
                <ul class="memberlist">
            <li>
                    <a class="class" href="#AbsErrorErrFunc">AbsErrorErrFunc</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#MarginErrFunc">MarginErrFunc</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#QuantileRegErrFunc">QuantileRegErrFunc</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#RegressorAdapter">RegressorAdapter</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#ClassifierAdapter">ClassifierAdapter</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#RegressorNc">RegressorNc</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#ClassifierNc">ClassifierNc</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#RegressorNormalizer">RegressorNormalizer</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#IcpRegressor">IcpRegressor</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#IcpClassifier">IcpClassifier</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#TcpClassifier">TcpClassifier</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../nnetsauce.html">nnetsauce</a><wbr>.nonconformist    </h1>

                        <div class="docstring"><p>docstring</p>
</div>

                        <input id="mod-nonconformist-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-nonconformist-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos"> 1</span></a><span class="ch">#!/usr/bin/env python</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos"> 2</span></a>
</span><span id="L-3"><a href="#L-3"><span class="linenos"> 3</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos"> 4</span></a><span class="sd">docstring</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos"> 5</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos"> 6</span></a>
</span><span id="L-7"><a href="#L-7"><span class="linenos"> 7</span></a><span class="c1"># Authors: Henrik Linusson</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos"> 8</span></a><span class="c1"># Yaniv Romano modified np.py file to include CQR</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos"> 9</span></a><span class="c1"># T. Moudiki modified __init__.py to import classes</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">10</span></a>
</span><span id="L-11"><a href="#L-11"><span class="linenos">11</span></a><span class="c1"># __version__ = &#39;2.1.0&#39;</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">12</span></a>
</span><span id="L-13"><a href="#L-13"><span class="linenos">13</span></a><span class="kn">from</span> <span class="nn">.nc</span> <span class="kn">import</span> <span class="p">(</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">14</span></a>    <span class="n">AbsErrorErrFunc</span><span class="p">,</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos">15</span></a>    <span class="n">QuantileRegErrFunc</span><span class="p">,</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos">16</span></a>    <span class="n">RegressorNc</span><span class="p">,</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos">17</span></a>    <span class="n">RegressorNormalizer</span><span class="p">,</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos">18</span></a><span class="p">)</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos">19</span></a><span class="kn">from</span> <span class="nn">.cp</span> <span class="kn">import</span> <span class="n">IcpRegressor</span><span class="p">,</span> <span class="n">TcpClassifier</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos">20</span></a><span class="kn">from</span> <span class="nn">.icp</span> <span class="kn">import</span> <span class="n">IcpClassifier</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos">21</span></a><span class="kn">from</span> <span class="nn">.nc</span> <span class="kn">import</span> <span class="n">ClassifierNc</span><span class="p">,</span> <span class="n">MarginErrFunc</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos">22</span></a><span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">RegressorAdapter</span><span class="p">,</span> <span class="n">ClassifierAdapter</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos">23</span></a>
</span><span id="L-24"><a href="#L-24"><span class="linenos">24</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos">25</span></a>    <span class="s2">&quot;AbsErrorErrFunc&quot;</span><span class="p">,</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos">26</span></a>    <span class="s2">&quot;MarginErrFunc&quot;</span><span class="p">,</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos">27</span></a>    <span class="s2">&quot;QuantileRegErrFunc&quot;</span><span class="p">,</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos">28</span></a>    <span class="s2">&quot;RegressorAdapter&quot;</span><span class="p">,</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos">29</span></a>    <span class="s2">&quot;ClassifierAdapter&quot;</span><span class="p">,</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos">30</span></a>    <span class="s2">&quot;RegressorNc&quot;</span><span class="p">,</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos">31</span></a>    <span class="s2">&quot;ClassifierNc&quot;</span><span class="p">,</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos">32</span></a>    <span class="s2">&quot;RegressorNormalizer&quot;</span><span class="p">,</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos">33</span></a>    <span class="s2">&quot;IcpRegressor&quot;</span><span class="p">,</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos">34</span></a>    <span class="s2">&quot;IcpClassifier&quot;</span><span class="p">,</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos">35</span></a>    <span class="s2">&quot;TcpClassifier&quot;</span><span class="p">,</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos">36</span></a><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="AbsErrorErrFunc">
                            <input id="AbsErrorErrFunc-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">AbsErrorErrFunc</span><wbr>(<span class="base">nnetsauce.nonconformist.nc.RegressionErrFunc</span>):

                <label class="view-source-button" for="AbsErrorErrFunc-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AbsErrorErrFunc"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AbsErrorErrFunc-135"><a href="#AbsErrorErrFunc-135"><span class="linenos">135</span></a><span class="k">class</span> <span class="nc">AbsErrorErrFunc</span><span class="p">(</span><span class="n">RegressionErrFunc</span><span class="p">):</span>
</span><span id="AbsErrorErrFunc-136"><a href="#AbsErrorErrFunc-136"><span class="linenos">136</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculates absolute error nonconformity for regression problems.&quot;&quot;&quot;</span>
</span><span id="AbsErrorErrFunc-137"><a href="#AbsErrorErrFunc-137"><span class="linenos">137</span></a>
</span><span id="AbsErrorErrFunc-138"><a href="#AbsErrorErrFunc-138"><span class="linenos">138</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AbsErrorErrFunc-139"><a href="#AbsErrorErrFunc-139"><span class="linenos">139</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">AbsErrorErrFunc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="AbsErrorErrFunc-140"><a href="#AbsErrorErrFunc-140"><span class="linenos">140</span></a>
</span><span id="AbsErrorErrFunc-141"><a href="#AbsErrorErrFunc-141"><span class="linenos">141</span></a>    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="AbsErrorErrFunc-142"><a href="#AbsErrorErrFunc-142"><span class="linenos">142</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
</span><span id="AbsErrorErrFunc-143"><a href="#AbsErrorErrFunc-143"><span class="linenos">143</span></a>
</span><span id="AbsErrorErrFunc-144"><a href="#AbsErrorErrFunc-144"><span class="linenos">144</span></a>    <span class="k">def</span> <span class="nf">apply_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="n">significance</span><span class="p">):</span>
</span><span id="AbsErrorErrFunc-145"><a href="#AbsErrorErrFunc-145"><span class="linenos">145</span></a>        <span class="n">nc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">nc</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="AbsErrorErrFunc-146"><a href="#AbsErrorErrFunc-146"><span class="linenos">146</span></a>        <span class="n">border</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">significance</span> <span class="o">*</span> <span class="p">(</span><span class="n">nc</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)))</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="AbsErrorErrFunc-147"><a href="#AbsErrorErrFunc-147"><span class="linenos">147</span></a>        <span class="c1"># TODO: should probably warn against too few calibration examples</span>
</span><span id="AbsErrorErrFunc-148"><a href="#AbsErrorErrFunc-148"><span class="linenos">148</span></a>        <span class="n">border</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">border</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">nc</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="AbsErrorErrFunc-149"><a href="#AbsErrorErrFunc-149"><span class="linenos">149</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">nc</span><span class="p">[</span><span class="n">border</span><span class="p">],</span> <span class="n">nc</span><span class="p">[</span><span class="n">border</span><span class="p">]])</span>
</span></pre></div>


            <div class="docstring"><p>Calculates absolute error nonconformity for regression problems.</p>
</div>


                        
                </section>
                <section id="MarginErrFunc">
                            <input id="MarginErrFunc-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">MarginErrFunc</span><wbr>(<span class="base">nnetsauce.nonconformist.nc.ClassificationErrFunc</span>):

                <label class="view-source-button" for="MarginErrFunc-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MarginErrFunc"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MarginErrFunc-116"><a href="#MarginErrFunc-116"><span class="linenos">116</span></a><span class="k">class</span> <span class="nc">MarginErrFunc</span><span class="p">(</span><span class="n">ClassificationErrFunc</span><span class="p">):</span>
</span><span id="MarginErrFunc-117"><a href="#MarginErrFunc-117"><span class="linenos">117</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MarginErrFunc-118"><a href="#MarginErrFunc-118"><span class="linenos">118</span></a><span class="sd">    Calculates the margin error.</span>
</span><span id="MarginErrFunc-119"><a href="#MarginErrFunc-119"><span class="linenos">119</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="MarginErrFunc-120"><a href="#MarginErrFunc-120"><span class="linenos">120</span></a>
</span><span id="MarginErrFunc-121"><a href="#MarginErrFunc-121"><span class="linenos">121</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="MarginErrFunc-122"><a href="#MarginErrFunc-122"><span class="linenos">122</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">MarginErrFunc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="MarginErrFunc-123"><a href="#MarginErrFunc-123"><span class="linenos">123</span></a>
</span><span id="MarginErrFunc-124"><a href="#MarginErrFunc-124"><span class="linenos">124</span></a>    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="MarginErrFunc-125"><a href="#MarginErrFunc-125"><span class="linenos">125</span></a>        <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="MarginErrFunc-126"><a href="#MarginErrFunc-126"><span class="linenos">126</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
</span><span id="MarginErrFunc-127"><a href="#MarginErrFunc-127"><span class="linenos">127</span></a>            <span class="k">if</span> <span class="n">y_</span> <span class="o">&gt;=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
</span><span id="MarginErrFunc-128"><a href="#MarginErrFunc-128"><span class="linenos">128</span></a>                <span class="n">prob</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MarginErrFunc-129"><a href="#MarginErrFunc-129"><span class="linenos">129</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="MarginErrFunc-130"><a href="#MarginErrFunc-130"><span class="linenos">130</span></a>                <span class="n">prob</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">y_</span><span class="p">)]</span>
</span><span id="MarginErrFunc-131"><a href="#MarginErrFunc-131"><span class="linenos">131</span></a>                <span class="n">prediction</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">y_</span><span class="p">)]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="MarginErrFunc-132"><a href="#MarginErrFunc-132"><span class="linenos">132</span></a>        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">-</span> <span class="p">((</span><span class="n">prob</span> <span class="o">-</span> <span class="n">prediction</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Calculates the margin error.</p>
</div>


                        
                </section>
                <section id="QuantileRegErrFunc">
                            <input id="QuantileRegErrFunc-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">QuantileRegErrFunc</span><wbr>(<span class="base">nnetsauce.nonconformist.nc.RegressionErrFunc</span>):

                <label class="view-source-button" for="QuantileRegErrFunc-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#QuantileRegErrFunc"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="QuantileRegErrFunc-178"><a href="#QuantileRegErrFunc-178"><span class="linenos">178</span></a><span class="k">class</span> <span class="nc">QuantileRegErrFunc</span><span class="p">(</span><span class="n">RegressionErrFunc</span><span class="p">):</span>
</span><span id="QuantileRegErrFunc-179"><a href="#QuantileRegErrFunc-179"><span class="linenos">179</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculates conformalized quantile regression error.&quot;&quot;&quot;</span>
</span><span id="QuantileRegErrFunc-180"><a href="#QuantileRegErrFunc-180"><span class="linenos">180</span></a>
</span><span id="QuantileRegErrFunc-181"><a href="#QuantileRegErrFunc-181"><span class="linenos">181</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="QuantileRegErrFunc-182"><a href="#QuantileRegErrFunc-182"><span class="linenos">182</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">QuantileRegErrFunc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="QuantileRegErrFunc-183"><a href="#QuantileRegErrFunc-183"><span class="linenos">183</span></a>
</span><span id="QuantileRegErrFunc-184"><a href="#QuantileRegErrFunc-184"><span class="linenos">184</span></a>    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="QuantileRegErrFunc-185"><a href="#QuantileRegErrFunc-185"><span class="linenos">185</span></a>        <span class="n">y_lower</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
</span><span id="QuantileRegErrFunc-186"><a href="#QuantileRegErrFunc-186"><span class="linenos">186</span></a>        <span class="n">y_upper</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="QuantileRegErrFunc-187"><a href="#QuantileRegErrFunc-187"><span class="linenos">187</span></a>        <span class="n">error_low</span> <span class="o">=</span> <span class="n">y_lower</span> <span class="o">-</span> <span class="n">y</span>
</span><span id="QuantileRegErrFunc-188"><a href="#QuantileRegErrFunc-188"><span class="linenos">188</span></a>        <span class="n">error_high</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_upper</span>
</span><span id="QuantileRegErrFunc-189"><a href="#QuantileRegErrFunc-189"><span class="linenos">189</span></a>        <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">error_high</span><span class="p">,</span> <span class="n">error_low</span><span class="p">)</span>
</span><span id="QuantileRegErrFunc-190"><a href="#QuantileRegErrFunc-190"><span class="linenos">190</span></a>        <span class="k">return</span> <span class="n">err</span>
</span><span id="QuantileRegErrFunc-191"><a href="#QuantileRegErrFunc-191"><span class="linenos">191</span></a>
</span><span id="QuantileRegErrFunc-192"><a href="#QuantileRegErrFunc-192"><span class="linenos">192</span></a>    <span class="k">def</span> <span class="nf">apply_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="n">significance</span><span class="p">):</span>
</span><span id="QuantileRegErrFunc-193"><a href="#QuantileRegErrFunc-193"><span class="linenos">193</span></a>        <span class="n">nc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">nc</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="QuantileRegErrFunc-194"><a href="#QuantileRegErrFunc-194"><span class="linenos">194</span></a>        <span class="n">index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">significance</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">nc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)))</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="QuantileRegErrFunc-195"><a href="#QuantileRegErrFunc-195"><span class="linenos">195</span></a>        <span class="n">index</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">nc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="QuantileRegErrFunc-196"><a href="#QuantileRegErrFunc-196"><span class="linenos">196</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">nc</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">nc</span><span class="p">[</span><span class="n">index</span><span class="p">]])</span>
</span></pre></div>


            <div class="docstring"><p>Calculates conformalized quantile regression error.</p>
</div>


                        
                </section>
                <section id="RegressorAdapter">
                            <input id="RegressorAdapter-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">RegressorAdapter</span><wbr>(<span class="base">nnetsauce.nonconformist.base.BaseModelAdapter</span>):

                <label class="view-source-button" for="RegressorAdapter-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RegressorAdapter"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RegressorAdapter-114"><a href="#RegressorAdapter-114"><span class="linenos">114</span></a><span class="k">class</span> <span class="nc">RegressorAdapter</span><span class="p">(</span><span class="n">BaseModelAdapter</span><span class="p">):</span>
</span><span id="RegressorAdapter-115"><a href="#RegressorAdapter-115"><span class="linenos">115</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="RegressorAdapter-116"><a href="#RegressorAdapter-116"><span class="linenos">116</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">RegressorAdapter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">fit_params</span><span class="p">)</span>
</span><span id="RegressorAdapter-117"><a href="#RegressorAdapter-117"><span class="linenos">117</span></a>
</span><span id="RegressorAdapter-118"><a href="#RegressorAdapter-118"><span class="linenos">118</span></a>    <span class="k">def</span> <span class="nf">_underlying_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="RegressorAdapter-119"><a href="#RegressorAdapter-119"><span class="linenos">119</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all estimators in scikit-learn.</p>

<p>Inheriting from this class provides default implementations of:</p>

<ul>
<li>setting and getting parameters used by <code>GridSearchCV</code> and friends;</li>
<li>textual and HTML representation displayed in terminals and IDEs;</li>
<li>estimator serialization;</li>
<li>parameters validation;</li>
<li>data validation;</li>
<li>feature names validation.</li>
</ul>

<p>Read more in the :ref:<code>User Guide &lt;rolling_your_own_estimator&gt;</code>.</p>

<h2 id="notes">Notes</h2>

<p>All estimators should specify all the parameters that can be set
at the class level in their <code><a href="#RegressorAdapter.__init__">__init__</a></code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>

<h2 id="examples">Examples</h2>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">MyEstimator</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">param</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">is_fitted_</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">fill_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">MyEstimator</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
<span class="go">{&#39;param&#39;: 2}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([2, 2, 2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([3, 3, 3])</span>
</code></pre>
</div>
</div>


                        
                </section>
                <section id="ClassifierAdapter">
                            <input id="ClassifierAdapter-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ClassifierAdapter</span><wbr>(<span class="base">nnetsauce.nonconformist.base.BaseModelAdapter</span>):

                <label class="view-source-button" for="ClassifierAdapter-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ClassifierAdapter"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ClassifierAdapter-106"><a href="#ClassifierAdapter-106"><span class="linenos">106</span></a><span class="k">class</span> <span class="nc">ClassifierAdapter</span><span class="p">(</span><span class="n">BaseModelAdapter</span><span class="p">):</span>
</span><span id="ClassifierAdapter-107"><a href="#ClassifierAdapter-107"><span class="linenos">107</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ClassifierAdapter-108"><a href="#ClassifierAdapter-108"><span class="linenos">108</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">ClassifierAdapter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">fit_params</span><span class="p">)</span>
</span><span id="ClassifierAdapter-109"><a href="#ClassifierAdapter-109"><span class="linenos">109</span></a>
</span><span id="ClassifierAdapter-110"><a href="#ClassifierAdapter-110"><span class="linenos">110</span></a>    <span class="k">def</span> <span class="nf">_underlying_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="ClassifierAdapter-111"><a href="#ClassifierAdapter-111"><span class="linenos">111</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all estimators in scikit-learn.</p>

<p>Inheriting from this class provides default implementations of:</p>

<ul>
<li>setting and getting parameters used by <code>GridSearchCV</code> and friends;</li>
<li>textual and HTML representation displayed in terminals and IDEs;</li>
<li>estimator serialization;</li>
<li>parameters validation;</li>
<li>data validation;</li>
<li>feature names validation.</li>
</ul>

<p>Read more in the :ref:<code>User Guide &lt;rolling_your_own_estimator&gt;</code>.</p>

<h2 id="notes">Notes</h2>

<p>All estimators should specify all the parameters that can be set
at the class level in their <code><a href="#ClassifierAdapter.__init__">__init__</a></code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>

<h2 id="examples">Examples</h2>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">MyEstimator</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">param</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">is_fitted_</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">fill_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">MyEstimator</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
<span class="go">{&#39;param&#39;: 2}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([2, 2, 2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([3, 3, 3])</span>
</code></pre>
</div>
</div>


                        
                </section>
                <section id="RegressorNc">
                            <input id="RegressorNc-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">RegressorNc</span><wbr>(<span class="base">nnetsauce.nonconformist.nc.BaseModelNc</span>):

                <label class="view-source-button" for="RegressorNc-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RegressorNc"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RegressorNc-462"><a href="#RegressorNc-462"><span class="linenos">462</span></a><span class="k">class</span> <span class="nc">RegressorNc</span><span class="p">(</span><span class="n">BaseModelNc</span><span class="p">):</span>
</span><span id="RegressorNc-463"><a href="#RegressorNc-463"><span class="linenos">463</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Nonconformity scorer using an underlying regression model.</span>
</span><span id="RegressorNc-464"><a href="#RegressorNc-464"><span class="linenos">464</span></a>
</span><span id="RegressorNc-465"><a href="#RegressorNc-465"><span class="linenos">465</span></a><span class="sd">    Parameters</span>
</span><span id="RegressorNc-466"><a href="#RegressorNc-466"><span class="linenos">466</span></a><span class="sd">    ----------</span>
</span><span id="RegressorNc-467"><a href="#RegressorNc-467"><span class="linenos">467</span></a><span class="sd">    model : RegressorAdapter</span>
</span><span id="RegressorNc-468"><a href="#RegressorNc-468"><span class="linenos">468</span></a><span class="sd">        Underlying regression model used for calculating nonconformity scores.</span>
</span><span id="RegressorNc-469"><a href="#RegressorNc-469"><span class="linenos">469</span></a>
</span><span id="RegressorNc-470"><a href="#RegressorNc-470"><span class="linenos">470</span></a><span class="sd">    err_func : RegressionErrFunc</span>
</span><span id="RegressorNc-471"><a href="#RegressorNc-471"><span class="linenos">471</span></a><span class="sd">        Error function object.</span>
</span><span id="RegressorNc-472"><a href="#RegressorNc-472"><span class="linenos">472</span></a>
</span><span id="RegressorNc-473"><a href="#RegressorNc-473"><span class="linenos">473</span></a><span class="sd">    normalizer : BaseScorer</span>
</span><span id="RegressorNc-474"><a href="#RegressorNc-474"><span class="linenos">474</span></a><span class="sd">        Normalization model.</span>
</span><span id="RegressorNc-475"><a href="#RegressorNc-475"><span class="linenos">475</span></a>
</span><span id="RegressorNc-476"><a href="#RegressorNc-476"><span class="linenos">476</span></a><span class="sd">    beta : float</span>
</span><span id="RegressorNc-477"><a href="#RegressorNc-477"><span class="linenos">477</span></a><span class="sd">        Normalization smoothing parameter. As the beta-value increases,</span>
</span><span id="RegressorNc-478"><a href="#RegressorNc-478"><span class="linenos">478</span></a><span class="sd">        the normalized nonconformity function approaches a non-normalized</span>
</span><span id="RegressorNc-479"><a href="#RegressorNc-479"><span class="linenos">479</span></a><span class="sd">        equivalent.</span>
</span><span id="RegressorNc-480"><a href="#RegressorNc-480"><span class="linenos">480</span></a>
</span><span id="RegressorNc-481"><a href="#RegressorNc-481"><span class="linenos">481</span></a><span class="sd">    Attributes</span>
</span><span id="RegressorNc-482"><a href="#RegressorNc-482"><span class="linenos">482</span></a><span class="sd">    ----------</span>
</span><span id="RegressorNc-483"><a href="#RegressorNc-483"><span class="linenos">483</span></a><span class="sd">    model : RegressorAdapter</span>
</span><span id="RegressorNc-484"><a href="#RegressorNc-484"><span class="linenos">484</span></a><span class="sd">        Underlying model object.</span>
</span><span id="RegressorNc-485"><a href="#RegressorNc-485"><span class="linenos">485</span></a>
</span><span id="RegressorNc-486"><a href="#RegressorNc-486"><span class="linenos">486</span></a><span class="sd">    err_func : RegressionErrFunc</span>
</span><span id="RegressorNc-487"><a href="#RegressorNc-487"><span class="linenos">487</span></a><span class="sd">        Scorer function used to calculate nonconformity scores.</span>
</span><span id="RegressorNc-488"><a href="#RegressorNc-488"><span class="linenos">488</span></a>
</span><span id="RegressorNc-489"><a href="#RegressorNc-489"><span class="linenos">489</span></a><span class="sd">    See also</span>
</span><span id="RegressorNc-490"><a href="#RegressorNc-490"><span class="linenos">490</span></a><span class="sd">    --------</span>
</span><span id="RegressorNc-491"><a href="#RegressorNc-491"><span class="linenos">491</span></a><span class="sd">    ProbEstClassifierNc, NormalizedRegressorNc</span>
</span><span id="RegressorNc-492"><a href="#RegressorNc-492"><span class="linenos">492</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="RegressorNc-493"><a href="#RegressorNc-493"><span class="linenos">493</span></a>
</span><span id="RegressorNc-494"><a href="#RegressorNc-494"><span class="linenos">494</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">err_func</span><span class="o">=</span><span class="n">AbsErrorErrFunc</span><span class="p">(),</span> <span class="n">normalizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
</span><span id="RegressorNc-495"><a href="#RegressorNc-495"><span class="linenos">495</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">RegressorNc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">err_func</span><span class="p">,</span> <span class="n">normalizer</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</span><span id="RegressorNc-496"><a href="#RegressorNc-496"><span class="linenos">496</span></a>
</span><span id="RegressorNc-497"><a href="#RegressorNc-497"><span class="linenos">497</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="RegressorNc-498"><a href="#RegressorNc-498"><span class="linenos">498</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructs prediction intervals for a set of test examples.</span>
</span><span id="RegressorNc-499"><a href="#RegressorNc-499"><span class="linenos">499</span></a>
</span><span id="RegressorNc-500"><a href="#RegressorNc-500"><span class="linenos">500</span></a><span class="sd">        Predicts the output of each test pattern using the underlying model,</span>
</span><span id="RegressorNc-501"><a href="#RegressorNc-501"><span class="linenos">501</span></a><span class="sd">        and applies the (partial) inverse nonconformity function to each</span>
</span><span id="RegressorNc-502"><a href="#RegressorNc-502"><span class="linenos">502</span></a><span class="sd">        prediction, resulting in a prediction interval for each test pattern.</span>
</span><span id="RegressorNc-503"><a href="#RegressorNc-503"><span class="linenos">503</span></a>
</span><span id="RegressorNc-504"><a href="#RegressorNc-504"><span class="linenos">504</span></a><span class="sd">        Parameters</span>
</span><span id="RegressorNc-505"><a href="#RegressorNc-505"><span class="linenos">505</span></a><span class="sd">        ----------</span>
</span><span id="RegressorNc-506"><a href="#RegressorNc-506"><span class="linenos">506</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="RegressorNc-507"><a href="#RegressorNc-507"><span class="linenos">507</span></a><span class="sd">            Inputs of patters for which to predict output values.</span>
</span><span id="RegressorNc-508"><a href="#RegressorNc-508"><span class="linenos">508</span></a>
</span><span id="RegressorNc-509"><a href="#RegressorNc-509"><span class="linenos">509</span></a><span class="sd">        significance : float</span>
</span><span id="RegressorNc-510"><a href="#RegressorNc-510"><span class="linenos">510</span></a><span class="sd">            Significance level (maximum allowed error rate) of predictions.</span>
</span><span id="RegressorNc-511"><a href="#RegressorNc-511"><span class="linenos">511</span></a><span class="sd">            Should be a float between 0 and 1. If ``None``, then intervals for</span>
</span><span id="RegressorNc-512"><a href="#RegressorNc-512"><span class="linenos">512</span></a><span class="sd">            all significance levels (0.01, 0.02, ..., 0.99) are output in a</span>
</span><span id="RegressorNc-513"><a href="#RegressorNc-513"><span class="linenos">513</span></a><span class="sd">            3d-matrix.</span>
</span><span id="RegressorNc-514"><a href="#RegressorNc-514"><span class="linenos">514</span></a>
</span><span id="RegressorNc-515"><a href="#RegressorNc-515"><span class="linenos">515</span></a><span class="sd">        Returns</span>
</span><span id="RegressorNc-516"><a href="#RegressorNc-516"><span class="linenos">516</span></a><span class="sd">        -------</span>
</span><span id="RegressorNc-517"><a href="#RegressorNc-517"><span class="linenos">517</span></a><span class="sd">        p : numpy array of shape [n_samples, 2] or [n_samples, 2, 99]</span>
</span><span id="RegressorNc-518"><a href="#RegressorNc-518"><span class="linenos">518</span></a><span class="sd">            If significance is ``None``, then p contains the interval (minimum</span>
</span><span id="RegressorNc-519"><a href="#RegressorNc-519"><span class="linenos">519</span></a><span class="sd">            and maximum boundaries) for each test pattern, and each significance</span>
</span><span id="RegressorNc-520"><a href="#RegressorNc-520"><span class="linenos">520</span></a><span class="sd">            level (0.01, 0.02, ..., 0.99). If significance is a float between</span>
</span><span id="RegressorNc-521"><a href="#RegressorNc-521"><span class="linenos">521</span></a><span class="sd">            0 and 1, then p contains the prediction intervals (minimum and</span>
</span><span id="RegressorNc-522"><a href="#RegressorNc-522"><span class="linenos">522</span></a><span class="sd">            maximum	boundaries) for the set of test patterns at the chosen</span>
</span><span id="RegressorNc-523"><a href="#RegressorNc-523"><span class="linenos">523</span></a><span class="sd">            significance level.</span>
</span><span id="RegressorNc-524"><a href="#RegressorNc-524"><span class="linenos">524</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="RegressorNc-525"><a href="#RegressorNc-525"><span class="linenos">525</span></a>        <span class="n">n_test</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="RegressorNc-526"><a href="#RegressorNc-526"><span class="linenos">526</span></a>        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="RegressorNc-527"><a href="#RegressorNc-527"><span class="linenos">527</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="RegressorNc-528"><a href="#RegressorNc-528"><span class="linenos">528</span></a>            <span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalizer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>
</span><span id="RegressorNc-529"><a href="#RegressorNc-529"><span class="linenos">529</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="RegressorNc-530"><a href="#RegressorNc-530"><span class="linenos">530</span></a>            <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_test</span><span class="p">)</span>
</span><span id="RegressorNc-531"><a href="#RegressorNc-531"><span class="linenos">531</span></a>
</span><span id="RegressorNc-532"><a href="#RegressorNc-532"><span class="linenos">532</span></a>        <span class="k">if</span> <span class="n">significance</span><span class="p">:</span>
</span><span id="RegressorNc-533"><a href="#RegressorNc-533"><span class="linenos">533</span></a>            <span class="n">intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>
</span><span id="RegressorNc-534"><a href="#RegressorNc-534"><span class="linenos">534</span></a>            <span class="n">err_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">err_func</span><span class="o">.</span><span class="n">apply_inverse</span><span class="p">(</span><span class="n">nc</span><span class="p">,</span> <span class="n">significance</span><span class="p">)</span>
</span><span id="RegressorNc-535"><a href="#RegressorNc-535"><span class="linenos">535</span></a>            <span class="n">err_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">err_dist</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_test</span><span class="p">)</span>
</span><span id="RegressorNc-536"><a href="#RegressorNc-536"><span class="linenos">536</span></a>            <span class="k">if</span> <span class="n">prediction</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># CQR</span>
</span><span id="RegressorNc-537"><a href="#RegressorNc-537"><span class="linenos">537</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc-538"><a href="#RegressorNc-538"><span class="linenos">538</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc-539"><a href="#RegressorNc-539"><span class="linenos">539</span></a>            <span class="k">else</span><span class="p">:</span>  <span class="c1"># regular conformal prediction</span>
</span><span id="RegressorNc-540"><a href="#RegressorNc-540"><span class="linenos">540</span></a>                <span class="n">err_dist</span> <span class="o">*=</span> <span class="n">norm</span>
</span><span id="RegressorNc-541"><a href="#RegressorNc-541"><span class="linenos">541</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">-</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc-542"><a href="#RegressorNc-542"><span class="linenos">542</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">+</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc-543"><a href="#RegressorNc-543"><span class="linenos">543</span></a>
</span><span id="RegressorNc-544"><a href="#RegressorNc-544"><span class="linenos">544</span></a>            <span class="k">return</span> <span class="n">intervals</span>
</span><span id="RegressorNc-545"><a href="#RegressorNc-545"><span class="linenos">545</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Not tested for CQR</span>
</span><span id="RegressorNc-546"><a href="#RegressorNc-546"><span class="linenos">546</span></a>            <span class="n">significance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</span><span id="RegressorNc-547"><a href="#RegressorNc-547"><span class="linenos">547</span></a>            <span class="n">intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="n">significance</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</span><span id="RegressorNc-548"><a href="#RegressorNc-548"><span class="linenos">548</span></a>
</span><span id="RegressorNc-549"><a href="#RegressorNc-549"><span class="linenos">549</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">significance</span><span class="p">):</span>
</span><span id="RegressorNc-550"><a href="#RegressorNc-550"><span class="linenos">550</span></a>                <span class="n">err_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">err_func</span><span class="o">.</span><span class="n">apply_inverse</span><span class="p">(</span><span class="n">nc</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</span><span id="RegressorNc-551"><a href="#RegressorNc-551"><span class="linenos">551</span></a>                <span class="n">err_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">err_dist</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_test</span><span class="p">)</span>
</span><span id="RegressorNc-552"><a href="#RegressorNc-552"><span class="linenos">552</span></a>                <span class="n">err_dist</span> <span class="o">*=</span> <span class="n">norm</span>
</span><span id="RegressorNc-553"><a href="#RegressorNc-553"><span class="linenos">553</span></a>
</span><span id="RegressorNc-554"><a href="#RegressorNc-554"><span class="linenos">554</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">-</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc-555"><a href="#RegressorNc-555"><span class="linenos">555</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">+</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc-556"><a href="#RegressorNc-556"><span class="linenos">556</span></a>
</span><span id="RegressorNc-557"><a href="#RegressorNc-557"><span class="linenos">557</span></a>            <span class="k">return</span> <span class="n">intervals</span>
</span></pre></div>


            <div class="docstring"><p>Nonconformity scorer using an underlying regression model.</p>

<h2 id="parameters">Parameters</h2>

<p>model : RegressorAdapter
    Underlying regression model used for calculating nonconformity scores.</p>

<p>err_func : RegressionErrFunc
    Error function object.</p>

<p>normalizer : BaseScorer
    Normalization model.</p>

<p>beta : float
    Normalization smoothing parameter. As the beta-value increases,
    the normalized nonconformity function approaches a non-normalized
    equivalent.</p>

<h2 id="attributes">Attributes</h2>

<p>model : RegressorAdapter
    Underlying model object.</p>

<p>err_func : RegressionErrFunc
    Scorer function used to calculate nonconformity scores.</p>

<h2 id="see-also">See also</h2>

<p>ProbEstClassifierNc, NormalizedRegressorNc</p>
</div>


                                <div id="RegressorNc.predict" class="classattr">
                                            <input id="RegressorNc.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span>, </span><span class="param"><span class="n">nc</span>, </span><span class="param"><span class="n">significance</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="RegressorNc.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RegressorNc.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RegressorNc.predict-497"><a href="#RegressorNc.predict-497"><span class="linenos">497</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="RegressorNc.predict-498"><a href="#RegressorNc.predict-498"><span class="linenos">498</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructs prediction intervals for a set of test examples.</span>
</span><span id="RegressorNc.predict-499"><a href="#RegressorNc.predict-499"><span class="linenos">499</span></a>
</span><span id="RegressorNc.predict-500"><a href="#RegressorNc.predict-500"><span class="linenos">500</span></a><span class="sd">        Predicts the output of each test pattern using the underlying model,</span>
</span><span id="RegressorNc.predict-501"><a href="#RegressorNc.predict-501"><span class="linenos">501</span></a><span class="sd">        and applies the (partial) inverse nonconformity function to each</span>
</span><span id="RegressorNc.predict-502"><a href="#RegressorNc.predict-502"><span class="linenos">502</span></a><span class="sd">        prediction, resulting in a prediction interval for each test pattern.</span>
</span><span id="RegressorNc.predict-503"><a href="#RegressorNc.predict-503"><span class="linenos">503</span></a>
</span><span id="RegressorNc.predict-504"><a href="#RegressorNc.predict-504"><span class="linenos">504</span></a><span class="sd">        Parameters</span>
</span><span id="RegressorNc.predict-505"><a href="#RegressorNc.predict-505"><span class="linenos">505</span></a><span class="sd">        ----------</span>
</span><span id="RegressorNc.predict-506"><a href="#RegressorNc.predict-506"><span class="linenos">506</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="RegressorNc.predict-507"><a href="#RegressorNc.predict-507"><span class="linenos">507</span></a><span class="sd">            Inputs of patters for which to predict output values.</span>
</span><span id="RegressorNc.predict-508"><a href="#RegressorNc.predict-508"><span class="linenos">508</span></a>
</span><span id="RegressorNc.predict-509"><a href="#RegressorNc.predict-509"><span class="linenos">509</span></a><span class="sd">        significance : float</span>
</span><span id="RegressorNc.predict-510"><a href="#RegressorNc.predict-510"><span class="linenos">510</span></a><span class="sd">            Significance level (maximum allowed error rate) of predictions.</span>
</span><span id="RegressorNc.predict-511"><a href="#RegressorNc.predict-511"><span class="linenos">511</span></a><span class="sd">            Should be a float between 0 and 1. If ``None``, then intervals for</span>
</span><span id="RegressorNc.predict-512"><a href="#RegressorNc.predict-512"><span class="linenos">512</span></a><span class="sd">            all significance levels (0.01, 0.02, ..., 0.99) are output in a</span>
</span><span id="RegressorNc.predict-513"><a href="#RegressorNc.predict-513"><span class="linenos">513</span></a><span class="sd">            3d-matrix.</span>
</span><span id="RegressorNc.predict-514"><a href="#RegressorNc.predict-514"><span class="linenos">514</span></a>
</span><span id="RegressorNc.predict-515"><a href="#RegressorNc.predict-515"><span class="linenos">515</span></a><span class="sd">        Returns</span>
</span><span id="RegressorNc.predict-516"><a href="#RegressorNc.predict-516"><span class="linenos">516</span></a><span class="sd">        -------</span>
</span><span id="RegressorNc.predict-517"><a href="#RegressorNc.predict-517"><span class="linenos">517</span></a><span class="sd">        p : numpy array of shape [n_samples, 2] or [n_samples, 2, 99]</span>
</span><span id="RegressorNc.predict-518"><a href="#RegressorNc.predict-518"><span class="linenos">518</span></a><span class="sd">            If significance is ``None``, then p contains the interval (minimum</span>
</span><span id="RegressorNc.predict-519"><a href="#RegressorNc.predict-519"><span class="linenos">519</span></a><span class="sd">            and maximum boundaries) for each test pattern, and each significance</span>
</span><span id="RegressorNc.predict-520"><a href="#RegressorNc.predict-520"><span class="linenos">520</span></a><span class="sd">            level (0.01, 0.02, ..., 0.99). If significance is a float between</span>
</span><span id="RegressorNc.predict-521"><a href="#RegressorNc.predict-521"><span class="linenos">521</span></a><span class="sd">            0 and 1, then p contains the prediction intervals (minimum and</span>
</span><span id="RegressorNc.predict-522"><a href="#RegressorNc.predict-522"><span class="linenos">522</span></a><span class="sd">            maximum	boundaries) for the set of test patterns at the chosen</span>
</span><span id="RegressorNc.predict-523"><a href="#RegressorNc.predict-523"><span class="linenos">523</span></a><span class="sd">            significance level.</span>
</span><span id="RegressorNc.predict-524"><a href="#RegressorNc.predict-524"><span class="linenos">524</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="RegressorNc.predict-525"><a href="#RegressorNc.predict-525"><span class="linenos">525</span></a>        <span class="n">n_test</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="RegressorNc.predict-526"><a href="#RegressorNc.predict-526"><span class="linenos">526</span></a>        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="RegressorNc.predict-527"><a href="#RegressorNc.predict-527"><span class="linenos">527</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="RegressorNc.predict-528"><a href="#RegressorNc.predict-528"><span class="linenos">528</span></a>            <span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalizer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>
</span><span id="RegressorNc.predict-529"><a href="#RegressorNc.predict-529"><span class="linenos">529</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="RegressorNc.predict-530"><a href="#RegressorNc.predict-530"><span class="linenos">530</span></a>            <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_test</span><span class="p">)</span>
</span><span id="RegressorNc.predict-531"><a href="#RegressorNc.predict-531"><span class="linenos">531</span></a>
</span><span id="RegressorNc.predict-532"><a href="#RegressorNc.predict-532"><span class="linenos">532</span></a>        <span class="k">if</span> <span class="n">significance</span><span class="p">:</span>
</span><span id="RegressorNc.predict-533"><a href="#RegressorNc.predict-533"><span class="linenos">533</span></a>            <span class="n">intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>
</span><span id="RegressorNc.predict-534"><a href="#RegressorNc.predict-534"><span class="linenos">534</span></a>            <span class="n">err_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">err_func</span><span class="o">.</span><span class="n">apply_inverse</span><span class="p">(</span><span class="n">nc</span><span class="p">,</span> <span class="n">significance</span><span class="p">)</span>
</span><span id="RegressorNc.predict-535"><a href="#RegressorNc.predict-535"><span class="linenos">535</span></a>            <span class="n">err_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">err_dist</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_test</span><span class="p">)</span>
</span><span id="RegressorNc.predict-536"><a href="#RegressorNc.predict-536"><span class="linenos">536</span></a>            <span class="k">if</span> <span class="n">prediction</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># CQR</span>
</span><span id="RegressorNc.predict-537"><a href="#RegressorNc.predict-537"><span class="linenos">537</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc.predict-538"><a href="#RegressorNc.predict-538"><span class="linenos">538</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc.predict-539"><a href="#RegressorNc.predict-539"><span class="linenos">539</span></a>            <span class="k">else</span><span class="p">:</span>  <span class="c1"># regular conformal prediction</span>
</span><span id="RegressorNc.predict-540"><a href="#RegressorNc.predict-540"><span class="linenos">540</span></a>                <span class="n">err_dist</span> <span class="o">*=</span> <span class="n">norm</span>
</span><span id="RegressorNc.predict-541"><a href="#RegressorNc.predict-541"><span class="linenos">541</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">-</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc.predict-542"><a href="#RegressorNc.predict-542"><span class="linenos">542</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">+</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc.predict-543"><a href="#RegressorNc.predict-543"><span class="linenos">543</span></a>
</span><span id="RegressorNc.predict-544"><a href="#RegressorNc.predict-544"><span class="linenos">544</span></a>            <span class="k">return</span> <span class="n">intervals</span>
</span><span id="RegressorNc.predict-545"><a href="#RegressorNc.predict-545"><span class="linenos">545</span></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Not tested for CQR</span>
</span><span id="RegressorNc.predict-546"><a href="#RegressorNc.predict-546"><span class="linenos">546</span></a>            <span class="n">significance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</span><span id="RegressorNc.predict-547"><a href="#RegressorNc.predict-547"><span class="linenos">547</span></a>            <span class="n">intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="n">significance</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</span><span id="RegressorNc.predict-548"><a href="#RegressorNc.predict-548"><span class="linenos">548</span></a>
</span><span id="RegressorNc.predict-549"><a href="#RegressorNc.predict-549"><span class="linenos">549</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">significance</span><span class="p">):</span>
</span><span id="RegressorNc.predict-550"><a href="#RegressorNc.predict-550"><span class="linenos">550</span></a>                <span class="n">err_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">err_func</span><span class="o">.</span><span class="n">apply_inverse</span><span class="p">(</span><span class="n">nc</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</span><span id="RegressorNc.predict-551"><a href="#RegressorNc.predict-551"><span class="linenos">551</span></a>                <span class="n">err_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">err_dist</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_test</span><span class="p">)</span>
</span><span id="RegressorNc.predict-552"><a href="#RegressorNc.predict-552"><span class="linenos">552</span></a>                <span class="n">err_dist</span> <span class="o">*=</span> <span class="n">norm</span>
</span><span id="RegressorNc.predict-553"><a href="#RegressorNc.predict-553"><span class="linenos">553</span></a>
</span><span id="RegressorNc.predict-554"><a href="#RegressorNc.predict-554"><span class="linenos">554</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">-</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc.predict-555"><a href="#RegressorNc.predict-555"><span class="linenos">555</span></a>                <span class="n">intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">+</span> <span class="n">err_dist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RegressorNc.predict-556"><a href="#RegressorNc.predict-556"><span class="linenos">556</span></a>
</span><span id="RegressorNc.predict-557"><a href="#RegressorNc.predict-557"><span class="linenos">557</span></a>            <span class="k">return</span> <span class="n">intervals</span>
</span></pre></div>


            <div class="docstring"><p>Constructs prediction intervals for a set of test examples.</p>

<p>Predicts the output of each test pattern using the underlying model,
and applies the (partial) inverse nonconformity function to each
prediction, resulting in a prediction interval for each test pattern.</p>

<h2 id="parameters">Parameters</h2>

<p>x : numpy array of shape [n_samples, n_features]
    Inputs of patters for which to predict output values.</p>

<p>significance : float
    Significance level (maximum allowed error rate) of predictions.
    Should be a float between 0 and 1. If <code>None</code>, then intervals for
    all significance levels (0.01, 0.02, ..., 0.99) are output in a
    3d-matrix.</p>

<h2 id="returns">Returns</h2>

<p>p : numpy array of shape [n_samples, 2] or [n_samples, 2, 99]
    If significance is <code>None</code>, then p contains the interval (minimum
    and maximum boundaries) for each test pattern, and each significance
    level (0.01, 0.02, ..., 0.99). If significance is a float between
    0 and 1, then p contains the prediction intervals (minimum and
    maximum     boundaries) for the set of test patterns at the chosen
    significance level.</p>
</div>


                                </div>
                        
                </section>
                <section id="ClassifierNc">
                            <input id="ClassifierNc-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ClassifierNc</span><wbr>(<span class="base">nnetsauce.nonconformist.nc.BaseModelNc</span>):

                <label class="view-source-button" for="ClassifierNc-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ClassifierNc"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ClassifierNc-421"><a href="#ClassifierNc-421"><span class="linenos">421</span></a><span class="k">class</span> <span class="nc">ClassifierNc</span><span class="p">(</span><span class="n">BaseModelNc</span><span class="p">):</span>
</span><span id="ClassifierNc-422"><a href="#ClassifierNc-422"><span class="linenos">422</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Nonconformity scorer using an underlying class probability estimating</span>
</span><span id="ClassifierNc-423"><a href="#ClassifierNc-423"><span class="linenos">423</span></a><span class="sd">    model.</span>
</span><span id="ClassifierNc-424"><a href="#ClassifierNc-424"><span class="linenos">424</span></a>
</span><span id="ClassifierNc-425"><a href="#ClassifierNc-425"><span class="linenos">425</span></a><span class="sd">    Parameters</span>
</span><span id="ClassifierNc-426"><a href="#ClassifierNc-426"><span class="linenos">426</span></a><span class="sd">    ----------</span>
</span><span id="ClassifierNc-427"><a href="#ClassifierNc-427"><span class="linenos">427</span></a><span class="sd">    model : ClassifierAdapter</span>
</span><span id="ClassifierNc-428"><a href="#ClassifierNc-428"><span class="linenos">428</span></a><span class="sd">        Underlying classification model used for calculating nonconformity</span>
</span><span id="ClassifierNc-429"><a href="#ClassifierNc-429"><span class="linenos">429</span></a><span class="sd">        scores.</span>
</span><span id="ClassifierNc-430"><a href="#ClassifierNc-430"><span class="linenos">430</span></a>
</span><span id="ClassifierNc-431"><a href="#ClassifierNc-431"><span class="linenos">431</span></a><span class="sd">    err_func : ClassificationErrFunc</span>
</span><span id="ClassifierNc-432"><a href="#ClassifierNc-432"><span class="linenos">432</span></a><span class="sd">        Error function object.</span>
</span><span id="ClassifierNc-433"><a href="#ClassifierNc-433"><span class="linenos">433</span></a>
</span><span id="ClassifierNc-434"><a href="#ClassifierNc-434"><span class="linenos">434</span></a><span class="sd">    normalizer : BaseScorer</span>
</span><span id="ClassifierNc-435"><a href="#ClassifierNc-435"><span class="linenos">435</span></a><span class="sd">        Normalization model.</span>
</span><span id="ClassifierNc-436"><a href="#ClassifierNc-436"><span class="linenos">436</span></a>
</span><span id="ClassifierNc-437"><a href="#ClassifierNc-437"><span class="linenos">437</span></a><span class="sd">    beta : float</span>
</span><span id="ClassifierNc-438"><a href="#ClassifierNc-438"><span class="linenos">438</span></a><span class="sd">        Normalization smoothing parameter. As the beta-value increases,</span>
</span><span id="ClassifierNc-439"><a href="#ClassifierNc-439"><span class="linenos">439</span></a><span class="sd">        the normalized nonconformity function approaches a non-normalized</span>
</span><span id="ClassifierNc-440"><a href="#ClassifierNc-440"><span class="linenos">440</span></a><span class="sd">        equivalent.</span>
</span><span id="ClassifierNc-441"><a href="#ClassifierNc-441"><span class="linenos">441</span></a>
</span><span id="ClassifierNc-442"><a href="#ClassifierNc-442"><span class="linenos">442</span></a><span class="sd">    Attributes</span>
</span><span id="ClassifierNc-443"><a href="#ClassifierNc-443"><span class="linenos">443</span></a><span class="sd">    ----------</span>
</span><span id="ClassifierNc-444"><a href="#ClassifierNc-444"><span class="linenos">444</span></a><span class="sd">    model : ClassifierAdapter</span>
</span><span id="ClassifierNc-445"><a href="#ClassifierNc-445"><span class="linenos">445</span></a><span class="sd">        Underlying model object.</span>
</span><span id="ClassifierNc-446"><a href="#ClassifierNc-446"><span class="linenos">446</span></a>
</span><span id="ClassifierNc-447"><a href="#ClassifierNc-447"><span class="linenos">447</span></a><span class="sd">    err_func : ClassificationErrFunc</span>
</span><span id="ClassifierNc-448"><a href="#ClassifierNc-448"><span class="linenos">448</span></a><span class="sd">        Scorer function used to calculate nonconformity scores.</span>
</span><span id="ClassifierNc-449"><a href="#ClassifierNc-449"><span class="linenos">449</span></a>
</span><span id="ClassifierNc-450"><a href="#ClassifierNc-450"><span class="linenos">450</span></a><span class="sd">    See also</span>
</span><span id="ClassifierNc-451"><a href="#ClassifierNc-451"><span class="linenos">451</span></a><span class="sd">    --------</span>
</span><span id="ClassifierNc-452"><a href="#ClassifierNc-452"><span class="linenos">452</span></a><span class="sd">    RegressorNc, NormalizedRegressorNc</span>
</span><span id="ClassifierNc-453"><a href="#ClassifierNc-453"><span class="linenos">453</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ClassifierNc-454"><a href="#ClassifierNc-454"><span class="linenos">454</span></a>
</span><span id="ClassifierNc-455"><a href="#ClassifierNc-455"><span class="linenos">455</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">err_func</span><span class="o">=</span><span class="n">MarginErrFunc</span><span class="p">(),</span> <span class="n">normalizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
</span><span id="ClassifierNc-456"><a href="#ClassifierNc-456"><span class="linenos">456</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">ClassifierNc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">err_func</span><span class="p">,</span> <span class="n">normalizer</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Nonconformity scorer using an underlying class probability estimating
model.</p>

<h2 id="parameters">Parameters</h2>

<p>model : ClassifierAdapter
    Underlying classification model used for calculating nonconformity
    scores.</p>

<p>err_func : ClassificationErrFunc
    Error function object.</p>

<p>normalizer : BaseScorer
    Normalization model.</p>

<p>beta : float
    Normalization smoothing parameter. As the beta-value increases,
    the normalized nonconformity function approaches a non-normalized
    equivalent.</p>

<h2 id="attributes">Attributes</h2>

<p>model : ClassifierAdapter
    Underlying model object.</p>

<p>err_func : ClassificationErrFunc
    Scorer function used to calculate nonconformity scores.</p>

<h2 id="see-also">See also</h2>

<p>RegressorNc, NormalizedRegressorNc</p>
</div>


                        
                </section>
                <section id="RegressorNormalizer">
                            <input id="RegressorNormalizer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">RegressorNormalizer</span><wbr>(<span class="base">nnetsauce.nonconformist.nc.BaseScorer</span>):

                <label class="view-source-button" for="RegressorNormalizer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RegressorNormalizer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RegressorNormalizer-243"><a href="#RegressorNormalizer-243"><span class="linenos">243</span></a><span class="k">class</span> <span class="nc">RegressorNormalizer</span><span class="p">(</span><span class="n">BaseScorer</span><span class="p">):</span>
</span><span id="RegressorNormalizer-244"><a href="#RegressorNormalizer-244"><span class="linenos">244</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="p">,</span> <span class="n">normalizer_model</span><span class="p">,</span> <span class="n">err_func</span><span class="p">):</span>
</span><span id="RegressorNormalizer-245"><a href="#RegressorNormalizer-245"><span class="linenos">245</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">RegressorNormalizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="RegressorNormalizer-246"><a href="#RegressorNormalizer-246"><span class="linenos">246</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">base_model</span>
</span><span id="RegressorNormalizer-247"><a href="#RegressorNormalizer-247"><span class="linenos">247</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">normalizer_model</span> <span class="o">=</span> <span class="n">normalizer_model</span>
</span><span id="RegressorNormalizer-248"><a href="#RegressorNormalizer-248"><span class="linenos">248</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">err_func</span> <span class="o">=</span> <span class="n">err_func</span>
</span><span id="RegressorNormalizer-249"><a href="#RegressorNormalizer-249"><span class="linenos">249</span></a>
</span><span id="RegressorNormalizer-250"><a href="#RegressorNormalizer-250"><span class="linenos">250</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="RegressorNormalizer-251"><a href="#RegressorNormalizer-251"><span class="linenos">251</span></a>        <span class="n">residual_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="RegressorNormalizer-252"><a href="#RegressorNormalizer-252"><span class="linenos">252</span></a>        <span class="n">residual_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">err_func</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">residual_prediction</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</span><span id="RegressorNormalizer-253"><a href="#RegressorNormalizer-253"><span class="linenos">253</span></a>
</span><span id="RegressorNormalizer-254"><a href="#RegressorNormalizer-254"><span class="linenos">254</span></a>        <span class="c1">######################################################################</span>
</span><span id="RegressorNormalizer-255"><a href="#RegressorNormalizer-255"><span class="linenos">255</span></a>        <span class="c1"># Optional: use logarithmic function as in the original implementation</span>
</span><span id="RegressorNormalizer-256"><a href="#RegressorNormalizer-256"><span class="linenos">256</span></a>        <span class="c1"># available in https://github.com/donlnz/nonconformist</span>
</span><span id="RegressorNormalizer-257"><a href="#RegressorNormalizer-257"><span class="linenos">257</span></a>        <span class="c1">#</span>
</span><span id="RegressorNormalizer-258"><a href="#RegressorNormalizer-258"><span class="linenos">258</span></a>        <span class="c1"># CODE:</span>
</span><span id="RegressorNormalizer-259"><a href="#RegressorNormalizer-259"><span class="linenos">259</span></a>        <span class="c1"># residual_error += 0.00001 # Add small term to avoid log(0)</span>
</span><span id="RegressorNormalizer-260"><a href="#RegressorNormalizer-260"><span class="linenos">260</span></a>        <span class="c1"># log_err = np.log(residual_error)</span>
</span><span id="RegressorNormalizer-261"><a href="#RegressorNormalizer-261"><span class="linenos">261</span></a>        <span class="c1">######################################################################</span>
</span><span id="RegressorNormalizer-262"><a href="#RegressorNormalizer-262"><span class="linenos">262</span></a>
</span><span id="RegressorNormalizer-263"><a href="#RegressorNormalizer-263"><span class="linenos">263</span></a>        <span class="n">log_err</span> <span class="o">=</span> <span class="n">residual_error</span>
</span><span id="RegressorNormalizer-264"><a href="#RegressorNormalizer-264"><span class="linenos">264</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">normalizer_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">log_err</span><span class="p">)</span>
</span><span id="RegressorNormalizer-265"><a href="#RegressorNormalizer-265"><span class="linenos">265</span></a>
</span><span id="RegressorNormalizer-266"><a href="#RegressorNormalizer-266"><span class="linenos">266</span></a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="RegressorNormalizer-267"><a href="#RegressorNormalizer-267"><span class="linenos">267</span></a>
</span><span id="RegressorNormalizer-268"><a href="#RegressorNormalizer-268"><span class="linenos">268</span></a>        <span class="c1">######################################################################</span>
</span><span id="RegressorNormalizer-269"><a href="#RegressorNormalizer-269"><span class="linenos">269</span></a>        <span class="c1"># Optional: use logarithmic function as in the original implementation</span>
</span><span id="RegressorNormalizer-270"><a href="#RegressorNormalizer-270"><span class="linenos">270</span></a>        <span class="c1"># available in https://github.com/donlnz/nonconformist</span>
</span><span id="RegressorNormalizer-271"><a href="#RegressorNormalizer-271"><span class="linenos">271</span></a>        <span class="c1">#</span>
</span><span id="RegressorNormalizer-272"><a href="#RegressorNormalizer-272"><span class="linenos">272</span></a>        <span class="c1"># CODE:</span>
</span><span id="RegressorNormalizer-273"><a href="#RegressorNormalizer-273"><span class="linenos">273</span></a>        <span class="c1"># norm = np.exp(self.normalizer_model.predict(x))</span>
</span><span id="RegressorNormalizer-274"><a href="#RegressorNormalizer-274"><span class="linenos">274</span></a>        <span class="c1">######################################################################</span>
</span><span id="RegressorNormalizer-275"><a href="#RegressorNormalizer-275"><span class="linenos">275</span></a>
</span><span id="RegressorNormalizer-276"><a href="#RegressorNormalizer-276"><span class="linenos">276</span></a>        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">normalizer_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span><span id="RegressorNormalizer-277"><a href="#RegressorNormalizer-277"><span class="linenos">277</span></a>        <span class="k">return</span> <span class="n">norm</span>
</span></pre></div>


            <div class="docstring"><p>Base class for all estimators in scikit-learn.</p>

<p>Inheriting from this class provides default implementations of:</p>

<ul>
<li>setting and getting parameters used by <code>GridSearchCV</code> and friends;</li>
<li>textual and HTML representation displayed in terminals and IDEs;</li>
<li>estimator serialization;</li>
<li>parameters validation;</li>
<li>data validation;</li>
<li>feature names validation.</li>
</ul>

<p>Read more in the :ref:<code>User Guide &lt;rolling_your_own_estimator&gt;</code>.</p>

<h2 id="notes">Notes</h2>

<p>All estimators should specify all the parameters that can be set
at the class level in their <code><a href="#RegressorNormalizer.__init__">__init__</a></code> as explicit keyword
arguments (no <code>*args</code> or <code>**kwargs</code>).</p>

<h2 id="examples">Examples</h2>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">MyEstimator</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">param</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">is_fitted_</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">fill_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">MyEstimator</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
<span class="go">{&#39;param&#39;: 2}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([2, 2, 2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([3, 3, 3])</span>
</code></pre>
</div>
</div>


                                <div id="RegressorNormalizer.fit" class="classattr">
                                            <input id="RegressorNormalizer.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span>, </span><span class="param"><span class="n">y</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="RegressorNormalizer.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RegressorNormalizer.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RegressorNormalizer.fit-250"><a href="#RegressorNormalizer.fit-250"><span class="linenos">250</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="RegressorNormalizer.fit-251"><a href="#RegressorNormalizer.fit-251"><span class="linenos">251</span></a>        <span class="n">residual_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="RegressorNormalizer.fit-252"><a href="#RegressorNormalizer.fit-252"><span class="linenos">252</span></a>        <span class="n">residual_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">err_func</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">residual_prediction</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</span><span id="RegressorNormalizer.fit-253"><a href="#RegressorNormalizer.fit-253"><span class="linenos">253</span></a>
</span><span id="RegressorNormalizer.fit-254"><a href="#RegressorNormalizer.fit-254"><span class="linenos">254</span></a>        <span class="c1">######################################################################</span>
</span><span id="RegressorNormalizer.fit-255"><a href="#RegressorNormalizer.fit-255"><span class="linenos">255</span></a>        <span class="c1"># Optional: use logarithmic function as in the original implementation</span>
</span><span id="RegressorNormalizer.fit-256"><a href="#RegressorNormalizer.fit-256"><span class="linenos">256</span></a>        <span class="c1"># available in https://github.com/donlnz/nonconformist</span>
</span><span id="RegressorNormalizer.fit-257"><a href="#RegressorNormalizer.fit-257"><span class="linenos">257</span></a>        <span class="c1">#</span>
</span><span id="RegressorNormalizer.fit-258"><a href="#RegressorNormalizer.fit-258"><span class="linenos">258</span></a>        <span class="c1"># CODE:</span>
</span><span id="RegressorNormalizer.fit-259"><a href="#RegressorNormalizer.fit-259"><span class="linenos">259</span></a>        <span class="c1"># residual_error += 0.00001 # Add small term to avoid log(0)</span>
</span><span id="RegressorNormalizer.fit-260"><a href="#RegressorNormalizer.fit-260"><span class="linenos">260</span></a>        <span class="c1"># log_err = np.log(residual_error)</span>
</span><span id="RegressorNormalizer.fit-261"><a href="#RegressorNormalizer.fit-261"><span class="linenos">261</span></a>        <span class="c1">######################################################################</span>
</span><span id="RegressorNormalizer.fit-262"><a href="#RegressorNormalizer.fit-262"><span class="linenos">262</span></a>
</span><span id="RegressorNormalizer.fit-263"><a href="#RegressorNormalizer.fit-263"><span class="linenos">263</span></a>        <span class="n">log_err</span> <span class="o">=</span> <span class="n">residual_error</span>
</span><span id="RegressorNormalizer.fit-264"><a href="#RegressorNormalizer.fit-264"><span class="linenos">264</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">normalizer_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">log_err</span><span class="p">)</span>
</span></pre></div>


    

                                </div>
                                <div id="RegressorNormalizer.score" class="classattr">
                                            <input id="RegressorNormalizer.score-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">score</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span>, </span><span class="param"><span class="n">y</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="RegressorNormalizer.score-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RegressorNormalizer.score"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RegressorNormalizer.score-266"><a href="#RegressorNormalizer.score-266"><span class="linenos">266</span></a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="RegressorNormalizer.score-267"><a href="#RegressorNormalizer.score-267"><span class="linenos">267</span></a>
</span><span id="RegressorNormalizer.score-268"><a href="#RegressorNormalizer.score-268"><span class="linenos">268</span></a>        <span class="c1">######################################################################</span>
</span><span id="RegressorNormalizer.score-269"><a href="#RegressorNormalizer.score-269"><span class="linenos">269</span></a>        <span class="c1"># Optional: use logarithmic function as in the original implementation</span>
</span><span id="RegressorNormalizer.score-270"><a href="#RegressorNormalizer.score-270"><span class="linenos">270</span></a>        <span class="c1"># available in https://github.com/donlnz/nonconformist</span>
</span><span id="RegressorNormalizer.score-271"><a href="#RegressorNormalizer.score-271"><span class="linenos">271</span></a>        <span class="c1">#</span>
</span><span id="RegressorNormalizer.score-272"><a href="#RegressorNormalizer.score-272"><span class="linenos">272</span></a>        <span class="c1"># CODE:</span>
</span><span id="RegressorNormalizer.score-273"><a href="#RegressorNormalizer.score-273"><span class="linenos">273</span></a>        <span class="c1"># norm = np.exp(self.normalizer_model.predict(x))</span>
</span><span id="RegressorNormalizer.score-274"><a href="#RegressorNormalizer.score-274"><span class="linenos">274</span></a>        <span class="c1">######################################################################</span>
</span><span id="RegressorNormalizer.score-275"><a href="#RegressorNormalizer.score-275"><span class="linenos">275</span></a>
</span><span id="RegressorNormalizer.score-276"><a href="#RegressorNormalizer.score-276"><span class="linenos">276</span></a>        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">normalizer_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span><span id="RegressorNormalizer.score-277"><a href="#RegressorNormalizer.score-277"><span class="linenos">277</span></a>        <span class="k">return</span> <span class="n">norm</span>
</span></pre></div>


    

                                </div>
                        
                </section>
                <section id="IcpRegressor">
                            <input id="IcpRegressor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">IcpRegressor</span><wbr>(<span class="base">nnetsauce.nonconformist.icp.BaseIcp</span>, <span class="base">nnetsauce.nonconformist.base.RegressorMixin</span>):

                <label class="view-source-button" for="IcpRegressor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#IcpRegressor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="IcpRegressor-300"><a href="#IcpRegressor-300"><span class="linenos">300</span></a><span class="k">class</span> <span class="nc">IcpRegressor</span><span class="p">(</span><span class="n">BaseIcp</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
</span><span id="IcpRegressor-301"><a href="#IcpRegressor-301"><span class="linenos">301</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Inductive conformal regressor.</span>
</span><span id="IcpRegressor-302"><a href="#IcpRegressor-302"><span class="linenos">302</span></a>
</span><span id="IcpRegressor-303"><a href="#IcpRegressor-303"><span class="linenos">303</span></a><span class="sd">    Parameters</span>
</span><span id="IcpRegressor-304"><a href="#IcpRegressor-304"><span class="linenos">304</span></a><span class="sd">    ----------</span>
</span><span id="IcpRegressor-305"><a href="#IcpRegressor-305"><span class="linenos">305</span></a><span class="sd">    nc_function : BaseScorer</span>
</span><span id="IcpRegressor-306"><a href="#IcpRegressor-306"><span class="linenos">306</span></a><span class="sd">            Nonconformity scorer object used to calculate nonconformity of</span>
</span><span id="IcpRegressor-307"><a href="#IcpRegressor-307"><span class="linenos">307</span></a><span class="sd">            calibration examples and test patterns. Should implement ``fit(x, y)``,</span>
</span><span id="IcpRegressor-308"><a href="#IcpRegressor-308"><span class="linenos">308</span></a><span class="sd">            ``calc_nc(x, y)`` and ``predict(x, nc_scores, significance)``.</span>
</span><span id="IcpRegressor-309"><a href="#IcpRegressor-309"><span class="linenos">309</span></a>
</span><span id="IcpRegressor-310"><a href="#IcpRegressor-310"><span class="linenos">310</span></a><span class="sd">    Attributes</span>
</span><span id="IcpRegressor-311"><a href="#IcpRegressor-311"><span class="linenos">311</span></a><span class="sd">    ----------</span>
</span><span id="IcpRegressor-312"><a href="#IcpRegressor-312"><span class="linenos">312</span></a><span class="sd">    cal_x : numpy array of shape [n_cal_examples, n_features]</span>
</span><span id="IcpRegressor-313"><a href="#IcpRegressor-313"><span class="linenos">313</span></a><span class="sd">            Inputs of calibration set.</span>
</span><span id="IcpRegressor-314"><a href="#IcpRegressor-314"><span class="linenos">314</span></a>
</span><span id="IcpRegressor-315"><a href="#IcpRegressor-315"><span class="linenos">315</span></a><span class="sd">    cal_y : numpy array of shape [n_cal_examples]</span>
</span><span id="IcpRegressor-316"><a href="#IcpRegressor-316"><span class="linenos">316</span></a><span class="sd">            Outputs of calibration set.</span>
</span><span id="IcpRegressor-317"><a href="#IcpRegressor-317"><span class="linenos">317</span></a>
</span><span id="IcpRegressor-318"><a href="#IcpRegressor-318"><span class="linenos">318</span></a><span class="sd">    nc_function : BaseScorer</span>
</span><span id="IcpRegressor-319"><a href="#IcpRegressor-319"><span class="linenos">319</span></a><span class="sd">            Nonconformity scorer object used to calculate nonconformity scores.</span>
</span><span id="IcpRegressor-320"><a href="#IcpRegressor-320"><span class="linenos">320</span></a>
</span><span id="IcpRegressor-321"><a href="#IcpRegressor-321"><span class="linenos">321</span></a><span class="sd">    See also</span>
</span><span id="IcpRegressor-322"><a href="#IcpRegressor-322"><span class="linenos">322</span></a><span class="sd">    --------</span>
</span><span id="IcpRegressor-323"><a href="#IcpRegressor-323"><span class="linenos">323</span></a><span class="sd">    IcpClassifier</span>
</span><span id="IcpRegressor-324"><a href="#IcpRegressor-324"><span class="linenos">324</span></a>
</span><span id="IcpRegressor-325"><a href="#IcpRegressor-325"><span class="linenos">325</span></a><span class="sd">    References</span>
</span><span id="IcpRegressor-326"><a href="#IcpRegressor-326"><span class="linenos">326</span></a><span class="sd">    ----------</span>
</span><span id="IcpRegressor-327"><a href="#IcpRegressor-327"><span class="linenos">327</span></a><span class="sd">    .. [1] Papadopoulos, H., Proedrou, K., Vovk, V., &amp; Gammerman, A. (2002).</span>
</span><span id="IcpRegressor-328"><a href="#IcpRegressor-328"><span class="linenos">328</span></a><span class="sd">            Inductive confidence machines for regression. In Machine Learning: ECML</span>
</span><span id="IcpRegressor-329"><a href="#IcpRegressor-329"><span class="linenos">329</span></a><span class="sd">            2002 (pp. 345-356). Springer Berlin Heidelberg.</span>
</span><span id="IcpRegressor-330"><a href="#IcpRegressor-330"><span class="linenos">330</span></a>
</span><span id="IcpRegressor-331"><a href="#IcpRegressor-331"><span class="linenos">331</span></a><span class="sd">    .. [2] Papadopoulos, H., &amp; Haralambous, H. (2011). Reliable prediction</span>
</span><span id="IcpRegressor-332"><a href="#IcpRegressor-332"><span class="linenos">332</span></a><span class="sd">            intervals with regression neural networks. Neural Networks, 24(8),</span>
</span><span id="IcpRegressor-333"><a href="#IcpRegressor-333"><span class="linenos">333</span></a><span class="sd">            842-851.</span>
</span><span id="IcpRegressor-334"><a href="#IcpRegressor-334"><span class="linenos">334</span></a>
</span><span id="IcpRegressor-335"><a href="#IcpRegressor-335"><span class="linenos">335</span></a><span class="sd">    Examples</span>
</span><span id="IcpRegressor-336"><a href="#IcpRegressor-336"><span class="linenos">336</span></a><span class="sd">    --------</span>
</span><span id="IcpRegressor-337"><a href="#IcpRegressor-337"><span class="linenos">337</span></a><span class="sd">    &gt;&gt;&gt; import numpy as np</span>
</span><span id="IcpRegressor-338"><a href="#IcpRegressor-338"><span class="linenos">338</span></a><span class="sd">    &gt;&gt;&gt; from sklearn.datasets import load_boston</span>
</span><span id="IcpRegressor-339"><a href="#IcpRegressor-339"><span class="linenos">339</span></a><span class="sd">    &gt;&gt;&gt; from sklearn.tree import DecisionTreeRegressor</span>
</span><span id="IcpRegressor-340"><a href="#IcpRegressor-340"><span class="linenos">340</span></a><span class="sd">    &gt;&gt;&gt; from nonconformist.base import RegressorAdapter</span>
</span><span id="IcpRegressor-341"><a href="#IcpRegressor-341"><span class="linenos">341</span></a><span class="sd">    &gt;&gt;&gt; from nonconformist.icp import IcpRegressor</span>
</span><span id="IcpRegressor-342"><a href="#IcpRegressor-342"><span class="linenos">342</span></a><span class="sd">    &gt;&gt;&gt; from nonconformist.nc import RegressorNc, AbsErrorErrFunc</span>
</span><span id="IcpRegressor-343"><a href="#IcpRegressor-343"><span class="linenos">343</span></a><span class="sd">    &gt;&gt;&gt; boston = load_boston()</span>
</span><span id="IcpRegressor-344"><a href="#IcpRegressor-344"><span class="linenos">344</span></a><span class="sd">    &gt;&gt;&gt; idx = np.random.permutation(boston.target.size)</span>
</span><span id="IcpRegressor-345"><a href="#IcpRegressor-345"><span class="linenos">345</span></a><span class="sd">    &gt;&gt;&gt; train = idx[:int(idx.size / 3)]</span>
</span><span id="IcpRegressor-346"><a href="#IcpRegressor-346"><span class="linenos">346</span></a><span class="sd">    &gt;&gt;&gt; cal = idx[int(idx.size / 3):int(2 * idx.size / 3)]</span>
</span><span id="IcpRegressor-347"><a href="#IcpRegressor-347"><span class="linenos">347</span></a><span class="sd">    &gt;&gt;&gt; test = idx[int(2 * idx.size / 3):]</span>
</span><span id="IcpRegressor-348"><a href="#IcpRegressor-348"><span class="linenos">348</span></a><span class="sd">    &gt;&gt;&gt; model = RegressorAdapter(DecisionTreeRegressor())</span>
</span><span id="IcpRegressor-349"><a href="#IcpRegressor-349"><span class="linenos">349</span></a><span class="sd">    &gt;&gt;&gt; nc = RegressorNc(model, AbsErrorErrFunc())</span>
</span><span id="IcpRegressor-350"><a href="#IcpRegressor-350"><span class="linenos">350</span></a><span class="sd">    &gt;&gt;&gt; icp = IcpRegressor(nc)</span>
</span><span id="IcpRegressor-351"><a href="#IcpRegressor-351"><span class="linenos">351</span></a><span class="sd">    &gt;&gt;&gt; icp.fit(boston.data[train, :], boston.target[train])</span>
</span><span id="IcpRegressor-352"><a href="#IcpRegressor-352"><span class="linenos">352</span></a><span class="sd">    &gt;&gt;&gt; icp.calibrate(boston.data[cal, :], boston.target[cal])</span>
</span><span id="IcpRegressor-353"><a href="#IcpRegressor-353"><span class="linenos">353</span></a><span class="sd">    &gt;&gt;&gt; icp.predict(boston.data[test, :], significance=0.10)</span>
</span><span id="IcpRegressor-354"><a href="#IcpRegressor-354"><span class="linenos">354</span></a><span class="sd">    ...     # doctest: +SKIP</span>
</span><span id="IcpRegressor-355"><a href="#IcpRegressor-355"><span class="linenos">355</span></a><span class="sd">    array([[  5. ,  20.6],</span>
</span><span id="IcpRegressor-356"><a href="#IcpRegressor-356"><span class="linenos">356</span></a><span class="sd">            [ 15.5,  31.1],</span>
</span><span id="IcpRegressor-357"><a href="#IcpRegressor-357"><span class="linenos">357</span></a><span class="sd">            ...,</span>
</span><span id="IcpRegressor-358"><a href="#IcpRegressor-358"><span class="linenos">358</span></a><span class="sd">            [ 14.2,  29.8],</span>
</span><span id="IcpRegressor-359"><a href="#IcpRegressor-359"><span class="linenos">359</span></a><span class="sd">            [ 11.6,  27.2]])</span>
</span><span id="IcpRegressor-360"><a href="#IcpRegressor-360"><span class="linenos">360</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="IcpRegressor-361"><a href="#IcpRegressor-361"><span class="linenos">361</span></a>
</span><span id="IcpRegressor-362"><a href="#IcpRegressor-362"><span class="linenos">362</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nc_function</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="IcpRegressor-363"><a href="#IcpRegressor-363"><span class="linenos">363</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">IcpRegressor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">nc_function</span><span class="p">,</span> <span class="n">condition</span><span class="p">)</span>
</span><span id="IcpRegressor-364"><a href="#IcpRegressor-364"><span class="linenos">364</span></a>
</span><span id="IcpRegressor-365"><a href="#IcpRegressor-365"><span class="linenos">365</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="IcpRegressor-366"><a href="#IcpRegressor-366"><span class="linenos">366</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict the output values for a set of input patterns.</span>
</span><span id="IcpRegressor-367"><a href="#IcpRegressor-367"><span class="linenos">367</span></a>
</span><span id="IcpRegressor-368"><a href="#IcpRegressor-368"><span class="linenos">368</span></a><span class="sd">        Parameters</span>
</span><span id="IcpRegressor-369"><a href="#IcpRegressor-369"><span class="linenos">369</span></a><span class="sd">        ----------</span>
</span><span id="IcpRegressor-370"><a href="#IcpRegressor-370"><span class="linenos">370</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="IcpRegressor-371"><a href="#IcpRegressor-371"><span class="linenos">371</span></a><span class="sd">                Inputs of patters for which to predict output values.</span>
</span><span id="IcpRegressor-372"><a href="#IcpRegressor-372"><span class="linenos">372</span></a>
</span><span id="IcpRegressor-373"><a href="#IcpRegressor-373"><span class="linenos">373</span></a><span class="sd">        significance : float</span>
</span><span id="IcpRegressor-374"><a href="#IcpRegressor-374"><span class="linenos">374</span></a><span class="sd">                Significance level (maximum allowed error rate) of predictions.</span>
</span><span id="IcpRegressor-375"><a href="#IcpRegressor-375"><span class="linenos">375</span></a><span class="sd">                Should be a float between 0 and 1. If ``None``, then intervals for</span>
</span><span id="IcpRegressor-376"><a href="#IcpRegressor-376"><span class="linenos">376</span></a><span class="sd">                all significance levels (0.01, 0.02, ..., 0.99) are output in a</span>
</span><span id="IcpRegressor-377"><a href="#IcpRegressor-377"><span class="linenos">377</span></a><span class="sd">                3d-matrix.</span>
</span><span id="IcpRegressor-378"><a href="#IcpRegressor-378"><span class="linenos">378</span></a>
</span><span id="IcpRegressor-379"><a href="#IcpRegressor-379"><span class="linenos">379</span></a><span class="sd">        Returns</span>
</span><span id="IcpRegressor-380"><a href="#IcpRegressor-380"><span class="linenos">380</span></a><span class="sd">        -------</span>
</span><span id="IcpRegressor-381"><a href="#IcpRegressor-381"><span class="linenos">381</span></a><span class="sd">        p : numpy array of shape [n_samples, 2] or [n_samples, 2, 99}</span>
</span><span id="IcpRegressor-382"><a href="#IcpRegressor-382"><span class="linenos">382</span></a><span class="sd">                If significance is ``None``, then p contains the interval (minimum</span>
</span><span id="IcpRegressor-383"><a href="#IcpRegressor-383"><span class="linenos">383</span></a><span class="sd">                and maximum boundaries) for each test pattern, and each significance</span>
</span><span id="IcpRegressor-384"><a href="#IcpRegressor-384"><span class="linenos">384</span></a><span class="sd">                level (0.01, 0.02, ..., 0.99). If significance is a float between</span>
</span><span id="IcpRegressor-385"><a href="#IcpRegressor-385"><span class="linenos">385</span></a><span class="sd">                0 and 1, then p contains the prediction intervals (minimum and</span>
</span><span id="IcpRegressor-386"><a href="#IcpRegressor-386"><span class="linenos">386</span></a><span class="sd">                maximum	boundaries) for the set of test patterns at the chosen</span>
</span><span id="IcpRegressor-387"><a href="#IcpRegressor-387"><span class="linenos">387</span></a><span class="sd">                significance level.</span>
</span><span id="IcpRegressor-388"><a href="#IcpRegressor-388"><span class="linenos">388</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="IcpRegressor-389"><a href="#IcpRegressor-389"><span class="linenos">389</span></a>        <span class="c1"># TODO: interpolated p-values</span>
</span><span id="IcpRegressor-390"><a href="#IcpRegressor-390"><span class="linenos">390</span></a>
</span><span id="IcpRegressor-391"><a href="#IcpRegressor-391"><span class="linenos">391</span></a>        <span class="n">n_significance</span> <span class="o">=</span> <span class="mi">99</span> <span class="k">if</span> <span class="n">significance</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">significance</span><span class="p">)</span><span class="o">.</span><span class="n">size</span>
</span><span id="IcpRegressor-392"><a href="#IcpRegressor-392"><span class="linenos">392</span></a>
</span><span id="IcpRegressor-393"><a href="#IcpRegressor-393"><span class="linenos">393</span></a>        <span class="k">if</span> <span class="n">n_significance</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="IcpRegressor-394"><a href="#IcpRegressor-394"><span class="linenos">394</span></a>            <span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_significance</span><span class="p">))</span>
</span><span id="IcpRegressor-395"><a href="#IcpRegressor-395"><span class="linenos">395</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="IcpRegressor-396"><a href="#IcpRegressor-396"><span class="linenos">396</span></a>            <span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>
</span><span id="IcpRegressor-397"><a href="#IcpRegressor-397"><span class="linenos">397</span></a>
</span><span id="IcpRegressor-398"><a href="#IcpRegressor-398"><span class="linenos">398</span></a>        <span class="n">condition_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="IcpRegressor-399"><a href="#IcpRegressor-399"><span class="linenos">399</span></a>            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">condition</span><span class="p">((</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="kc">None</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
</span><span id="IcpRegressor-400"><a href="#IcpRegressor-400"><span class="linenos">400</span></a>        <span class="p">)</span>
</span><span id="IcpRegressor-401"><a href="#IcpRegressor-401"><span class="linenos">401</span></a>
</span><span id="IcpRegressor-402"><a href="#IcpRegressor-402"><span class="linenos">402</span></a>        <span class="k">for</span> <span class="n">condition</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">categories</span><span class="p">:</span>
</span><span id="IcpRegressor-403"><a href="#IcpRegressor-403"><span class="linenos">403</span></a>            <span class="n">idx</span> <span class="o">=</span> <span class="n">condition_map</span> <span class="o">==</span> <span class="n">condition</span>
</span><span id="IcpRegressor-404"><a href="#IcpRegressor-404"><span class="linenos">404</span></a>            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="IcpRegressor-405"><a href="#IcpRegressor-405"><span class="linenos">405</span></a>                <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nc_function</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
</span><span id="IcpRegressor-406"><a href="#IcpRegressor-406"><span class="linenos">406</span></a>                    <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cal_scores</span><span class="p">[</span><span class="n">condition</span><span class="p">],</span> <span class="n">significance</span>
</span><span id="IcpRegressor-407"><a href="#IcpRegressor-407"><span class="linenos">407</span></a>                <span class="p">)</span>
</span><span id="IcpRegressor-408"><a href="#IcpRegressor-408"><span class="linenos">408</span></a>                <span class="k">if</span> <span class="n">n_significance</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="IcpRegressor-409"><a href="#IcpRegressor-409"><span class="linenos">409</span></a>                    <span class="n">prediction</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">p</span>
</span><span id="IcpRegressor-410"><a href="#IcpRegressor-410"><span class="linenos">410</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="IcpRegressor-411"><a href="#IcpRegressor-411"><span class="linenos">411</span></a>                    <span class="n">prediction</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">p</span>
</span><span id="IcpRegressor-412"><a href="#IcpRegressor-412"><span class="linenos">412</span></a>
</span><span id="IcpRegressor-413"><a href="#IcpRegressor-413"><span class="linenos">413</span></a>        <span class="k">return</span> <span class="n">prediction</span>
</span></pre></div>


            <div class="docstring"><p>Inductive conformal regressor.</p>

<h2 id="parameters">Parameters</h2>

<p>nc_function : BaseScorer
        Nonconformity scorer object used to calculate nonconformity of
        calibration examples and test patterns. Should implement <code>fit(x, y)</code>,
        <code>calc_nc(x, y)</code> and <code>predict(x, nc_scores, significance)</code>.</p>

<h2 id="attributes">Attributes</h2>

<p>cal_x : numpy array of shape [n_cal_examples, n_features]
        Inputs of calibration set.</p>

<p>cal_y : numpy array of shape [n_cal_examples]
        Outputs of calibration set.</p>

<p>nc_function : BaseScorer
        Nonconformity scorer object used to calculate nonconformity scores.</p>

<h2 id="see-also">See also</h2>

<p>IcpClassifier</p>

<h2 id="references">References</h2>

<h2 id="examples">Examples</h2>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nonconformist.base</span> <span class="kn">import</span> <span class="n">RegressorAdapter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nonconformist.icp</span> <span class="kn">import</span> <span class="n">IcpRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nonconformist.nc</span> <span class="kn">import</span> <span class="n">RegressorNc</span><span class="p">,</span> <span class="n">AbsErrorErrFunc</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">3</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cal</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">3</span><span class="p">):</span><span class="nb">int</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">3</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">3</span><span class="p">):]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">RegressorAdapter</span><span class="p">(</span><span class="n">DecisionTreeRegressor</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nc</span> <span class="o">=</span> <span class="n">RegressorNc</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">AbsErrorErrFunc</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">icp</span> <span class="o">=</span> <span class="n">IcpRegressor</span><span class="p">(</span><span class="n">nc</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">icp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">icp</span><span class="o">.</span><span class="n">calibrate</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">cal</span><span class="p">,</span> <span class="p">:],</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">cal</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">icp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:],</span> <span class="n">significance</span><span class="o">=</span><span class="mf">0.10</span><span class="p">)</span>
<span class="gp">... </span>    <span class="c1"># doctest: +SKIP</span>
<span class="go">array([[  5. ,  20.6],</span>
<span class="go">        [ 15.5,  31.1],</span>
<span class="go">        ...,</span>
<span class="go">        [ 14.2,  29.8],</span>
<span class="go">        [ 11.6,  27.2]])</span>
</code></pre>
</div>

<div class="footnotes">
<hr />
<ol>
</ol>
</div>
</div>


                                <div id="IcpRegressor.predict" class="classattr">
                                            <input id="IcpRegressor.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span>, </span><span class="param"><span class="n">significance</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="IcpRegressor.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#IcpRegressor.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="IcpRegressor.predict-365"><a href="#IcpRegressor.predict-365"><span class="linenos">365</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="IcpRegressor.predict-366"><a href="#IcpRegressor.predict-366"><span class="linenos">366</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict the output values for a set of input patterns.</span>
</span><span id="IcpRegressor.predict-367"><a href="#IcpRegressor.predict-367"><span class="linenos">367</span></a>
</span><span id="IcpRegressor.predict-368"><a href="#IcpRegressor.predict-368"><span class="linenos">368</span></a><span class="sd">        Parameters</span>
</span><span id="IcpRegressor.predict-369"><a href="#IcpRegressor.predict-369"><span class="linenos">369</span></a><span class="sd">        ----------</span>
</span><span id="IcpRegressor.predict-370"><a href="#IcpRegressor.predict-370"><span class="linenos">370</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="IcpRegressor.predict-371"><a href="#IcpRegressor.predict-371"><span class="linenos">371</span></a><span class="sd">                Inputs of patters for which to predict output values.</span>
</span><span id="IcpRegressor.predict-372"><a href="#IcpRegressor.predict-372"><span class="linenos">372</span></a>
</span><span id="IcpRegressor.predict-373"><a href="#IcpRegressor.predict-373"><span class="linenos">373</span></a><span class="sd">        significance : float</span>
</span><span id="IcpRegressor.predict-374"><a href="#IcpRegressor.predict-374"><span class="linenos">374</span></a><span class="sd">                Significance level (maximum allowed error rate) of predictions.</span>
</span><span id="IcpRegressor.predict-375"><a href="#IcpRegressor.predict-375"><span class="linenos">375</span></a><span class="sd">                Should be a float between 0 and 1. If ``None``, then intervals for</span>
</span><span id="IcpRegressor.predict-376"><a href="#IcpRegressor.predict-376"><span class="linenos">376</span></a><span class="sd">                all significance levels (0.01, 0.02, ..., 0.99) are output in a</span>
</span><span id="IcpRegressor.predict-377"><a href="#IcpRegressor.predict-377"><span class="linenos">377</span></a><span class="sd">                3d-matrix.</span>
</span><span id="IcpRegressor.predict-378"><a href="#IcpRegressor.predict-378"><span class="linenos">378</span></a>
</span><span id="IcpRegressor.predict-379"><a href="#IcpRegressor.predict-379"><span class="linenos">379</span></a><span class="sd">        Returns</span>
</span><span id="IcpRegressor.predict-380"><a href="#IcpRegressor.predict-380"><span class="linenos">380</span></a><span class="sd">        -------</span>
</span><span id="IcpRegressor.predict-381"><a href="#IcpRegressor.predict-381"><span class="linenos">381</span></a><span class="sd">        p : numpy array of shape [n_samples, 2] or [n_samples, 2, 99}</span>
</span><span id="IcpRegressor.predict-382"><a href="#IcpRegressor.predict-382"><span class="linenos">382</span></a><span class="sd">                If significance is ``None``, then p contains the interval (minimum</span>
</span><span id="IcpRegressor.predict-383"><a href="#IcpRegressor.predict-383"><span class="linenos">383</span></a><span class="sd">                and maximum boundaries) for each test pattern, and each significance</span>
</span><span id="IcpRegressor.predict-384"><a href="#IcpRegressor.predict-384"><span class="linenos">384</span></a><span class="sd">                level (0.01, 0.02, ..., 0.99). If significance is a float between</span>
</span><span id="IcpRegressor.predict-385"><a href="#IcpRegressor.predict-385"><span class="linenos">385</span></a><span class="sd">                0 and 1, then p contains the prediction intervals (minimum and</span>
</span><span id="IcpRegressor.predict-386"><a href="#IcpRegressor.predict-386"><span class="linenos">386</span></a><span class="sd">                maximum	boundaries) for the set of test patterns at the chosen</span>
</span><span id="IcpRegressor.predict-387"><a href="#IcpRegressor.predict-387"><span class="linenos">387</span></a><span class="sd">                significance level.</span>
</span><span id="IcpRegressor.predict-388"><a href="#IcpRegressor.predict-388"><span class="linenos">388</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="IcpRegressor.predict-389"><a href="#IcpRegressor.predict-389"><span class="linenos">389</span></a>        <span class="c1"># TODO: interpolated p-values</span>
</span><span id="IcpRegressor.predict-390"><a href="#IcpRegressor.predict-390"><span class="linenos">390</span></a>
</span><span id="IcpRegressor.predict-391"><a href="#IcpRegressor.predict-391"><span class="linenos">391</span></a>        <span class="n">n_significance</span> <span class="o">=</span> <span class="mi">99</span> <span class="k">if</span> <span class="n">significance</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">significance</span><span class="p">)</span><span class="o">.</span><span class="n">size</span>
</span><span id="IcpRegressor.predict-392"><a href="#IcpRegressor.predict-392"><span class="linenos">392</span></a>
</span><span id="IcpRegressor.predict-393"><a href="#IcpRegressor.predict-393"><span class="linenos">393</span></a>        <span class="k">if</span> <span class="n">n_significance</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="IcpRegressor.predict-394"><a href="#IcpRegressor.predict-394"><span class="linenos">394</span></a>            <span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_significance</span><span class="p">))</span>
</span><span id="IcpRegressor.predict-395"><a href="#IcpRegressor.predict-395"><span class="linenos">395</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="IcpRegressor.predict-396"><a href="#IcpRegressor.predict-396"><span class="linenos">396</span></a>            <span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>
</span><span id="IcpRegressor.predict-397"><a href="#IcpRegressor.predict-397"><span class="linenos">397</span></a>
</span><span id="IcpRegressor.predict-398"><a href="#IcpRegressor.predict-398"><span class="linenos">398</span></a>        <span class="n">condition_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="IcpRegressor.predict-399"><a href="#IcpRegressor.predict-399"><span class="linenos">399</span></a>            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">condition</span><span class="p">((</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="kc">None</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
</span><span id="IcpRegressor.predict-400"><a href="#IcpRegressor.predict-400"><span class="linenos">400</span></a>        <span class="p">)</span>
</span><span id="IcpRegressor.predict-401"><a href="#IcpRegressor.predict-401"><span class="linenos">401</span></a>
</span><span id="IcpRegressor.predict-402"><a href="#IcpRegressor.predict-402"><span class="linenos">402</span></a>        <span class="k">for</span> <span class="n">condition</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">categories</span><span class="p">:</span>
</span><span id="IcpRegressor.predict-403"><a href="#IcpRegressor.predict-403"><span class="linenos">403</span></a>            <span class="n">idx</span> <span class="o">=</span> <span class="n">condition_map</span> <span class="o">==</span> <span class="n">condition</span>
</span><span id="IcpRegressor.predict-404"><a href="#IcpRegressor.predict-404"><span class="linenos">404</span></a>            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="IcpRegressor.predict-405"><a href="#IcpRegressor.predict-405"><span class="linenos">405</span></a>                <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nc_function</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
</span><span id="IcpRegressor.predict-406"><a href="#IcpRegressor.predict-406"><span class="linenos">406</span></a>                    <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cal_scores</span><span class="p">[</span><span class="n">condition</span><span class="p">],</span> <span class="n">significance</span>
</span><span id="IcpRegressor.predict-407"><a href="#IcpRegressor.predict-407"><span class="linenos">407</span></a>                <span class="p">)</span>
</span><span id="IcpRegressor.predict-408"><a href="#IcpRegressor.predict-408"><span class="linenos">408</span></a>                <span class="k">if</span> <span class="n">n_significance</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="IcpRegressor.predict-409"><a href="#IcpRegressor.predict-409"><span class="linenos">409</span></a>                    <span class="n">prediction</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">p</span>
</span><span id="IcpRegressor.predict-410"><a href="#IcpRegressor.predict-410"><span class="linenos">410</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="IcpRegressor.predict-411"><a href="#IcpRegressor.predict-411"><span class="linenos">411</span></a>                    <span class="n">prediction</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">p</span>
</span><span id="IcpRegressor.predict-412"><a href="#IcpRegressor.predict-412"><span class="linenos">412</span></a>
</span><span id="IcpRegressor.predict-413"><a href="#IcpRegressor.predict-413"><span class="linenos">413</span></a>        <span class="k">return</span> <span class="n">prediction</span>
</span></pre></div>


            <div class="docstring"><p>Predict the output values for a set of input patterns.</p>

<h2 id="parameters">Parameters</h2>

<p>x : numpy array of shape [n_samples, n_features]
        Inputs of patters for which to predict output values.</p>

<p>significance : float
        Significance level (maximum allowed error rate) of predictions.
        Should be a float between 0 and 1. If <code>None</code>, then intervals for
        all significance levels (0.01, 0.02, ..., 0.99) are output in a
        3d-matrix.</p>

<h2 id="returns">Returns</h2>

<p>p : numpy array of shape [n_samples, 2] or [n_samples, 2, 99}
        If significance is <code>None</code>, then p contains the interval (minimum
        and maximum boundaries) for each test pattern, and each significance
        level (0.01, 0.02, ..., 0.99). If significance is a float between
        0 and 1, then p contains the prediction intervals (minimum and
        maximum boundaries) for the set of test patterns at the chosen
        significance level.</p>
</div>


                                </div>
                        
                </section>
                <section id="IcpClassifier">
                            <input id="IcpClassifier-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">IcpClassifier</span><wbr>(<span class="base">nnetsauce.nonconformist.icp.BaseIcp</span>, <span class="base">nnetsauce.nonconformist.base.ClassifierMixin</span>):

                <label class="view-source-button" for="IcpClassifier-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#IcpClassifier"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="IcpClassifier-125"><a href="#IcpClassifier-125"><span class="linenos">125</span></a><span class="k">class</span> <span class="nc">IcpClassifier</span><span class="p">(</span><span class="n">BaseIcp</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
</span><span id="IcpClassifier-126"><a href="#IcpClassifier-126"><span class="linenos">126</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Inductive conformal classifier.</span>
</span><span id="IcpClassifier-127"><a href="#IcpClassifier-127"><span class="linenos">127</span></a>
</span><span id="IcpClassifier-128"><a href="#IcpClassifier-128"><span class="linenos">128</span></a><span class="sd">    Parameters</span>
</span><span id="IcpClassifier-129"><a href="#IcpClassifier-129"><span class="linenos">129</span></a><span class="sd">    ----------</span>
</span><span id="IcpClassifier-130"><a href="#IcpClassifier-130"><span class="linenos">130</span></a><span class="sd">    nc_function : BaseScorer</span>
</span><span id="IcpClassifier-131"><a href="#IcpClassifier-131"><span class="linenos">131</span></a><span class="sd">            Nonconformity scorer object used to calculate nonconformity of</span>
</span><span id="IcpClassifier-132"><a href="#IcpClassifier-132"><span class="linenos">132</span></a><span class="sd">            calibration examples and test patterns. Should implement ``fit(x, y)``</span>
</span><span id="IcpClassifier-133"><a href="#IcpClassifier-133"><span class="linenos">133</span></a><span class="sd">            and ``calc_nc(x, y)``.</span>
</span><span id="IcpClassifier-134"><a href="#IcpClassifier-134"><span class="linenos">134</span></a>
</span><span id="IcpClassifier-135"><a href="#IcpClassifier-135"><span class="linenos">135</span></a><span class="sd">    smoothing : boolean</span>
</span><span id="IcpClassifier-136"><a href="#IcpClassifier-136"><span class="linenos">136</span></a><span class="sd">            Decides whether to use stochastic smoothing of p-values.</span>
</span><span id="IcpClassifier-137"><a href="#IcpClassifier-137"><span class="linenos">137</span></a>
</span><span id="IcpClassifier-138"><a href="#IcpClassifier-138"><span class="linenos">138</span></a><span class="sd">    Attributes</span>
</span><span id="IcpClassifier-139"><a href="#IcpClassifier-139"><span class="linenos">139</span></a><span class="sd">    ----------</span>
</span><span id="IcpClassifier-140"><a href="#IcpClassifier-140"><span class="linenos">140</span></a><span class="sd">    cal_x : numpy array of shape [n_cal_examples, n_features]</span>
</span><span id="IcpClassifier-141"><a href="#IcpClassifier-141"><span class="linenos">141</span></a><span class="sd">            Inputs of calibration set.</span>
</span><span id="IcpClassifier-142"><a href="#IcpClassifier-142"><span class="linenos">142</span></a>
</span><span id="IcpClassifier-143"><a href="#IcpClassifier-143"><span class="linenos">143</span></a><span class="sd">    cal_y : numpy array of shape [n_cal_examples]</span>
</span><span id="IcpClassifier-144"><a href="#IcpClassifier-144"><span class="linenos">144</span></a><span class="sd">            Outputs of calibration set.</span>
</span><span id="IcpClassifier-145"><a href="#IcpClassifier-145"><span class="linenos">145</span></a>
</span><span id="IcpClassifier-146"><a href="#IcpClassifier-146"><span class="linenos">146</span></a><span class="sd">    nc_function : BaseScorer</span>
</span><span id="IcpClassifier-147"><a href="#IcpClassifier-147"><span class="linenos">147</span></a><span class="sd">            Nonconformity scorer object used to calculate nonconformity scores.</span>
</span><span id="IcpClassifier-148"><a href="#IcpClassifier-148"><span class="linenos">148</span></a>
</span><span id="IcpClassifier-149"><a href="#IcpClassifier-149"><span class="linenos">149</span></a><span class="sd">    classes : numpy array of shape [n_classes]</span>
</span><span id="IcpClassifier-150"><a href="#IcpClassifier-150"><span class="linenos">150</span></a><span class="sd">            List of class labels, with indices corresponding to output columns</span>
</span><span id="IcpClassifier-151"><a href="#IcpClassifier-151"><span class="linenos">151</span></a><span class="sd">             of IcpClassifier.predict()</span>
</span><span id="IcpClassifier-152"><a href="#IcpClassifier-152"><span class="linenos">152</span></a>
</span><span id="IcpClassifier-153"><a href="#IcpClassifier-153"><span class="linenos">153</span></a><span class="sd">    See also</span>
</span><span id="IcpClassifier-154"><a href="#IcpClassifier-154"><span class="linenos">154</span></a><span class="sd">    --------</span>
</span><span id="IcpClassifier-155"><a href="#IcpClassifier-155"><span class="linenos">155</span></a><span class="sd">    IcpRegressor</span>
</span><span id="IcpClassifier-156"><a href="#IcpClassifier-156"><span class="linenos">156</span></a>
</span><span id="IcpClassifier-157"><a href="#IcpClassifier-157"><span class="linenos">157</span></a><span class="sd">    References</span>
</span><span id="IcpClassifier-158"><a href="#IcpClassifier-158"><span class="linenos">158</span></a><span class="sd">    ----------</span>
</span><span id="IcpClassifier-159"><a href="#IcpClassifier-159"><span class="linenos">159</span></a><span class="sd">    .. [1] Papadopoulos, H., &amp; Haralambous, H. (2011). Reliable prediction</span>
</span><span id="IcpClassifier-160"><a href="#IcpClassifier-160"><span class="linenos">160</span></a><span class="sd">            intervals with regression neural networks. Neural Networks, 24(8),</span>
</span><span id="IcpClassifier-161"><a href="#IcpClassifier-161"><span class="linenos">161</span></a><span class="sd">            842-851.</span>
</span><span id="IcpClassifier-162"><a href="#IcpClassifier-162"><span class="linenos">162</span></a>
</span><span id="IcpClassifier-163"><a href="#IcpClassifier-163"><span class="linenos">163</span></a><span class="sd">    Examples</span>
</span><span id="IcpClassifier-164"><a href="#IcpClassifier-164"><span class="linenos">164</span></a><span class="sd">    --------</span>
</span><span id="IcpClassifier-165"><a href="#IcpClassifier-165"><span class="linenos">165</span></a><span class="sd">    &gt;&gt;&gt; import numpy as np</span>
</span><span id="IcpClassifier-166"><a href="#IcpClassifier-166"><span class="linenos">166</span></a><span class="sd">    &gt;&gt;&gt; from sklearn.datasets import load_iris</span>
</span><span id="IcpClassifier-167"><a href="#IcpClassifier-167"><span class="linenos">167</span></a><span class="sd">    &gt;&gt;&gt; from sklearn.tree import DecisionTreeClassifier</span>
</span><span id="IcpClassifier-168"><a href="#IcpClassifier-168"><span class="linenos">168</span></a><span class="sd">    &gt;&gt;&gt; from nonconformist.base import ClassifierAdapter</span>
</span><span id="IcpClassifier-169"><a href="#IcpClassifier-169"><span class="linenos">169</span></a><span class="sd">    &gt;&gt;&gt; from nonconformist.icp import IcpClassifier</span>
</span><span id="IcpClassifier-170"><a href="#IcpClassifier-170"><span class="linenos">170</span></a><span class="sd">    &gt;&gt;&gt; from nonconformist.nc import ClassifierNc, MarginErrFunc</span>
</span><span id="IcpClassifier-171"><a href="#IcpClassifier-171"><span class="linenos">171</span></a><span class="sd">    &gt;&gt;&gt; iris = load_iris()</span>
</span><span id="IcpClassifier-172"><a href="#IcpClassifier-172"><span class="linenos">172</span></a><span class="sd">    &gt;&gt;&gt; idx = np.random.permutation(iris.target.size)</span>
</span><span id="IcpClassifier-173"><a href="#IcpClassifier-173"><span class="linenos">173</span></a><span class="sd">    &gt;&gt;&gt; train = idx[:int(idx.size / 3)]</span>
</span><span id="IcpClassifier-174"><a href="#IcpClassifier-174"><span class="linenos">174</span></a><span class="sd">    &gt;&gt;&gt; cal = idx[int(idx.size / 3):int(2 * idx.size / 3)]</span>
</span><span id="IcpClassifier-175"><a href="#IcpClassifier-175"><span class="linenos">175</span></a><span class="sd">    &gt;&gt;&gt; test = idx[int(2 * idx.size / 3):]</span>
</span><span id="IcpClassifier-176"><a href="#IcpClassifier-176"><span class="linenos">176</span></a><span class="sd">    &gt;&gt;&gt; model = ClassifierAdapter(DecisionTreeClassifier())</span>
</span><span id="IcpClassifier-177"><a href="#IcpClassifier-177"><span class="linenos">177</span></a><span class="sd">    &gt;&gt;&gt; nc = ClassifierNc(model, MarginErrFunc())</span>
</span><span id="IcpClassifier-178"><a href="#IcpClassifier-178"><span class="linenos">178</span></a><span class="sd">    &gt;&gt;&gt; icp = IcpClassifier(nc)</span>
</span><span id="IcpClassifier-179"><a href="#IcpClassifier-179"><span class="linenos">179</span></a><span class="sd">    &gt;&gt;&gt; icp.fit(iris.data[train, :], iris.target[train])</span>
</span><span id="IcpClassifier-180"><a href="#IcpClassifier-180"><span class="linenos">180</span></a><span class="sd">    &gt;&gt;&gt; icp.calibrate(iris.data[cal, :], iris.target[cal])</span>
</span><span id="IcpClassifier-181"><a href="#IcpClassifier-181"><span class="linenos">181</span></a><span class="sd">    &gt;&gt;&gt; icp.predict(iris.data[test, :], significance=0.10)</span>
</span><span id="IcpClassifier-182"><a href="#IcpClassifier-182"><span class="linenos">182</span></a><span class="sd">    ...             # doctest: +SKIP</span>
</span><span id="IcpClassifier-183"><a href="#IcpClassifier-183"><span class="linenos">183</span></a><span class="sd">    array([[ True, False, False],</span>
</span><span id="IcpClassifier-184"><a href="#IcpClassifier-184"><span class="linenos">184</span></a><span class="sd">            [False,  True, False],</span>
</span><span id="IcpClassifier-185"><a href="#IcpClassifier-185"><span class="linenos">185</span></a><span class="sd">            ...,</span>
</span><span id="IcpClassifier-186"><a href="#IcpClassifier-186"><span class="linenos">186</span></a><span class="sd">            [False,  True, False],</span>
</span><span id="IcpClassifier-187"><a href="#IcpClassifier-187"><span class="linenos">187</span></a><span class="sd">            [False,  True, False]], dtype=bool)</span>
</span><span id="IcpClassifier-188"><a href="#IcpClassifier-188"><span class="linenos">188</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="IcpClassifier-189"><a href="#IcpClassifier-189"><span class="linenos">189</span></a>
</span><span id="IcpClassifier-190"><a href="#IcpClassifier-190"><span class="linenos">190</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nc_function</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">smoothing</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="IcpClassifier-191"><a href="#IcpClassifier-191"><span class="linenos">191</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">IcpClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">nc_function</span><span class="p">,</span> <span class="n">condition</span><span class="p">)</span>
</span><span id="IcpClassifier-192"><a href="#IcpClassifier-192"><span class="linenos">192</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="IcpClassifier-193"><a href="#IcpClassifier-193"><span class="linenos">193</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span> <span class="o">=</span> <span class="n">smoothing</span>
</span><span id="IcpClassifier-194"><a href="#IcpClassifier-194"><span class="linenos">194</span></a>
</span><span id="IcpClassifier-195"><a href="#IcpClassifier-195"><span class="linenos">195</span></a>    <span class="k">def</span> <span class="nf">_calibrate_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">increment</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="IcpClassifier-196"><a href="#IcpClassifier-196"><span class="linenos">196</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_update_classes</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">increment</span><span class="p">)</span>
</span><span id="IcpClassifier-197"><a href="#IcpClassifier-197"><span class="linenos">197</span></a>
</span><span id="IcpClassifier-198"><a href="#IcpClassifier-198"><span class="linenos">198</span></a>    <span class="k">def</span> <span class="nf">_update_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">increment</span><span class="p">):</span>
</span><span id="IcpClassifier-199"><a href="#IcpClassifier-199"><span class="linenos">199</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">increment</span><span class="p">:</span>
</span><span id="IcpClassifier-200"><a href="#IcpClassifier-200"><span class="linenos">200</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="IcpClassifier-201"><a href="#IcpClassifier-201"><span class="linenos">201</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="IcpClassifier-202"><a href="#IcpClassifier-202"><span class="linenos">202</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">y</span><span class="p">]))</span>
</span><span id="IcpClassifier-203"><a href="#IcpClassifier-203"><span class="linenos">203</span></a>
</span><span id="IcpClassifier-204"><a href="#IcpClassifier-204"><span class="linenos">204</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="IcpClassifier-205"><a href="#IcpClassifier-205"><span class="linenos">205</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict the output values for a set of input patterns.</span>
</span><span id="IcpClassifier-206"><a href="#IcpClassifier-206"><span class="linenos">206</span></a>
</span><span id="IcpClassifier-207"><a href="#IcpClassifier-207"><span class="linenos">207</span></a><span class="sd">        Parameters</span>
</span><span id="IcpClassifier-208"><a href="#IcpClassifier-208"><span class="linenos">208</span></a><span class="sd">        ----------</span>
</span><span id="IcpClassifier-209"><a href="#IcpClassifier-209"><span class="linenos">209</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="IcpClassifier-210"><a href="#IcpClassifier-210"><span class="linenos">210</span></a><span class="sd">                Inputs of patters for which to predict output values.</span>
</span><span id="IcpClassifier-211"><a href="#IcpClassifier-211"><span class="linenos">211</span></a>
</span><span id="IcpClassifier-212"><a href="#IcpClassifier-212"><span class="linenos">212</span></a><span class="sd">        significance : float or None</span>
</span><span id="IcpClassifier-213"><a href="#IcpClassifier-213"><span class="linenos">213</span></a><span class="sd">                Significance level (maximum allowed error rate) of predictions.</span>
</span><span id="IcpClassifier-214"><a href="#IcpClassifier-214"><span class="linenos">214</span></a><span class="sd">                Should be a float between 0 and 1. If ``None``, then the p-values</span>
</span><span id="IcpClassifier-215"><a href="#IcpClassifier-215"><span class="linenos">215</span></a><span class="sd">                are output rather than the predictions.</span>
</span><span id="IcpClassifier-216"><a href="#IcpClassifier-216"><span class="linenos">216</span></a>
</span><span id="IcpClassifier-217"><a href="#IcpClassifier-217"><span class="linenos">217</span></a><span class="sd">        Returns</span>
</span><span id="IcpClassifier-218"><a href="#IcpClassifier-218"><span class="linenos">218</span></a><span class="sd">        -------</span>
</span><span id="IcpClassifier-219"><a href="#IcpClassifier-219"><span class="linenos">219</span></a><span class="sd">        p : numpy array of shape [n_samples, n_classes]</span>
</span><span id="IcpClassifier-220"><a href="#IcpClassifier-220"><span class="linenos">220</span></a><span class="sd">                If significance is ``None``, then p contains the p-values for each</span>
</span><span id="IcpClassifier-221"><a href="#IcpClassifier-221"><span class="linenos">221</span></a><span class="sd">                sample-class pair; if significance is a float between 0 and 1, then</span>
</span><span id="IcpClassifier-222"><a href="#IcpClassifier-222"><span class="linenos">222</span></a><span class="sd">                p is a boolean array denoting which labels are included in the</span>
</span><span id="IcpClassifier-223"><a href="#IcpClassifier-223"><span class="linenos">223</span></a><span class="sd">                prediction sets.</span>
</span><span id="IcpClassifier-224"><a href="#IcpClassifier-224"><span class="linenos">224</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="IcpClassifier-225"><a href="#IcpClassifier-225"><span class="linenos">225</span></a>        <span class="c1"># TODO: if x == self.last_x ...</span>
</span><span id="IcpClassifier-226"><a href="#IcpClassifier-226"><span class="linenos">226</span></a>        <span class="n">n_test_objects</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="IcpClassifier-227"><a href="#IcpClassifier-227"><span class="linenos">227</span></a>        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_test_objects</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</span><span id="IcpClassifier-228"><a href="#IcpClassifier-228"><span class="linenos">228</span></a>
</span><span id="IcpClassifier-229"><a href="#IcpClassifier-229"><span class="linenos">229</span></a>        <span class="n">ncal_ngt_neq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_stats</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="IcpClassifier-230"><a href="#IcpClassifier-230"><span class="linenos">230</span></a>
</span><span id="IcpClassifier-231"><a href="#IcpClassifier-231"><span class="linenos">231</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">)):</span>
</span><span id="IcpClassifier-232"><a href="#IcpClassifier-232"><span class="linenos">232</span></a>            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test_objects</span><span class="p">):</span>
</span><span id="IcpClassifier-233"><a href="#IcpClassifier-233"><span class="linenos">233</span></a>                <span class="n">p</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_p</span><span class="p">(</span>
</span><span id="IcpClassifier-234"><a href="#IcpClassifier-234"><span class="linenos">234</span></a>                    <span class="n">ncal_ngt_neq</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
</span><span id="IcpClassifier-235"><a href="#IcpClassifier-235"><span class="linenos">235</span></a>                    <span class="n">ncal_ngt_neq</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
</span><span id="IcpClassifier-236"><a href="#IcpClassifier-236"><span class="linenos">236</span></a>                    <span class="n">ncal_ngt_neq</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span><span id="IcpClassifier-237"><a href="#IcpClassifier-237"><span class="linenos">237</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span><span class="p">,</span>
</span><span id="IcpClassifier-238"><a href="#IcpClassifier-238"><span class="linenos">238</span></a>                <span class="p">)</span>
</span><span id="IcpClassifier-239"><a href="#IcpClassifier-239"><span class="linenos">239</span></a>
</span><span id="IcpClassifier-240"><a href="#IcpClassifier-240"><span class="linenos">240</span></a>        <span class="k">if</span> <span class="n">significance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="IcpClassifier-241"><a href="#IcpClassifier-241"><span class="linenos">241</span></a>            <span class="k">return</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="n">significance</span>
</span><span id="IcpClassifier-242"><a href="#IcpClassifier-242"><span class="linenos">242</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="IcpClassifier-243"><a href="#IcpClassifier-243"><span class="linenos">243</span></a>            <span class="k">return</span> <span class="n">p</span>
</span><span id="IcpClassifier-244"><a href="#IcpClassifier-244"><span class="linenos">244</span></a>
</span><span id="IcpClassifier-245"><a href="#IcpClassifier-245"><span class="linenos">245</span></a>    <span class="k">def</span> <span class="nf">_get_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="IcpClassifier-246"><a href="#IcpClassifier-246"><span class="linenos">246</span></a>        <span class="n">n_test_objects</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="IcpClassifier-247"><a href="#IcpClassifier-247"><span class="linenos">247</span></a>        <span class="n">ncal_ngt_neq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_test_objects</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span><span id="IcpClassifier-248"><a href="#IcpClassifier-248"><span class="linenos">248</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">):</span>
</span><span id="IcpClassifier-249"><a href="#IcpClassifier-249"><span class="linenos">249</span></a>            <span class="n">test_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="IcpClassifier-250"><a href="#IcpClassifier-250"><span class="linenos">250</span></a>            <span class="n">test_class</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</span><span id="IcpClassifier-251"><a href="#IcpClassifier-251"><span class="linenos">251</span></a>
</span><span id="IcpClassifier-252"><a href="#IcpClassifier-252"><span class="linenos">252</span></a>            <span class="c1"># TODO: maybe calculate p-values using cython or similar</span>
</span><span id="IcpClassifier-253"><a href="#IcpClassifier-253"><span class="linenos">253</span></a>            <span class="c1"># TODO: interpolated p-values</span>
</span><span id="IcpClassifier-254"><a href="#IcpClassifier-254"><span class="linenos">254</span></a>
</span><span id="IcpClassifier-255"><a href="#IcpClassifier-255"><span class="linenos">255</span></a>            <span class="c1"># TODO: nc_function.calc_nc should take X * {y1, y2, ... ,yn}</span>
</span><span id="IcpClassifier-256"><a href="#IcpClassifier-256"><span class="linenos">256</span></a>            <span class="n">test_nc_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nc_function</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">test_class</span><span class="p">)</span>
</span><span id="IcpClassifier-257"><a href="#IcpClassifier-257"><span class="linenos">257</span></a>            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">nc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_nc_scores</span><span class="p">):</span>
</span><span id="IcpClassifier-258"><a href="#IcpClassifier-258"><span class="linenos">258</span></a>                <span class="n">cal_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cal_scores</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">condition</span><span class="p">((</span><span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:],</span> <span class="n">c</span><span class="p">))][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="IcpClassifier-259"><a href="#IcpClassifier-259"><span class="linenos">259</span></a>                <span class="n">n_cal</span> <span class="o">=</span> <span class="n">cal_scores</span><span class="o">.</span><span class="n">size</span>
</span><span id="IcpClassifier-260"><a href="#IcpClassifier-260"><span class="linenos">260</span></a>
</span><span id="IcpClassifier-261"><a href="#IcpClassifier-261"><span class="linenos">261</span></a>                <span class="n">idx_left</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">cal_scores</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">)</span>
</span><span id="IcpClassifier-262"><a href="#IcpClassifier-262"><span class="linenos">262</span></a>                <span class="n">idx_right</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">cal_scores</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">)</span>
</span><span id="IcpClassifier-263"><a href="#IcpClassifier-263"><span class="linenos">263</span></a>
</span><span id="IcpClassifier-264"><a href="#IcpClassifier-264"><span class="linenos">264</span></a>                <span class="n">ncal_ngt_neq</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_cal</span>
</span><span id="IcpClassifier-265"><a href="#IcpClassifier-265"><span class="linenos">265</span></a>                <span class="n">ncal_ngt_neq</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_cal</span> <span class="o">-</span> <span class="n">idx_right</span>
</span><span id="IcpClassifier-266"><a href="#IcpClassifier-266"><span class="linenos">266</span></a>                <span class="n">ncal_ngt_neq</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">idx_right</span> <span class="o">-</span> <span class="n">idx_left</span>
</span><span id="IcpClassifier-267"><a href="#IcpClassifier-267"><span class="linenos">267</span></a>
</span><span id="IcpClassifier-268"><a href="#IcpClassifier-268"><span class="linenos">268</span></a>        <span class="k">return</span> <span class="n">ncal_ngt_neq</span>
</span><span id="IcpClassifier-269"><a href="#IcpClassifier-269"><span class="linenos">269</span></a>
</span><span id="IcpClassifier-270"><a href="#IcpClassifier-270"><span class="linenos">270</span></a>    <span class="k">def</span> <span class="nf">predict_conf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="IcpClassifier-271"><a href="#IcpClassifier-271"><span class="linenos">271</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict the output values for a set of input patterns, using</span>
</span><span id="IcpClassifier-272"><a href="#IcpClassifier-272"><span class="linenos">272</span></a><span class="sd">        the confidence-and-credibility output scheme.</span>
</span><span id="IcpClassifier-273"><a href="#IcpClassifier-273"><span class="linenos">273</span></a>
</span><span id="IcpClassifier-274"><a href="#IcpClassifier-274"><span class="linenos">274</span></a><span class="sd">        Parameters</span>
</span><span id="IcpClassifier-275"><a href="#IcpClassifier-275"><span class="linenos">275</span></a><span class="sd">        ----------</span>
</span><span id="IcpClassifier-276"><a href="#IcpClassifier-276"><span class="linenos">276</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="IcpClassifier-277"><a href="#IcpClassifier-277"><span class="linenos">277</span></a><span class="sd">                Inputs of patters for which to predict output values.</span>
</span><span id="IcpClassifier-278"><a href="#IcpClassifier-278"><span class="linenos">278</span></a>
</span><span id="IcpClassifier-279"><a href="#IcpClassifier-279"><span class="linenos">279</span></a><span class="sd">        Returns</span>
</span><span id="IcpClassifier-280"><a href="#IcpClassifier-280"><span class="linenos">280</span></a><span class="sd">        -------</span>
</span><span id="IcpClassifier-281"><a href="#IcpClassifier-281"><span class="linenos">281</span></a><span class="sd">        p : numpy array of shape [n_samples, 3]</span>
</span><span id="IcpClassifier-282"><a href="#IcpClassifier-282"><span class="linenos">282</span></a><span class="sd">                p contains three columns: the first column contains the most</span>
</span><span id="IcpClassifier-283"><a href="#IcpClassifier-283"><span class="linenos">283</span></a><span class="sd">                likely class for each test pattern; the second column contains</span>
</span><span id="IcpClassifier-284"><a href="#IcpClassifier-284"><span class="linenos">284</span></a><span class="sd">                the confidence in the predicted class label, and the third column</span>
</span><span id="IcpClassifier-285"><a href="#IcpClassifier-285"><span class="linenos">285</span></a><span class="sd">                contains the credibility of the prediction.</span>
</span><span id="IcpClassifier-286"><a href="#IcpClassifier-286"><span class="linenos">286</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="IcpClassifier-287"><a href="#IcpClassifier-287"><span class="linenos">287</span></a>        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span><span id="IcpClassifier-288"><a href="#IcpClassifier-288"><span class="linenos">288</span></a>        <span class="n">label</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="IcpClassifier-289"><a href="#IcpClassifier-289"><span class="linenos">289</span></a>        <span class="n">credibility</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="IcpClassifier-290"><a href="#IcpClassifier-290"><span class="linenos">290</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
</span><span id="IcpClassifier-291"><a href="#IcpClassifier-291"><span class="linenos">291</span></a>            <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="IcpClassifier-292"><a href="#IcpClassifier-292"><span class="linenos">292</span></a>        <span class="n">confidence</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="IcpClassifier-293"><a href="#IcpClassifier-293"><span class="linenos">293</span></a>
</span><span id="IcpClassifier-294"><a href="#IcpClassifier-294"><span class="linenos">294</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">label</span><span class="p">,</span> <span class="n">confidence</span><span class="p">,</span> <span class="n">credibility</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
</span></pre></div>


            <div class="docstring"><p>Inductive conformal classifier.</p>

<h2 id="parameters">Parameters</h2>

<p>nc_function : BaseScorer
        Nonconformity scorer object used to calculate nonconformity of
        calibration examples and test patterns. Should implement <code>fit(x, y)</code>
        and <code>calc_nc(x, y)</code>.</p>

<p>smoothing : boolean
        Decides whether to use stochastic smoothing of p-values.</p>

<h2 id="attributes">Attributes</h2>

<p>cal_x : numpy array of shape [n_cal_examples, n_features]
        Inputs of calibration set.</p>

<p>cal_y : numpy array of shape [n_cal_examples]
        Outputs of calibration set.</p>

<p>nc_function : BaseScorer
        Nonconformity scorer object used to calculate nonconformity scores.</p>

<p>classes : numpy array of shape [n_classes]
        List of class labels, with indices corresponding to output columns
         of <a href="#IcpClassifier.predict">IcpClassifier.predict()</a></p>

<h2 id="see-also">See also</h2>

<p>IcpRegressor</p>

<h2 id="references">References</h2>

<h2 id="examples">Examples</h2>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nonconformist.base</span> <span class="kn">import</span> <span class="n">ClassifierAdapter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nonconformist.icp</span> <span class="kn">import</span> <span class="n">IcpClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nonconformist.nc</span> <span class="kn">import</span> <span class="n">ClassifierNc</span><span class="p">,</span> <span class="n">MarginErrFunc</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">3</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cal</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">3</span><span class="p">):</span><span class="nb">int</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">3</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">3</span><span class="p">):]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ClassifierAdapter</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nc</span> <span class="o">=</span> <span class="n">ClassifierNc</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">MarginErrFunc</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">icp</span> <span class="o">=</span> <span class="n">IcpClassifier</span><span class="p">(</span><span class="n">nc</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">icp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">icp</span><span class="o">.</span><span class="n">calibrate</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">cal</span><span class="p">,</span> <span class="p">:],</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">cal</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">icp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:],</span> <span class="n">significance</span><span class="o">=</span><span class="mf">0.10</span><span class="p">)</span>
<span class="gp">... </span>            <span class="c1"># doctest: +SKIP</span>
<span class="go">array([[ True, False, False],</span>
<span class="go">        [False,  True, False],</span>
<span class="go">        ...,</span>
<span class="go">        [False,  True, False],</span>
<span class="go">        [False,  True, False]], dtype=bool)</span>
</code></pre>
</div>

<div class="footnotes">
<hr />
<ol>
</ol>
</div>
</div>


                                <div id="IcpClassifier.predict" class="classattr">
                                            <input id="IcpClassifier.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span>, </span><span class="param"><span class="n">significance</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="IcpClassifier.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#IcpClassifier.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="IcpClassifier.predict-204"><a href="#IcpClassifier.predict-204"><span class="linenos">204</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="IcpClassifier.predict-205"><a href="#IcpClassifier.predict-205"><span class="linenos">205</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict the output values for a set of input patterns.</span>
</span><span id="IcpClassifier.predict-206"><a href="#IcpClassifier.predict-206"><span class="linenos">206</span></a>
</span><span id="IcpClassifier.predict-207"><a href="#IcpClassifier.predict-207"><span class="linenos">207</span></a><span class="sd">        Parameters</span>
</span><span id="IcpClassifier.predict-208"><a href="#IcpClassifier.predict-208"><span class="linenos">208</span></a><span class="sd">        ----------</span>
</span><span id="IcpClassifier.predict-209"><a href="#IcpClassifier.predict-209"><span class="linenos">209</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="IcpClassifier.predict-210"><a href="#IcpClassifier.predict-210"><span class="linenos">210</span></a><span class="sd">                Inputs of patters for which to predict output values.</span>
</span><span id="IcpClassifier.predict-211"><a href="#IcpClassifier.predict-211"><span class="linenos">211</span></a>
</span><span id="IcpClassifier.predict-212"><a href="#IcpClassifier.predict-212"><span class="linenos">212</span></a><span class="sd">        significance : float or None</span>
</span><span id="IcpClassifier.predict-213"><a href="#IcpClassifier.predict-213"><span class="linenos">213</span></a><span class="sd">                Significance level (maximum allowed error rate) of predictions.</span>
</span><span id="IcpClassifier.predict-214"><a href="#IcpClassifier.predict-214"><span class="linenos">214</span></a><span class="sd">                Should be a float between 0 and 1. If ``None``, then the p-values</span>
</span><span id="IcpClassifier.predict-215"><a href="#IcpClassifier.predict-215"><span class="linenos">215</span></a><span class="sd">                are output rather than the predictions.</span>
</span><span id="IcpClassifier.predict-216"><a href="#IcpClassifier.predict-216"><span class="linenos">216</span></a>
</span><span id="IcpClassifier.predict-217"><a href="#IcpClassifier.predict-217"><span class="linenos">217</span></a><span class="sd">        Returns</span>
</span><span id="IcpClassifier.predict-218"><a href="#IcpClassifier.predict-218"><span class="linenos">218</span></a><span class="sd">        -------</span>
</span><span id="IcpClassifier.predict-219"><a href="#IcpClassifier.predict-219"><span class="linenos">219</span></a><span class="sd">        p : numpy array of shape [n_samples, n_classes]</span>
</span><span id="IcpClassifier.predict-220"><a href="#IcpClassifier.predict-220"><span class="linenos">220</span></a><span class="sd">                If significance is ``None``, then p contains the p-values for each</span>
</span><span id="IcpClassifier.predict-221"><a href="#IcpClassifier.predict-221"><span class="linenos">221</span></a><span class="sd">                sample-class pair; if significance is a float between 0 and 1, then</span>
</span><span id="IcpClassifier.predict-222"><a href="#IcpClassifier.predict-222"><span class="linenos">222</span></a><span class="sd">                p is a boolean array denoting which labels are included in the</span>
</span><span id="IcpClassifier.predict-223"><a href="#IcpClassifier.predict-223"><span class="linenos">223</span></a><span class="sd">                prediction sets.</span>
</span><span id="IcpClassifier.predict-224"><a href="#IcpClassifier.predict-224"><span class="linenos">224</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="IcpClassifier.predict-225"><a href="#IcpClassifier.predict-225"><span class="linenos">225</span></a>        <span class="c1"># TODO: if x == self.last_x ...</span>
</span><span id="IcpClassifier.predict-226"><a href="#IcpClassifier.predict-226"><span class="linenos">226</span></a>        <span class="n">n_test_objects</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="IcpClassifier.predict-227"><a href="#IcpClassifier.predict-227"><span class="linenos">227</span></a>        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_test_objects</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</span><span id="IcpClassifier.predict-228"><a href="#IcpClassifier.predict-228"><span class="linenos">228</span></a>
</span><span id="IcpClassifier.predict-229"><a href="#IcpClassifier.predict-229"><span class="linenos">229</span></a>        <span class="n">ncal_ngt_neq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_stats</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="IcpClassifier.predict-230"><a href="#IcpClassifier.predict-230"><span class="linenos">230</span></a>
</span><span id="IcpClassifier.predict-231"><a href="#IcpClassifier.predict-231"><span class="linenos">231</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">)):</span>
</span><span id="IcpClassifier.predict-232"><a href="#IcpClassifier.predict-232"><span class="linenos">232</span></a>            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test_objects</span><span class="p">):</span>
</span><span id="IcpClassifier.predict-233"><a href="#IcpClassifier.predict-233"><span class="linenos">233</span></a>                <span class="n">p</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_p</span><span class="p">(</span>
</span><span id="IcpClassifier.predict-234"><a href="#IcpClassifier.predict-234"><span class="linenos">234</span></a>                    <span class="n">ncal_ngt_neq</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
</span><span id="IcpClassifier.predict-235"><a href="#IcpClassifier.predict-235"><span class="linenos">235</span></a>                    <span class="n">ncal_ngt_neq</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
</span><span id="IcpClassifier.predict-236"><a href="#IcpClassifier.predict-236"><span class="linenos">236</span></a>                    <span class="n">ncal_ngt_neq</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span><span id="IcpClassifier.predict-237"><a href="#IcpClassifier.predict-237"><span class="linenos">237</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span><span class="p">,</span>
</span><span id="IcpClassifier.predict-238"><a href="#IcpClassifier.predict-238"><span class="linenos">238</span></a>                <span class="p">)</span>
</span><span id="IcpClassifier.predict-239"><a href="#IcpClassifier.predict-239"><span class="linenos">239</span></a>
</span><span id="IcpClassifier.predict-240"><a href="#IcpClassifier.predict-240"><span class="linenos">240</span></a>        <span class="k">if</span> <span class="n">significance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="IcpClassifier.predict-241"><a href="#IcpClassifier.predict-241"><span class="linenos">241</span></a>            <span class="k">return</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="n">significance</span>
</span><span id="IcpClassifier.predict-242"><a href="#IcpClassifier.predict-242"><span class="linenos">242</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="IcpClassifier.predict-243"><a href="#IcpClassifier.predict-243"><span class="linenos">243</span></a>            <span class="k">return</span> <span class="n">p</span>
</span></pre></div>


            <div class="docstring"><p>Predict the output values for a set of input patterns.</p>

<h2 id="parameters">Parameters</h2>

<p>x : numpy array of shape [n_samples, n_features]
        Inputs of patters for which to predict output values.</p>

<p>significance : float or None
        Significance level (maximum allowed error rate) of predictions.
        Should be a float between 0 and 1. If <code>None</code>, then the p-values
        are output rather than the predictions.</p>

<h2 id="returns">Returns</h2>

<p>p : numpy array of shape [n_samples, n_classes]
        If significance is <code>None</code>, then p contains the p-values for each
        sample-class pair; if significance is a float between 0 and 1, then
        p is a boolean array denoting which labels are included in the
        prediction sets.</p>
</div>


                                </div>
                        
                </section>
                <section id="TcpClassifier">
                            <input id="TcpClassifier-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">TcpClassifier</span><wbr>(<span class="base">sklearn.base.BaseEstimator</span>, <span class="base">nnetsauce.nonconformist.base.ClassifierMixin</span>):

                <label class="view-source-button" for="TcpClassifier-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TcpClassifier"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TcpClassifier-10"><a href="#TcpClassifier-10"><span class="linenos"> 10</span></a><span class="k">class</span> <span class="nc">TcpClassifier</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
</span><span id="TcpClassifier-11"><a href="#TcpClassifier-11"><span class="linenos"> 11</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Transductive conformal classifier.</span>
</span><span id="TcpClassifier-12"><a href="#TcpClassifier-12"><span class="linenos"> 12</span></a>
</span><span id="TcpClassifier-13"><a href="#TcpClassifier-13"><span class="linenos"> 13</span></a><span class="sd">    Parameters</span>
</span><span id="TcpClassifier-14"><a href="#TcpClassifier-14"><span class="linenos"> 14</span></a><span class="sd">    ----------</span>
</span><span id="TcpClassifier-15"><a href="#TcpClassifier-15"><span class="linenos"> 15</span></a><span class="sd">    nc_function : BaseScorer</span>
</span><span id="TcpClassifier-16"><a href="#TcpClassifier-16"><span class="linenos"> 16</span></a><span class="sd">            Nonconformity scorer object used to calculate nonconformity of</span>
</span><span id="TcpClassifier-17"><a href="#TcpClassifier-17"><span class="linenos"> 17</span></a><span class="sd">            calibration examples and test patterns. Should implement ``fit(x, y)``</span>
</span><span id="TcpClassifier-18"><a href="#TcpClassifier-18"><span class="linenos"> 18</span></a><span class="sd">            and ``calc_nc(x, y)``.</span>
</span><span id="TcpClassifier-19"><a href="#TcpClassifier-19"><span class="linenos"> 19</span></a>
</span><span id="TcpClassifier-20"><a href="#TcpClassifier-20"><span class="linenos"> 20</span></a><span class="sd">    smoothing : boolean</span>
</span><span id="TcpClassifier-21"><a href="#TcpClassifier-21"><span class="linenos"> 21</span></a><span class="sd">            Decides whether to use stochastic smoothing of p-values.</span>
</span><span id="TcpClassifier-22"><a href="#TcpClassifier-22"><span class="linenos"> 22</span></a>
</span><span id="TcpClassifier-23"><a href="#TcpClassifier-23"><span class="linenos"> 23</span></a><span class="sd">    Attributes</span>
</span><span id="TcpClassifier-24"><a href="#TcpClassifier-24"><span class="linenos"> 24</span></a><span class="sd">    ----------</span>
</span><span id="TcpClassifier-25"><a href="#TcpClassifier-25"><span class="linenos"> 25</span></a><span class="sd">    train_x : numpy array of shape [n_cal_examples, n_features]</span>
</span><span id="TcpClassifier-26"><a href="#TcpClassifier-26"><span class="linenos"> 26</span></a><span class="sd">            Inputs of training set.</span>
</span><span id="TcpClassifier-27"><a href="#TcpClassifier-27"><span class="linenos"> 27</span></a>
</span><span id="TcpClassifier-28"><a href="#TcpClassifier-28"><span class="linenos"> 28</span></a><span class="sd">    train_y : numpy array of shape [n_cal_examples]</span>
</span><span id="TcpClassifier-29"><a href="#TcpClassifier-29"><span class="linenos"> 29</span></a><span class="sd">            Outputs of calibration set.</span>
</span><span id="TcpClassifier-30"><a href="#TcpClassifier-30"><span class="linenos"> 30</span></a>
</span><span id="TcpClassifier-31"><a href="#TcpClassifier-31"><span class="linenos"> 31</span></a><span class="sd">    nc_function : BaseScorer</span>
</span><span id="TcpClassifier-32"><a href="#TcpClassifier-32"><span class="linenos"> 32</span></a><span class="sd">            Nonconformity scorer object used to calculate nonconformity scores.</span>
</span><span id="TcpClassifier-33"><a href="#TcpClassifier-33"><span class="linenos"> 33</span></a>
</span><span id="TcpClassifier-34"><a href="#TcpClassifier-34"><span class="linenos"> 34</span></a><span class="sd">    classes : numpy array of shape [n_classes]</span>
</span><span id="TcpClassifier-35"><a href="#TcpClassifier-35"><span class="linenos"> 35</span></a><span class="sd">            List of class labels, with indices corresponding to output columns</span>
</span><span id="TcpClassifier-36"><a href="#TcpClassifier-36"><span class="linenos"> 36</span></a><span class="sd">             of TcpClassifier.predict()</span>
</span><span id="TcpClassifier-37"><a href="#TcpClassifier-37"><span class="linenos"> 37</span></a>
</span><span id="TcpClassifier-38"><a href="#TcpClassifier-38"><span class="linenos"> 38</span></a><span class="sd">    See also</span>
</span><span id="TcpClassifier-39"><a href="#TcpClassifier-39"><span class="linenos"> 39</span></a><span class="sd">    --------</span>
</span><span id="TcpClassifier-40"><a href="#TcpClassifier-40"><span class="linenos"> 40</span></a><span class="sd">    IcpClassifier</span>
</span><span id="TcpClassifier-41"><a href="#TcpClassifier-41"><span class="linenos"> 41</span></a>
</span><span id="TcpClassifier-42"><a href="#TcpClassifier-42"><span class="linenos"> 42</span></a><span class="sd">    References</span>
</span><span id="TcpClassifier-43"><a href="#TcpClassifier-43"><span class="linenos"> 43</span></a><span class="sd">    ----------</span>
</span><span id="TcpClassifier-44"><a href="#TcpClassifier-44"><span class="linenos"> 44</span></a><span class="sd">    .. [1] Vovk, V., Gammerman, A., &amp; Shafer, G. (2005). Algorithmic learning</span>
</span><span id="TcpClassifier-45"><a href="#TcpClassifier-45"><span class="linenos"> 45</span></a><span class="sd">    in a random world. Springer Science &amp; Business Media.</span>
</span><span id="TcpClassifier-46"><a href="#TcpClassifier-46"><span class="linenos"> 46</span></a>
</span><span id="TcpClassifier-47"><a href="#TcpClassifier-47"><span class="linenos"> 47</span></a><span class="sd">    Examples</span>
</span><span id="TcpClassifier-48"><a href="#TcpClassifier-48"><span class="linenos"> 48</span></a><span class="sd">    --------</span>
</span><span id="TcpClassifier-49"><a href="#TcpClassifier-49"><span class="linenos"> 49</span></a><span class="sd">    &gt;&gt;&gt; import numpy as np</span>
</span><span id="TcpClassifier-50"><a href="#TcpClassifier-50"><span class="linenos"> 50</span></a><span class="sd">    &gt;&gt;&gt; from sklearn.datasets import load_iris</span>
</span><span id="TcpClassifier-51"><a href="#TcpClassifier-51"><span class="linenos"> 51</span></a><span class="sd">    &gt;&gt;&gt; from sklearn.svm import SVC</span>
</span><span id="TcpClassifier-52"><a href="#TcpClassifier-52"><span class="linenos"> 52</span></a><span class="sd">    &gt;&gt;&gt; from nonconformist.base import ClassifierAdapter</span>
</span><span id="TcpClassifier-53"><a href="#TcpClassifier-53"><span class="linenos"> 53</span></a><span class="sd">    &gt;&gt;&gt; from nonconformist.cp import TcpClassifier</span>
</span><span id="TcpClassifier-54"><a href="#TcpClassifier-54"><span class="linenos"> 54</span></a><span class="sd">    &gt;&gt;&gt; from nonconformist.nc import ClassifierNc, MarginErrFunc</span>
</span><span id="TcpClassifier-55"><a href="#TcpClassifier-55"><span class="linenos"> 55</span></a><span class="sd">    &gt;&gt;&gt; iris = load_iris()</span>
</span><span id="TcpClassifier-56"><a href="#TcpClassifier-56"><span class="linenos"> 56</span></a><span class="sd">    &gt;&gt;&gt; idx = np.random.permutation(iris.target.size)</span>
</span><span id="TcpClassifier-57"><a href="#TcpClassifier-57"><span class="linenos"> 57</span></a><span class="sd">    &gt;&gt;&gt; train = idx[:int(idx.size / 2)]</span>
</span><span id="TcpClassifier-58"><a href="#TcpClassifier-58"><span class="linenos"> 58</span></a><span class="sd">    &gt;&gt;&gt; test = idx[int(idx.size / 2):]</span>
</span><span id="TcpClassifier-59"><a href="#TcpClassifier-59"><span class="linenos"> 59</span></a><span class="sd">    &gt;&gt;&gt; model = ClassifierAdapter(SVC(probability=True))</span>
</span><span id="TcpClassifier-60"><a href="#TcpClassifier-60"><span class="linenos"> 60</span></a><span class="sd">    &gt;&gt;&gt; nc = ClassifierNc(model, MarginErrFunc())</span>
</span><span id="TcpClassifier-61"><a href="#TcpClassifier-61"><span class="linenos"> 61</span></a><span class="sd">    &gt;&gt;&gt; tcp = TcpClassifier(nc)</span>
</span><span id="TcpClassifier-62"><a href="#TcpClassifier-62"><span class="linenos"> 62</span></a><span class="sd">    &gt;&gt;&gt; tcp.fit(iris.data[train, :], iris.target[train])</span>
</span><span id="TcpClassifier-63"><a href="#TcpClassifier-63"><span class="linenos"> 63</span></a><span class="sd">    &gt;&gt;&gt; tcp.predict(iris.data[test, :], significance=0.10)</span>
</span><span id="TcpClassifier-64"><a href="#TcpClassifier-64"><span class="linenos"> 64</span></a><span class="sd">    ...             # doctest: +SKIP</span>
</span><span id="TcpClassifier-65"><a href="#TcpClassifier-65"><span class="linenos"> 65</span></a><span class="sd">    array([[ True, False, False],</span>
</span><span id="TcpClassifier-66"><a href="#TcpClassifier-66"><span class="linenos"> 66</span></a><span class="sd">            [False,  True, False],</span>
</span><span id="TcpClassifier-67"><a href="#TcpClassifier-67"><span class="linenos"> 67</span></a><span class="sd">            ...,</span>
</span><span id="TcpClassifier-68"><a href="#TcpClassifier-68"><span class="linenos"> 68</span></a><span class="sd">            [False,  True, False],</span>
</span><span id="TcpClassifier-69"><a href="#TcpClassifier-69"><span class="linenos"> 69</span></a><span class="sd">            [False,  True, False]], dtype=bool)</span>
</span><span id="TcpClassifier-70"><a href="#TcpClassifier-70"><span class="linenos"> 70</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="TcpClassifier-71"><a href="#TcpClassifier-71"><span class="linenos"> 71</span></a>
</span><span id="TcpClassifier-72"><a href="#TcpClassifier-72"><span class="linenos"> 72</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nc_function</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">smoothing</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="TcpClassifier-73"><a href="#TcpClassifier-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_y</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="TcpClassifier-74"><a href="#TcpClassifier-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">nc_function</span> <span class="o">=</span> <span class="n">nc_function</span>
</span><span id="TcpClassifier-75"><a href="#TcpClassifier-75"><span class="linenos"> 75</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">TcpClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="TcpClassifier-76"><a href="#TcpClassifier-76"><span class="linenos"> 76</span></a>
</span><span id="TcpClassifier-77"><a href="#TcpClassifier-77"><span class="linenos"> 77</span></a>        <span class="c1"># Check if condition-parameter is the default function (i.e.,</span>
</span><span id="TcpClassifier-78"><a href="#TcpClassifier-78"><span class="linenos"> 78</span></a>        <span class="c1"># lambda x: 0). This is so we can safely clone the object without</span>
</span><span id="TcpClassifier-79"><a href="#TcpClassifier-79"><span class="linenos"> 79</span></a>        <span class="c1"># the clone accidentally having self.conditional = True.</span>
</span><span id="TcpClassifier-80"><a href="#TcpClassifier-80"><span class="linenos"> 80</span></a>        <span class="k">def</span> <span class="nf">default_condition</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span id="TcpClassifier-81"><a href="#TcpClassifier-81"><span class="linenos"> 81</span></a>            <span class="k">return</span> <span class="mi">0</span>
</span><span id="TcpClassifier-82"><a href="#TcpClassifier-82"><span class="linenos"> 82</span></a>
</span><span id="TcpClassifier-83"><a href="#TcpClassifier-83"><span class="linenos"> 83</span></a>        <span class="n">is_default</span> <span class="o">=</span> <span class="nb">callable</span><span class="p">(</span><span class="n">condition</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
</span><span id="TcpClassifier-84"><a href="#TcpClassifier-84"><span class="linenos"> 84</span></a>            <span class="n">condition</span><span class="o">.</span><span class="vm">__code__</span><span class="o">.</span><span class="n">co_code</span> <span class="o">==</span> <span class="n">default_condition</span><span class="o">.</span><span class="vm">__code__</span><span class="o">.</span><span class="n">co_code</span>
</span><span id="TcpClassifier-85"><a href="#TcpClassifier-85"><span class="linenos"> 85</span></a>        <span class="p">)</span>
</span><span id="TcpClassifier-86"><a href="#TcpClassifier-86"><span class="linenos"> 86</span></a>
</span><span id="TcpClassifier-87"><a href="#TcpClassifier-87"><span class="linenos"> 87</span></a>        <span class="k">if</span> <span class="n">is_default</span><span class="p">:</span>
</span><span id="TcpClassifier-88"><a href="#TcpClassifier-88"><span class="linenos"> 88</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">condition</span> <span class="o">=</span> <span class="n">condition</span>
</span><span id="TcpClassifier-89"><a href="#TcpClassifier-89"><span class="linenos"> 89</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conditional</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="TcpClassifier-90"><a href="#TcpClassifier-90"><span class="linenos"> 90</span></a>        <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">condition</span><span class="p">):</span>
</span><span id="TcpClassifier-91"><a href="#TcpClassifier-91"><span class="linenos"> 91</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">condition</span> <span class="o">=</span> <span class="n">condition</span>
</span><span id="TcpClassifier-92"><a href="#TcpClassifier-92"><span class="linenos"> 92</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conditional</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TcpClassifier-93"><a href="#TcpClassifier-93"><span class="linenos"> 93</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="TcpClassifier-94"><a href="#TcpClassifier-94"><span class="linenos"> 94</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">condition</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span>
</span><span id="TcpClassifier-95"><a href="#TcpClassifier-95"><span class="linenos"> 95</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">conditional</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="TcpClassifier-96"><a href="#TcpClassifier-96"><span class="linenos"> 96</span></a>
</span><span id="TcpClassifier-97"><a href="#TcpClassifier-97"><span class="linenos"> 97</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span> <span class="o">=</span> <span class="n">smoothing</span>
</span><span id="TcpClassifier-98"><a href="#TcpClassifier-98"><span class="linenos"> 98</span></a>
</span><span id="TcpClassifier-99"><a href="#TcpClassifier-99"><span class="linenos"> 99</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">base_icp</span> <span class="o">=</span> <span class="n">IcpClassifier</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nc_function</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">condition</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span><span class="p">)</span>
</span><span id="TcpClassifier-100"><a href="#TcpClassifier-100"><span class="linenos">100</span></a>
</span><span id="TcpClassifier-101"><a href="#TcpClassifier-101"><span class="linenos">101</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TcpClassifier-102"><a href="#TcpClassifier-102"><span class="linenos">102</span></a>
</span><span id="TcpClassifier-103"><a href="#TcpClassifier-103"><span class="linenos">103</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="TcpClassifier-104"><a href="#TcpClassifier-104"><span class="linenos">104</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_y</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</span><span id="TcpClassifier-105"><a href="#TcpClassifier-105"><span class="linenos">105</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="TcpClassifier-106"><a href="#TcpClassifier-106"><span class="linenos">106</span></a>
</span><span id="TcpClassifier-107"><a href="#TcpClassifier-107"><span class="linenos">107</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="TcpClassifier-108"><a href="#TcpClassifier-108"><span class="linenos">108</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict the output values for a set of input patterns.</span>
</span><span id="TcpClassifier-109"><a href="#TcpClassifier-109"><span class="linenos">109</span></a>
</span><span id="TcpClassifier-110"><a href="#TcpClassifier-110"><span class="linenos">110</span></a><span class="sd">        Parameters</span>
</span><span id="TcpClassifier-111"><a href="#TcpClassifier-111"><span class="linenos">111</span></a><span class="sd">        ----------</span>
</span><span id="TcpClassifier-112"><a href="#TcpClassifier-112"><span class="linenos">112</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="TcpClassifier-113"><a href="#TcpClassifier-113"><span class="linenos">113</span></a><span class="sd">                Inputs of patters for which to predict output values.</span>
</span><span id="TcpClassifier-114"><a href="#TcpClassifier-114"><span class="linenos">114</span></a>
</span><span id="TcpClassifier-115"><a href="#TcpClassifier-115"><span class="linenos">115</span></a><span class="sd">        significance : float or None</span>
</span><span id="TcpClassifier-116"><a href="#TcpClassifier-116"><span class="linenos">116</span></a><span class="sd">                Significance level (maximum allowed error rate) of predictions.</span>
</span><span id="TcpClassifier-117"><a href="#TcpClassifier-117"><span class="linenos">117</span></a><span class="sd">                Should be a float between 0 and 1. If ``None``, then the p-values</span>
</span><span id="TcpClassifier-118"><a href="#TcpClassifier-118"><span class="linenos">118</span></a><span class="sd">                are output rather than the predictions.</span>
</span><span id="TcpClassifier-119"><a href="#TcpClassifier-119"><span class="linenos">119</span></a>
</span><span id="TcpClassifier-120"><a href="#TcpClassifier-120"><span class="linenos">120</span></a><span class="sd">        Returns</span>
</span><span id="TcpClassifier-121"><a href="#TcpClassifier-121"><span class="linenos">121</span></a><span class="sd">        -------</span>
</span><span id="TcpClassifier-122"><a href="#TcpClassifier-122"><span class="linenos">122</span></a><span class="sd">        p : numpy array of shape [n_samples, n_classes]</span>
</span><span id="TcpClassifier-123"><a href="#TcpClassifier-123"><span class="linenos">123</span></a><span class="sd">                If significance is ``None``, then p contains the p-values for each</span>
</span><span id="TcpClassifier-124"><a href="#TcpClassifier-124"><span class="linenos">124</span></a><span class="sd">                sample-class pair; if significance is a float between 0 and 1, then</span>
</span><span id="TcpClassifier-125"><a href="#TcpClassifier-125"><span class="linenos">125</span></a><span class="sd">                p is a boolean array denoting which labels are included in the</span>
</span><span id="TcpClassifier-126"><a href="#TcpClassifier-126"><span class="linenos">126</span></a><span class="sd">                prediction sets.</span>
</span><span id="TcpClassifier-127"><a href="#TcpClassifier-127"><span class="linenos">127</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TcpClassifier-128"><a href="#TcpClassifier-128"><span class="linenos">128</span></a>        <span class="n">n_test</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="TcpClassifier-129"><a href="#TcpClassifier-129"><span class="linenos">129</span></a>        <span class="n">n_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="TcpClassifier-130"><a href="#TcpClassifier-130"><span class="linenos">130</span></a>        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</span><span id="TcpClassifier-131"><a href="#TcpClassifier-131"><span class="linenos">131</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test</span><span class="p">):</span>
</span><span id="TcpClassifier-132"><a href="#TcpClassifier-132"><span class="linenos">132</span></a>            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">):</span>
</span><span id="TcpClassifier-133"><a href="#TcpClassifier-133"><span class="linenos">133</span></a>                <span class="n">train_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_x</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]])</span>
</span><span id="TcpClassifier-134"><a href="#TcpClassifier-134"><span class="linenos">134</span></a>                <span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_y</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
</span><span id="TcpClassifier-135"><a href="#TcpClassifier-135"><span class="linenos">135</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">base_icp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
</span><span id="TcpClassifier-136"><a href="#TcpClassifier-136"><span class="linenos">136</span></a>                <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_icp</span><span class="o">.</span><span class="n">nc_function</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
</span><span id="TcpClassifier-137"><a href="#TcpClassifier-137"><span class="linenos">137</span></a>                <span class="n">ngt</span> <span class="o">=</span> <span class="p">(</span><span class="n">scores</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="TcpClassifier-138"><a href="#TcpClassifier-138"><span class="linenos">138</span></a>                <span class="n">neq</span> <span class="o">=</span> <span class="p">(</span><span class="n">scores</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="TcpClassifier-139"><a href="#TcpClassifier-139"><span class="linenos">139</span></a>
</span><span id="TcpClassifier-140"><a href="#TcpClassifier-140"><span class="linenos">140</span></a>                <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_p</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">ngt</span><span class="p">,</span> <span class="n">neq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span><span class="p">)</span>
</span><span id="TcpClassifier-141"><a href="#TcpClassifier-141"><span class="linenos">141</span></a>
</span><span id="TcpClassifier-142"><a href="#TcpClassifier-142"><span class="linenos">142</span></a>        <span class="k">if</span> <span class="n">significance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TcpClassifier-143"><a href="#TcpClassifier-143"><span class="linenos">143</span></a>            <span class="k">return</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="n">significance</span>
</span><span id="TcpClassifier-144"><a href="#TcpClassifier-144"><span class="linenos">144</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="TcpClassifier-145"><a href="#TcpClassifier-145"><span class="linenos">145</span></a>            <span class="k">return</span> <span class="n">p</span>
</span><span id="TcpClassifier-146"><a href="#TcpClassifier-146"><span class="linenos">146</span></a>
</span><span id="TcpClassifier-147"><a href="#TcpClassifier-147"><span class="linenos">147</span></a>    <span class="k">def</span> <span class="nf">predict_conf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="TcpClassifier-148"><a href="#TcpClassifier-148"><span class="linenos">148</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict the output values for a set of input patterns, using</span>
</span><span id="TcpClassifier-149"><a href="#TcpClassifier-149"><span class="linenos">149</span></a><span class="sd">        the confidence-and-credibility output scheme.</span>
</span><span id="TcpClassifier-150"><a href="#TcpClassifier-150"><span class="linenos">150</span></a>
</span><span id="TcpClassifier-151"><a href="#TcpClassifier-151"><span class="linenos">151</span></a><span class="sd">        Parameters</span>
</span><span id="TcpClassifier-152"><a href="#TcpClassifier-152"><span class="linenos">152</span></a><span class="sd">        ----------</span>
</span><span id="TcpClassifier-153"><a href="#TcpClassifier-153"><span class="linenos">153</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="TcpClassifier-154"><a href="#TcpClassifier-154"><span class="linenos">154</span></a><span class="sd">                Inputs of patters for which to predict output values.</span>
</span><span id="TcpClassifier-155"><a href="#TcpClassifier-155"><span class="linenos">155</span></a>
</span><span id="TcpClassifier-156"><a href="#TcpClassifier-156"><span class="linenos">156</span></a><span class="sd">        Returns</span>
</span><span id="TcpClassifier-157"><a href="#TcpClassifier-157"><span class="linenos">157</span></a><span class="sd">        -------</span>
</span><span id="TcpClassifier-158"><a href="#TcpClassifier-158"><span class="linenos">158</span></a><span class="sd">        p : numpy array of shape [n_samples, 3]</span>
</span><span id="TcpClassifier-159"><a href="#TcpClassifier-159"><span class="linenos">159</span></a><span class="sd">                p contains three columns: the first column contains the most</span>
</span><span id="TcpClassifier-160"><a href="#TcpClassifier-160"><span class="linenos">160</span></a><span class="sd">                likely class for each test pattern; the second column contains</span>
</span><span id="TcpClassifier-161"><a href="#TcpClassifier-161"><span class="linenos">161</span></a><span class="sd">                the confidence in the predicted class label, and the third column</span>
</span><span id="TcpClassifier-162"><a href="#TcpClassifier-162"><span class="linenos">162</span></a><span class="sd">                contains the credibility of the prediction.</span>
</span><span id="TcpClassifier-163"><a href="#TcpClassifier-163"><span class="linenos">163</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TcpClassifier-164"><a href="#TcpClassifier-164"><span class="linenos">164</span></a>        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span><span id="TcpClassifier-165"><a href="#TcpClassifier-165"><span class="linenos">165</span></a>        <span class="n">label</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="TcpClassifier-166"><a href="#TcpClassifier-166"><span class="linenos">166</span></a>        <span class="n">credibility</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="TcpClassifier-167"><a href="#TcpClassifier-167"><span class="linenos">167</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
</span><span id="TcpClassifier-168"><a href="#TcpClassifier-168"><span class="linenos">168</span></a>            <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="TcpClassifier-169"><a href="#TcpClassifier-169"><span class="linenos">169</span></a>        <span class="n">confidence</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="TcpClassifier-170"><a href="#TcpClassifier-170"><span class="linenos">170</span></a>
</span><span id="TcpClassifier-171"><a href="#TcpClassifier-171"><span class="linenos">171</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">label</span><span class="p">,</span> <span class="n">confidence</span><span class="p">,</span> <span class="n">credibility</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
</span></pre></div>


            <div class="docstring"><p>Transductive conformal classifier.</p>

<h2 id="parameters">Parameters</h2>

<p>nc_function : BaseScorer
        Nonconformity scorer object used to calculate nonconformity of
        calibration examples and test patterns. Should implement <code>fit(x, y)</code>
        and <code>calc_nc(x, y)</code>.</p>

<p>smoothing : boolean
        Decides whether to use stochastic smoothing of p-values.</p>

<h2 id="attributes">Attributes</h2>

<p>train_x : numpy array of shape [n_cal_examples, n_features]
        Inputs of training set.</p>

<p>train_y : numpy array of shape [n_cal_examples]
        Outputs of calibration set.</p>

<p>nc_function : BaseScorer
        Nonconformity scorer object used to calculate nonconformity scores.</p>

<p>classes : numpy array of shape [n_classes]
        List of class labels, with indices corresponding to output columns
         of <a href="#TcpClassifier.predict">TcpClassifier.predict()</a></p>

<h2 id="see-also">See also</h2>

<p>IcpClassifier</p>

<h2 id="references">References</h2>

<p>in a random world. Springer Science &amp; Business Media.</p>

<h2 id="examples">Examples</h2>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nonconformist.base</span> <span class="kn">import</span> <span class="n">ClassifierAdapter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nonconformist.cp</span> <span class="kn">import</span> <span class="n">TcpClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nonconformist.nc</span> <span class="kn">import</span> <span class="n">ClassifierNc</span><span class="p">,</span> <span class="n">MarginErrFunc</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">):]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ClassifierAdapter</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nc</span> <span class="o">=</span> <span class="n">ClassifierNc</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">MarginErrFunc</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tcp</span> <span class="o">=</span> <span class="n">TcpClassifier</span><span class="p">(</span><span class="n">nc</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tcp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tcp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:],</span> <span class="n">significance</span><span class="o">=</span><span class="mf">0.10</span><span class="p">)</span>
<span class="gp">... </span>            <span class="c1"># doctest: +SKIP</span>
<span class="go">array([[ True, False, False],</span>
<span class="go">        [False,  True, False],</span>
<span class="go">        ...,</span>
<span class="go">        [False,  True, False],</span>
<span class="go">        [False,  True, False]], dtype=bool)</span>
</code></pre>
</div>

<div class="footnotes">
<hr />
<ol>
</ol>
</div>
</div>


                                <div id="TcpClassifier.fit" class="classattr">
                                            <input id="TcpClassifier.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span>, </span><span class="param"><span class="n">y</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="TcpClassifier.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TcpClassifier.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TcpClassifier.fit-103"><a href="#TcpClassifier.fit-103"><span class="linenos">103</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="TcpClassifier.fit-104"><a href="#TcpClassifier.fit-104"><span class="linenos">104</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_y</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</span><span id="TcpClassifier.fit-105"><a href="#TcpClassifier.fit-105"><span class="linenos">105</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span></pre></div>


    

                                </div>
                                <div id="TcpClassifier.predict" class="classattr">
                                            <input id="TcpClassifier.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">x</span>, </span><span class="param"><span class="n">significance</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="TcpClassifier.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TcpClassifier.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TcpClassifier.predict-107"><a href="#TcpClassifier.predict-107"><span class="linenos">107</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="TcpClassifier.predict-108"><a href="#TcpClassifier.predict-108"><span class="linenos">108</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict the output values for a set of input patterns.</span>
</span><span id="TcpClassifier.predict-109"><a href="#TcpClassifier.predict-109"><span class="linenos">109</span></a>
</span><span id="TcpClassifier.predict-110"><a href="#TcpClassifier.predict-110"><span class="linenos">110</span></a><span class="sd">        Parameters</span>
</span><span id="TcpClassifier.predict-111"><a href="#TcpClassifier.predict-111"><span class="linenos">111</span></a><span class="sd">        ----------</span>
</span><span id="TcpClassifier.predict-112"><a href="#TcpClassifier.predict-112"><span class="linenos">112</span></a><span class="sd">        x : numpy array of shape [n_samples, n_features]</span>
</span><span id="TcpClassifier.predict-113"><a href="#TcpClassifier.predict-113"><span class="linenos">113</span></a><span class="sd">                Inputs of patters for which to predict output values.</span>
</span><span id="TcpClassifier.predict-114"><a href="#TcpClassifier.predict-114"><span class="linenos">114</span></a>
</span><span id="TcpClassifier.predict-115"><a href="#TcpClassifier.predict-115"><span class="linenos">115</span></a><span class="sd">        significance : float or None</span>
</span><span id="TcpClassifier.predict-116"><a href="#TcpClassifier.predict-116"><span class="linenos">116</span></a><span class="sd">                Significance level (maximum allowed error rate) of predictions.</span>
</span><span id="TcpClassifier.predict-117"><a href="#TcpClassifier.predict-117"><span class="linenos">117</span></a><span class="sd">                Should be a float between 0 and 1. If ``None``, then the p-values</span>
</span><span id="TcpClassifier.predict-118"><a href="#TcpClassifier.predict-118"><span class="linenos">118</span></a><span class="sd">                are output rather than the predictions.</span>
</span><span id="TcpClassifier.predict-119"><a href="#TcpClassifier.predict-119"><span class="linenos">119</span></a>
</span><span id="TcpClassifier.predict-120"><a href="#TcpClassifier.predict-120"><span class="linenos">120</span></a><span class="sd">        Returns</span>
</span><span id="TcpClassifier.predict-121"><a href="#TcpClassifier.predict-121"><span class="linenos">121</span></a><span class="sd">        -------</span>
</span><span id="TcpClassifier.predict-122"><a href="#TcpClassifier.predict-122"><span class="linenos">122</span></a><span class="sd">        p : numpy array of shape [n_samples, n_classes]</span>
</span><span id="TcpClassifier.predict-123"><a href="#TcpClassifier.predict-123"><span class="linenos">123</span></a><span class="sd">                If significance is ``None``, then p contains the p-values for each</span>
</span><span id="TcpClassifier.predict-124"><a href="#TcpClassifier.predict-124"><span class="linenos">124</span></a><span class="sd">                sample-class pair; if significance is a float between 0 and 1, then</span>
</span><span id="TcpClassifier.predict-125"><a href="#TcpClassifier.predict-125"><span class="linenos">125</span></a><span class="sd">                p is a boolean array denoting which labels are included in the</span>
</span><span id="TcpClassifier.predict-126"><a href="#TcpClassifier.predict-126"><span class="linenos">126</span></a><span class="sd">                prediction sets.</span>
</span><span id="TcpClassifier.predict-127"><a href="#TcpClassifier.predict-127"><span class="linenos">127</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TcpClassifier.predict-128"><a href="#TcpClassifier.predict-128"><span class="linenos">128</span></a>        <span class="n">n_test</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="TcpClassifier.predict-129"><a href="#TcpClassifier.predict-129"><span class="linenos">129</span></a>        <span class="n">n_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="TcpClassifier.predict-130"><a href="#TcpClassifier.predict-130"><span class="linenos">130</span></a>        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</span><span id="TcpClassifier.predict-131"><a href="#TcpClassifier.predict-131"><span class="linenos">131</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test</span><span class="p">):</span>
</span><span id="TcpClassifier.predict-132"><a href="#TcpClassifier.predict-132"><span class="linenos">132</span></a>            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">):</span>
</span><span id="TcpClassifier.predict-133"><a href="#TcpClassifier.predict-133"><span class="linenos">133</span></a>                <span class="n">train_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_x</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]])</span>
</span><span id="TcpClassifier.predict-134"><a href="#TcpClassifier.predict-134"><span class="linenos">134</span></a>                <span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_y</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
</span><span id="TcpClassifier.predict-135"><a href="#TcpClassifier.predict-135"><span class="linenos">135</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">base_icp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
</span><span id="TcpClassifier.predict-136"><a href="#TcpClassifier.predict-136"><span class="linenos">136</span></a>                <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_icp</span><span class="o">.</span><span class="n">nc_function</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
</span><span id="TcpClassifier.predict-137"><a href="#TcpClassifier.predict-137"><span class="linenos">137</span></a>                <span class="n">ngt</span> <span class="o">=</span> <span class="p">(</span><span class="n">scores</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="TcpClassifier.predict-138"><a href="#TcpClassifier.predict-138"><span class="linenos">138</span></a>                <span class="n">neq</span> <span class="o">=</span> <span class="p">(</span><span class="n">scores</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="TcpClassifier.predict-139"><a href="#TcpClassifier.predict-139"><span class="linenos">139</span></a>
</span><span id="TcpClassifier.predict-140"><a href="#TcpClassifier.predict-140"><span class="linenos">140</span></a>                <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_p</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">ngt</span><span class="p">,</span> <span class="n">neq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span><span class="p">)</span>
</span><span id="TcpClassifier.predict-141"><a href="#TcpClassifier.predict-141"><span class="linenos">141</span></a>
</span><span id="TcpClassifier.predict-142"><a href="#TcpClassifier.predict-142"><span class="linenos">142</span></a>        <span class="k">if</span> <span class="n">significance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TcpClassifier.predict-143"><a href="#TcpClassifier.predict-143"><span class="linenos">143</span></a>            <span class="k">return</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="n">significance</span>
</span><span id="TcpClassifier.predict-144"><a href="#TcpClassifier.predict-144"><span class="linenos">144</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="TcpClassifier.predict-145"><a href="#TcpClassifier.predict-145"><span class="linenos">145</span></a>            <span class="k">return</span> <span class="n">p</span>
</span></pre></div>


            <div class="docstring"><p>Predict the output values for a set of input patterns.</p>

<h2 id="parameters">Parameters</h2>

<p>x : numpy array of shape [n_samples, n_features]
        Inputs of patters for which to predict output values.</p>

<p>significance : float or None
        Significance level (maximum allowed error rate) of predictions.
        Should be a float between 0 and 1. If <code>None</code>, then the p-values
        are output rather than the predictions.</p>

<h2 id="returns">Returns</h2>

<p>p : numpy array of shape [n_samples, n_classes]
        If significance is <code>None</code>, then p contains the p-values for each
        sample-class pair; if significance is a float between 0 and 1, then
        p is a boolean array denoting which labels are included in the
        prediction sets.</p>
</div>


                                </div>
                        
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>